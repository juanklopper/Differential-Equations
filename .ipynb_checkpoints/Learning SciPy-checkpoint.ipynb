{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sympy as sym\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sym.init_printing()\n",
    "c = sym.symbols('c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c81e3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-2 * np.pi, 2 * np.pi, 64 * 4)\n",
    "plt.plot(x, np.sin(x))\n",
    "plt.plot(x, np.cos(x))\n",
    "#plt.plot(x, np.tan(x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.\n",
      "  15.  16.  17.  18.  19.]\n",
      "9.5\n",
      "5.76628129734\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "score = np.arange(0., 20., 1)\n",
    "xmean = np.mean(score)\n",
    "xstd = np.std(score)\n",
    "n = np.size(score)\n",
    "print score\n",
    "print xmean\n",
    "print xstd\n",
    "print n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\begin{pmatrix}\\begin{pmatrix}9.5, & \\begin{pmatrix}6.73118943198, & 12.268810568\\end{pmatrix}\\end{pmatrix}, & \\begin{pmatrix}39.1176470588, & \\begin{pmatrix}20.2420973954, & 74.6644326483\\end{pmatrix}\\end{pmatrix}, & \\begin{pmatrix}6.16315863776, & \\begin{pmatrix}4.49912184714, & 8.64085832821\\end{pmatrix}\\end{pmatrix}\\end{pmatrix}$$"
      ],
      "text/plain": [
       "((9.5, (6.73118943198, 12.268810568)), (39.1176470588, (20.2420973954, 74.6644\n",
       "326483)), (6.16315863776, (4.49912184714, 8.64085832821)))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "result = sp.stats.bayes_mvs(score,alpha = 0.95)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\begin{pmatrix}9.5, & \\begin{pmatrix}6.73118943198, & 12.268810568\\end{pmatrix}\\end{pmatrix}$$"
      ],
      "text/plain": [
       "(9.5, (6.73118943198, 12.268810568))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package scipy.stats in scipy:\n",
      "\n",
      "NAME\n",
      "    scipy.stats\n",
      "\n",
      "FILE\n",
      "    /usr/lib/python2.7/dist-packages/scipy/stats/__init__.py\n",
      "\n",
      "DESCRIPTION\n",
      "    ==========================================\n",
      "    Statistical functions (:mod:`scipy.stats`)\n",
      "    ==========================================\n",
      "    \n",
      "    .. module:: scipy.stats\n",
      "    \n",
      "    This module contains a large number of probability distributions as\n",
      "    well as a growing library of statistical functions.\n",
      "    \n",
      "    Each included distribution is an instance of the class rv_continous:\n",
      "    For each given name the following methods are available:\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       rv_continuous\n",
      "       rv_continuous.pdf\n",
      "       rv_continuous.logpdf\n",
      "       rv_continuous.cdf\n",
      "       rv_continuous.logcdf\n",
      "       rv_continuous.sf\n",
      "       rv_continuous.logsf\n",
      "       rv_continuous.ppf\n",
      "       rv_continuous.isf\n",
      "       rv_continuous.moment\n",
      "       rv_continuous.stats\n",
      "       rv_continuous.entropy\n",
      "       rv_continuous.fit\n",
      "       rv_continuous.expect\n",
      "    \n",
      "    Calling the instance as a function returns a frozen pdf whose shape,\n",
      "    location, and scale parameters are fixed.\n",
      "    \n",
      "    Similarly, each discrete distribution is an instance of the class\n",
      "    rv_discrete:\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       rv_discrete\n",
      "       rv_discrete.rvs\n",
      "       rv_discrete.pmf\n",
      "       rv_discrete.logpmf\n",
      "       rv_discrete.cdf\n",
      "       rv_discrete.logcdf\n",
      "       rv_discrete.sf\n",
      "       rv_discrete.logsf\n",
      "       rv_discrete.ppf\n",
      "       rv_discrete.isf\n",
      "       rv_discrete.stats\n",
      "       rv_discrete.moment\n",
      "       rv_discrete.entropy\n",
      "       rv_discrete.expect\n",
      "    \n",
      "    Continuous distributions\n",
      "    ========================\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       alpha             -- Alpha\n",
      "       anglit            -- Anglit\n",
      "       arcsine           -- Arcsine\n",
      "       beta              -- Beta\n",
      "       betaprime         -- Beta Prime\n",
      "       bradford          -- Bradford\n",
      "       burr              -- Burr\n",
      "       cauchy            -- Cauchy\n",
      "       chi               -- Chi\n",
      "       chi2              -- Chi-squared\n",
      "       cosine            -- Cosine\n",
      "       dgamma            -- Double Gamma\n",
      "       dweibull          -- Double Weibull\n",
      "       erlang            -- Erlang\n",
      "       expon             -- Exponential\n",
      "       exponweib         -- Exponentiated Weibull\n",
      "       exponpow          -- Exponential Power\n",
      "       f                 -- F (Snecdor F)\n",
      "       fatiguelife       -- Fatigue Life (Birnbaum-Sanders)\n",
      "       fisk              -- Fisk\n",
      "       foldcauchy        -- Folded Cauchy\n",
      "       foldnorm          -- Folded Normal\n",
      "       frechet_r         -- Frechet Right Sided, Extreme Value Type II (Extreme LB) or weibull_min\n",
      "       frechet_l         -- Frechet Left Sided, Weibull_max\n",
      "       genlogistic       -- Generalized Logistic\n",
      "       genpareto         -- Generalized Pareto\n",
      "       genexpon          -- Generalized Exponential\n",
      "       genextreme        -- Generalized Extreme Value\n",
      "       gausshyper        -- Gauss Hypergeometric\n",
      "       gamma             -- Gamma\n",
      "       gengamma          -- Generalized gamma\n",
      "       genhalflogistic   -- Generalized Half Logistic\n",
      "       gilbrat           -- Gilbrat\n",
      "       gompertz          -- Gompertz (Truncated Gumbel)\n",
      "       gumbel_r          -- Right Sided Gumbel, Log-Weibull, Fisher-Tippett, Extreme Value Type I\n",
      "       gumbel_l          -- Left Sided Gumbel, etc.\n",
      "       halfcauchy        -- Half Cauchy\n",
      "       halflogistic      -- Half Logistic\n",
      "       halfnorm          -- Half Normal\n",
      "       hypsecant         -- Hyperbolic Secant\n",
      "       invgamma          -- Inverse Gamma\n",
      "       invgauss          -- Inverse Gaussian\n",
      "       invweibull        -- Inverse Weibull\n",
      "       johnsonsb         -- Johnson SB\n",
      "       johnsonsu         -- Johnson SU\n",
      "       ksone             -- Kolmogorov-Smirnov one-sided (no stats)\n",
      "       kstwobign         -- Kolmogorov-Smirnov two-sided test for Large N (no stats)\n",
      "       laplace           -- Laplace\n",
      "       logistic          -- Logistic\n",
      "       loggamma          -- Log-Gamma\n",
      "       loglaplace        -- Log-Laplace (Log Double Exponential)\n",
      "       lognorm           -- Log-Normal\n",
      "       lomax             -- Lomax (Pareto of the second kind)\n",
      "       maxwell           -- Maxwell\n",
      "       mielke            -- Mielke's Beta-Kappa\n",
      "       nakagami          -- Nakagami\n",
      "       ncx2              -- Non-central chi-squared\n",
      "       ncf               -- Non-central F\n",
      "       nct               -- Non-central Student's T\n",
      "       norm              -- Normal (Gaussian)\n",
      "       pareto            -- Pareto\n",
      "       pearson3          -- Pearson type III\n",
      "       powerlaw          -- Power-function\n",
      "       powerlognorm      -- Power log normal\n",
      "       powernorm         -- Power normal\n",
      "       rdist             -- R-distribution\n",
      "       reciprocal        -- Reciprocal\n",
      "       rayleigh          -- Rayleigh\n",
      "       rice              -- Rice\n",
      "       recipinvgauss     -- Reciprocal Inverse Gaussian\n",
      "       semicircular      -- Semicircular\n",
      "       t                 -- Student's T\n",
      "       triang            -- Triangular\n",
      "       truncexpon        -- Truncated Exponential\n",
      "       truncnorm         -- Truncated Normal\n",
      "       tukeylambda       -- Tukey-Lambda\n",
      "       uniform           -- Uniform\n",
      "       vonmises          -- Von-Mises (Circular)\n",
      "       wald              -- Wald\n",
      "       weibull_min       -- Minimum Weibull (see Frechet)\n",
      "       weibull_max       -- Maximum Weibull (see Frechet)\n",
      "       wrapcauchy        -- Wrapped Cauchy\n",
      "    \n",
      "    Discrete distributions\n",
      "    ======================\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       bernoulli         -- Bernoulli\n",
      "       binom             -- Binomial\n",
      "       boltzmann         -- Boltzmann (Truncated Discrete Exponential)\n",
      "       dlaplace          -- Discrete Laplacian\n",
      "       geom              -- Geometric\n",
      "       hypergeom         -- Hypergeometric\n",
      "       logser            -- Logarithmic (Log-Series, Series)\n",
      "       nbinom            -- Negative Binomial\n",
      "       planck            -- Planck (Discrete Exponential)\n",
      "       poisson           -- Poisson\n",
      "       randint           -- Discrete Uniform\n",
      "       skellam           -- Skellam\n",
      "       zipf              -- Zipf\n",
      "    \n",
      "    Statistical functions\n",
      "    =====================\n",
      "    \n",
      "    Several of these functions have a similar version in scipy.stats.mstats\n",
      "    which work for masked arrays.\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       cmedian           -- Computed median\n",
      "       describe          -- Descriptive statistics\n",
      "       gmean             -- Geometric mean\n",
      "       hmean             -- Harmonic mean\n",
      "       kurtosis          -- Fisher or Pearson kurtosis\n",
      "       kurtosistest      --\n",
      "       mode              -- Modal value\n",
      "       moment            -- Central moment\n",
      "       normaltest        --\n",
      "       skew              -- Skewness\n",
      "       skewtest          --\n",
      "       tmean             -- Truncated arithmetic mean\n",
      "       tvar              -- Truncated variance\n",
      "       tmin              --\n",
      "       tmax              --\n",
      "       tstd              --\n",
      "       tsem              --\n",
      "       nanmean           -- Mean, ignoring NaN values\n",
      "       nanstd            -- Standard deviation, ignoring NaN values\n",
      "       nanmedian         -- Median, ignoring NaN values\n",
      "       variation         -- Coefficient of variation\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       cumfreq           _\n",
      "       histogram2        _\n",
      "       histogram         _\n",
      "       itemfreq          _\n",
      "       percentileofscore _\n",
      "       scoreatpercentile _\n",
      "       relfreq           _\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       binned_statistic     -- Compute a binned statistic for a set of data.\n",
      "       binned_statistic_2d  -- Compute a 2-D binned statistic for a set of data.\n",
      "       binned_statistic_dd  -- Compute a d-D binned statistic for a set of data.\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       obrientransform\n",
      "       signaltonoise\n",
      "       bayes_mvs\n",
      "       sem\n",
      "       zmap\n",
      "       zscore\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       threshold\n",
      "       trimboth\n",
      "       trim1\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       f_oneway\n",
      "       pearsonr\n",
      "       spearmanr\n",
      "       pointbiserialr\n",
      "       kendalltau\n",
      "       linregress\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       ttest_1samp\n",
      "       ttest_ind\n",
      "       ttest_rel\n",
      "       kstest\n",
      "       chisquare\n",
      "       power_divergence\n",
      "       ks_2samp\n",
      "       mannwhitneyu\n",
      "       tiecorrect\n",
      "       rankdata\n",
      "       ranksums\n",
      "       wilcoxon\n",
      "       kruskal\n",
      "       friedmanchisquare\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       ansari\n",
      "       bartlett\n",
      "       levene\n",
      "       shapiro\n",
      "       anderson\n",
      "       binom_test\n",
      "       fligner\n",
      "       mood\n",
      "       oneway\n",
      "    \n",
      "    Contingency table functions\n",
      "    ===========================\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       chi2_contingency\n",
      "       contingency.expected_freq\n",
      "       contingency.margins\n",
      "       fisher_exact\n",
      "    \n",
      "    General linear model\n",
      "    ====================\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       glm\n",
      "    \n",
      "    Plot-tests\n",
      "    ==========\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       ppcc_max\n",
      "       ppcc_plot\n",
      "       probplot\n",
      "    \n",
      "    \n",
      "    Masked statistics functions\n",
      "    ===========================\n",
      "    \n",
      "    .. toctree::\n",
      "    \n",
      "       stats.mstats\n",
      "    \n",
      "    \n",
      "    Univariate and multivariate kernel density estimation (:mod:`scipy.stats.kde`)\n",
      "    ==============================================================================\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       gaussian_kde\n",
      "    \n",
      "    For many more stat related functions install the software R and the\n",
      "    interface package rpy.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _binned_statistic\n",
      "    _rank\n",
      "    _support\n",
      "    _tukeylambda_stats\n",
      "    contingency\n",
      "    distributions\n",
      "    futil\n",
      "    kde\n",
      "    morestats\n",
      "    mstats\n",
      "    mstats_basic\n",
      "    mstats_extras\n",
      "    mvn\n",
      "    rv\n",
      "    statlib\n",
      "    stats\n",
      "    vonmises\n",
      "    vonmises_cython\n",
      "\n",
      "CLASSES\n",
      "    __builtin__.object\n",
      "        scipy.stats.kde.gaussian_kde\n",
      "    scipy.stats.distributions.rv_generic(__builtin__.object)\n",
      "        scipy.stats.distributions.rv_continuous\n",
      "        scipy.stats.distributions.rv_discrete\n",
      "    \n",
      "    class gaussian_kde(__builtin__.object)\n",
      "     |  Representation of a kernel-density estimate using Gaussian kernels.\n",
      "     |  \n",
      "     |  Kernel density estimation is a way to estimate the probability density\n",
      "     |  function (PDF) of a random variable in a non-parametric way.\n",
      "     |  `gaussian_kde` works for both uni-variate and multi-variate data.   It\n",
      "     |  includes automatic bandwidth determination.  The estimation works best for\n",
      "     |  a unimodal distribution; bimodal or multi-modal distributions tend to be\n",
      "     |  oversmoothed.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  dataset : array_like\n",
      "     |      Datapoints to estimate from. In case of univariate data this is a 1-D\n",
      "     |      array, otherwise a 2-D array with shape (# of dims, # of data).\n",
      "     |  bw_method : str, scalar or callable, optional\n",
      "     |      The method used to calculate the estimator bandwidth.  This can be\n",
      "     |      'scott', 'silverman', a scalar constant or a callable.  If a scalar,\n",
      "     |      this will be used directly as `kde.factor`.  If a callable, it should\n",
      "     |      take a `gaussian_kde` instance as only parameter and return a scalar.\n",
      "     |      If None (default), 'scott' is used.  See Notes for more details.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  dataset : ndarray\n",
      "     |      The dataset with which `gaussian_kde` was initialized.\n",
      "     |  d : int\n",
      "     |      Number of dimensions.\n",
      "     |  n : int\n",
      "     |      Number of datapoints.\n",
      "     |  factor : float\n",
      "     |      The bandwidth factor, obtained from `kde.covariance_factor`, with which\n",
      "     |      the covariance matrix is multiplied.\n",
      "     |  covariance : ndarray\n",
      "     |      The covariance matrix of `dataset`, scaled by the calculated bandwidth\n",
      "     |      (`kde.factor`).\n",
      "     |  inv_cov : ndarray\n",
      "     |      The inverse of `covariance`.\n",
      "     |  \n",
      "     |  Methods\n",
      "     |  -------\n",
      "     |  kde.evaluate(points) : ndarray\n",
      "     |      Evaluate the estimated pdf on a provided set of points.\n",
      "     |  kde(points) : ndarray\n",
      "     |      Same as kde.evaluate(points)\n",
      "     |  kde.integrate_gaussian(mean, cov) : float\n",
      "     |      Multiply pdf with a specified Gaussian and integrate over the whole\n",
      "     |      domain.\n",
      "     |  kde.integrate_box_1d(low, high) : float\n",
      "     |      Integrate pdf (1D only) between two bounds.\n",
      "     |  kde.integrate_box(low_bounds, high_bounds) : float\n",
      "     |      Integrate pdf over a rectangular space between low_bounds and\n",
      "     |      high_bounds.\n",
      "     |  kde.integrate_kde(other_kde) : float\n",
      "     |      Integrate two kernel density estimates multiplied together.\n",
      "     |  kde.resample(size=None) : ndarray\n",
      "     |      Randomly sample a dataset from the estimated pdf.\n",
      "     |  kde.set_bandwidth(bw_method='scott') : None\n",
      "     |      Computes the bandwidth, i.e. the coefficient that multiplies the data\n",
      "     |      covariance matrix to obtain the kernel covariance matrix.\n",
      "     |      .. versionadded:: 0.11.0\n",
      "     |  kde.covariance_factor : float\n",
      "     |      Computes the coefficient (`kde.factor`) that multiplies the data\n",
      "     |      covariance matrix to obtain the kernel covariance matrix.\n",
      "     |      The default is `scotts_factor`.  A subclass can overwrite this method\n",
      "     |      to provide a different method, or set it through a call to\n",
      "     |      `kde.set_bandwidth`.\n",
      "     |  \n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  Bandwidth selection strongly influences the estimate obtained from the KDE\n",
      "     |  (much more so than the actual shape of the kernel).  Bandwidth selection\n",
      "     |  can be done by a \"rule of thumb\", by cross-validation, by \"plug-in\n",
      "     |  methods\" or by other means; see [3]_, [4]_ for reviews.  `gaussian_kde`\n",
      "     |  uses a rule of thumb, the default is Scott's Rule.\n",
      "     |  \n",
      "     |  Scott's Rule [1]_, implemented as `scotts_factor`, is::\n",
      "     |  \n",
      "     |      n**(-1./(d+4)),\n",
      "     |  \n",
      "     |  with ``n`` the number of data points and ``d`` the number of dimensions.\n",
      "     |  Silverman's Rule [2]_, implemented as `silverman_factor`, is::\n",
      "     |  \n",
      "     |      n * (d + 2) / 4.)**(-1. / (d + 4)).\n",
      "     |  \n",
      "     |  Good general descriptions of kernel density estimation can be found in [1]_\n",
      "     |  and [2]_, the mathematics for this multi-dimensional implementation can be\n",
      "     |  found in [1]_.\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  .. [1] D.W. Scott, \"Multivariate Density Estimation: Theory, Practice, and\n",
      "     |         Visualization\", John Wiley & Sons, New York, Chicester, 1992.\n",
      "     |  .. [2] B.W. Silverman, \"Density Estimation for Statistics and Data\n",
      "     |         Analysis\", Vol. 26, Monographs on Statistics and Applied Probability,\n",
      "     |         Chapman and Hall, London, 1986.\n",
      "     |  .. [3] B.A. Turlach, \"Bandwidth Selection in Kernel Density Estimation: A\n",
      "     |         Review\", CORE and Institut de Statistique, Vol. 19, pp. 1-33, 1993.\n",
      "     |  .. [4] D.M. Bashtannyk and R.J. Hyndman, \"Bandwidth selection for kernel\n",
      "     |         conditional density estimation\", Computational Statistics & Data\n",
      "     |         Analysis, Vol. 36, pp. 279-298, 2001.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  Generate some random two-dimensional data:\n",
      "     |  \n",
      "     |  >>> from scipy import stats\n",
      "     |  >>> def measure(n):\n",
      "     |  >>>     \"Measurement model, return two coupled measurements.\"\n",
      "     |  >>>     m1 = np.random.normal(size=n)\n",
      "     |  >>>     m2 = np.random.normal(scale=0.5, size=n)\n",
      "     |  >>>     return m1+m2, m1-m2\n",
      "     |  \n",
      "     |  >>> m1, m2 = measure(2000)\n",
      "     |  >>> xmin = m1.min()\n",
      "     |  >>> xmax = m1.max()\n",
      "     |  >>> ymin = m2.min()\n",
      "     |  >>> ymax = m2.max()\n",
      "     |  \n",
      "     |  Perform a kernel density estimate on the data:\n",
      "     |  \n",
      "     |  >>> X, Y = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
      "     |  >>> positions = np.vstack([X.ravel(), Y.ravel()])\n",
      "     |  >>> values = np.vstack([m1, m2])\n",
      "     |  >>> kernel = stats.gaussian_kde(values)\n",
      "     |  >>> Z = np.reshape(kernel(positions).T, X.shape)\n",
      "     |  \n",
      "     |  Plot the results:\n",
      "     |  \n",
      "     |  >>> import matplotlib.pyplot as plt\n",
      "     |  >>> fig = plt.figure()\n",
      "     |  >>> ax = fig.add_subplot(111)\n",
      "     |  >>> ax.imshow(np.rot90(Z), cmap=plt.cm.gist_earth_r,\n",
      "     |  ...           extent=[xmin, xmax, ymin, ymax])\n",
      "     |  >>> ax.plot(m1, m2, 'k.', markersize=2)\n",
      "     |  >>> ax.set_xlim([xmin, xmax])\n",
      "     |  >>> ax.set_ylim([ymin, ymax])\n",
      "     |  >>> plt.show()\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__ = evaluate(self, points)\n",
      "     |  \n",
      "     |  __init__(self, dataset, bw_method=None)\n",
      "     |  \n",
      "     |  covariance_factor = scotts_factor(self)\n",
      "     |  \n",
      "     |  evaluate(self, points)\n",
      "     |      Evaluate the estimated pdf on a set of points.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      points : (# of dimensions, # of points)-array\n",
      "     |          Alternatively, a (# of dimensions,) vector can be passed in and\n",
      "     |          treated as a single point.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      values : (# of points,)-array\n",
      "     |          The values at each point.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError : if the dimensionality of the input points is different than\n",
      "     |                   the dimensionality of the KDE.\n",
      "     |  \n",
      "     |  integrate_box(self, low_bounds, high_bounds, maxpts=None)\n",
      "     |      Computes the integral of a pdf over a rectangular interval.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      low_bounds : array_like\n",
      "     |          A 1-D array containing the lower bounds of integration.\n",
      "     |      high_bounds : array_like\n",
      "     |          A 1-D array containing the upper bounds of integration.\n",
      "     |      maxpts : int, optional\n",
      "     |          The maximum number of points to use for integration.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      value : scalar\n",
      "     |          The result of the integral.\n",
      "     |  \n",
      "     |  integrate_box_1d(self, low, high)\n",
      "     |      Computes the integral of a 1D pdf between two bounds.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      low : scalar\n",
      "     |          Lower bound of integration.\n",
      "     |      high : scalar\n",
      "     |          Upper bound of integration.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      value : scalar\n",
      "     |          The result of the integral.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          If the KDE is over more than one dimension.\n",
      "     |  \n",
      "     |  integrate_gaussian(self, mean, cov)\n",
      "     |      Multiply estimated density by a multivariate Gaussian and integrate\n",
      "     |      over the whole space.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      mean : aray_like\n",
      "     |          A 1-D array, specifying the mean of the Gaussian.\n",
      "     |      cov : array_like\n",
      "     |          A 2-D array, specifying the covariance matrix of the Gaussian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : scalar\n",
      "     |          The value of the integral.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError :\n",
      "     |          If the mean or covariance of the input Gaussian differs from\n",
      "     |          the KDE's dimensionality.\n",
      "     |  \n",
      "     |  integrate_kde(self, other)\n",
      "     |      Computes the integral of the product of this  kernel density estimate\n",
      "     |      with another.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : gaussian_kde instance\n",
      "     |          The other kde.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      value : scalar\n",
      "     |          The result of the integral.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          If the KDEs have different dimensionality.\n",
      "     |  \n",
      "     |  resample(self, size=None)\n",
      "     |      Randomly sample a dataset from the estimated pdf.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      size : int, optional\n",
      "     |          The number of samples to draw.  If not provided, then the size is\n",
      "     |          the same as the underlying dataset.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      resample : (self.d, `size`) ndarray\n",
      "     |          The sampled dataset.\n",
      "     |  \n",
      "     |  scotts_factor(self)\n",
      "     |  \n",
      "     |  set_bandwidth(self, bw_method=None)\n",
      "     |      Compute the estimator bandwidth with given method.\n",
      "     |      \n",
      "     |      The new bandwidth calculated after a call to `set_bandwidth` is used\n",
      "     |      for subsequent evaluations of the estimated density.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      bw_method : str, scalar or callable, optional\n",
      "     |          The method used to calculate the estimator bandwidth.  This can be\n",
      "     |          'scott', 'silverman', a scalar constant or a callable.  If a\n",
      "     |          scalar, this will be used directly as `kde.factor`.  If a callable,\n",
      "     |          it should take a `gaussian_kde` instance as only parameter and\n",
      "     |          return a scalar.  If None (default), nothing happens; the current\n",
      "     |          `kde.covariance_factor` method is kept.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. versionadded:: 0.11\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x1 = np.array([-7, -5, 1, 4, 5.])\n",
      "     |      >>> kde = stats.gaussian_kde(x1)\n",
      "     |      >>> xs = np.linspace(-10, 10, num=50)\n",
      "     |      >>> y1 = kde(xs)\n",
      "     |      >>> kde.set_bandwidth(bw_method='silverman')\n",
      "     |      >>> y2 = kde(xs)\n",
      "     |      >>> kde.set_bandwidth(bw_method=kde.factor / 3.)\n",
      "     |      >>> y3 = kde(xs)\n",
      "     |      \n",
      "     |      >>> fig = plt.figure()\n",
      "     |      >>> ax = fig.add_subplot(111)\n",
      "     |      >>> ax.plot(x1, np.ones(x1.shape) / (4. * x1.size), 'bo',\n",
      "     |      ...         label='Data points (rescaled)')\n",
      "     |      >>> ax.plot(xs, y1, label='Scott (default)')\n",
      "     |      >>> ax.plot(xs, y2, label='Silverman')\n",
      "     |      >>> ax.plot(xs, y3, label='Const (1/3 * Silverman)')\n",
      "     |      >>> ax.legend()\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  silverman_factor(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class rv_continuous(rv_generic)\n",
      "     |  A generic continuous random variable class meant for subclassing.\n",
      "     |  \n",
      "     |  `rv_continuous` is a base class to construct specific distribution classes\n",
      "     |  and instances from for continuous random variables. It cannot be used\n",
      "     |  directly as a distribution.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  momtype : int, optional\n",
      "     |      The type of generic moment calculation to use: 0 for pdf, 1 (default)\n",
      "     |      for ppf.\n",
      "     |  a : float, optional\n",
      "     |      Lower bound of the support of the distribution, default is minus\n",
      "     |      infinity.\n",
      "     |  b : float, optional\n",
      "     |      Upper bound of the support of the distribution, default is plus\n",
      "     |      infinity.\n",
      "     |  xtol : float, optional\n",
      "     |      The tolerance for fixed point calculation for generic ppf.\n",
      "     |  badvalue : object, optional\n",
      "     |      The value in a result arrays that indicates a value that for which\n",
      "     |      some argument restriction is violated, default is np.nan.\n",
      "     |  name : str, optional\n",
      "     |      The name of the instance. This string is used to construct the default\n",
      "     |      example for distributions.\n",
      "     |  longname : str, optional\n",
      "     |      This string is used as part of the first line of the docstring returned\n",
      "     |      when a subclass has no docstring of its own. Note: `longname` exists\n",
      "     |      for backwards compatibility, do not use for new subclasses.\n",
      "     |  shapes : str, optional\n",
      "     |      The shape of the distribution. For example ``\"m, n\"`` for a\n",
      "     |      distribution that takes two integers as the two shape arguments for all\n",
      "     |      its methods.\n",
      "     |  extradoc :  str, optional, deprecated\n",
      "     |      This string is used as the last part of the docstring returned when a\n",
      "     |      subclass has no docstring of its own. Note: `extradoc` exists for\n",
      "     |      backwards compatibility, do not use for new subclasses.\n",
      "     |  \n",
      "     |  Methods\n",
      "     |  -------\n",
      "     |  rvs(<shape(s)>, loc=0, scale=1, size=1)\n",
      "     |      random variates\n",
      "     |  \n",
      "     |  pdf(x, <shape(s)>, loc=0, scale=1)\n",
      "     |      probability density function\n",
      "     |  \n",
      "     |  logpdf(x, <shape(s)>, loc=0, scale=1)\n",
      "     |      log of the probability density function\n",
      "     |  \n",
      "     |  cdf(x, <shape(s)>, loc=0, scale=1)\n",
      "     |      cumulative density function\n",
      "     |  \n",
      "     |  logcdf(x, <shape(s)>, loc=0, scale=1)\n",
      "     |      log of the cumulative density function\n",
      "     |  \n",
      "     |  sf(x, <shape(s)>, loc=0, scale=1)\n",
      "     |      survival function (1-cdf --- sometimes more accurate)\n",
      "     |  \n",
      "     |  logsf(x, <shape(s)>, loc=0, scale=1)\n",
      "     |      log of the survival function\n",
      "     |  \n",
      "     |  ppf(q, <shape(s)>, loc=0, scale=1)\n",
      "     |    percent point function (inverse of cdf --- quantiles)\n",
      "     |  \n",
      "     |  isf(q, <shape(s)>, loc=0, scale=1)\n",
      "     |      inverse survival function (inverse of sf)\n",
      "     |  \n",
      "     |  moment(n, <shape(s)>, loc=0, scale=1)\n",
      "     |      non-central n-th moment of the distribution.  May not work for array arguments.\n",
      "     |  \n",
      "     |  stats(<shape(s)>, loc=0, scale=1, moments='mv')\n",
      "     |      mean('m'), variance('v'), skew('s'), and/or kurtosis('k')\n",
      "     |  \n",
      "     |  entropy(<shape(s)>, loc=0, scale=1)\n",
      "     |      (differential) entropy of the RV.\n",
      "     |  \n",
      "     |  fit(data, <shape(s)>, loc=0, scale=1)\n",
      "     |      Parameter estimates for generic data\n",
      "     |  \n",
      "     |  expect(func=None, args=(), loc=0, scale=1, lb=None, ub=None,\n",
      "     |           conditional=False, **kwds)\n",
      "     |      Expected value of a function with respect to the distribution.\n",
      "     |      Additional kwd arguments passed to integrate.quad\n",
      "     |  \n",
      "     |  median(<shape(s)>, loc=0, scale=1)\n",
      "     |      Median of the distribution.\n",
      "     |  \n",
      "     |  mean(<shape(s)>, loc=0, scale=1)\n",
      "     |      Mean of the distribution.\n",
      "     |  \n",
      "     |  std(<shape(s)>, loc=0, scale=1)\n",
      "     |      Standard deviation of the distribution.\n",
      "     |  \n",
      "     |  var(<shape(s)>, loc=0, scale=1)\n",
      "     |      Variance of the distribution.\n",
      "     |  \n",
      "     |  interval(alpha, <shape(s)>, loc=0, scale=1)\n",
      "     |      Interval that with `alpha` percent probability contains a random\n",
      "     |      realization of this distribution.\n",
      "     |  \n",
      "     |  __call__(<shape(s)>, loc=0, scale=1)\n",
      "     |      Calling a distribution instance creates a frozen RV object with the\n",
      "     |      same methods but holding the given shape, location, and scale fixed.\n",
      "     |      See Notes section.\n",
      "     |  \n",
      "     |  **Parameters for Methods**\n",
      "     |  \n",
      "     |  x : array_like\n",
      "     |      quantiles\n",
      "     |  q : array_like\n",
      "     |      lower or upper tail probability\n",
      "     |  <shape(s)> : array_like\n",
      "     |      shape parameters\n",
      "     |  loc : array_like, optional\n",
      "     |      location parameter (default=0)\n",
      "     |  scale : array_like, optional\n",
      "     |      scale parameter (default=1)\n",
      "     |  size : int or tuple of ints, optional\n",
      "     |      shape of random variates (default computed from input arguments )\n",
      "     |  moments : string, optional\n",
      "     |      composed of letters ['mvsk'] specifying which moments to compute where\n",
      "     |      'm' = mean, 'v' = variance, 's' = (Fisher's) skew and\n",
      "     |      'k' = (Fisher's) kurtosis. (default='mv')\n",
      "     |  n : int\n",
      "     |      order of moment to calculate in method moments\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  \n",
      "     |  **Methods that can be overwritten by subclasses**\n",
      "     |  ::\n",
      "     |  \n",
      "     |    _rvs\n",
      "     |    _pdf\n",
      "     |    _cdf\n",
      "     |    _sf\n",
      "     |    _ppf\n",
      "     |    _isf\n",
      "     |    _stats\n",
      "     |    _munp\n",
      "     |    _entropy\n",
      "     |    _argcheck\n",
      "     |  \n",
      "     |  There are additional (internal and private) generic methods that can\n",
      "     |  be useful for cross-checking and for debugging, but might work in all\n",
      "     |  cases when directly called.\n",
      "     |  \n",
      "     |  **Frozen Distribution**\n",
      "     |  \n",
      "     |  Alternatively, the object may be called (as a function) to fix the shape,\n",
      "     |  location, and scale parameters returning a \"frozen\" continuous RV object:\n",
      "     |  \n",
      "     |  rv = generic(<shape(s)>, loc=0, scale=1)\n",
      "     |      frozen RV object with the same methods but holding the given shape,\n",
      "     |      location, and scale fixed\n",
      "     |  \n",
      "     |  **Subclassing**\n",
      "     |  \n",
      "     |  New random variables can be defined by subclassing rv_continuous class\n",
      "     |  and re-defining at least the ``_pdf`` or the ``_cdf`` method (normalized\n",
      "     |  to location 0 and scale 1) which will be given clean arguments (in between\n",
      "     |  a and b) and passing the argument check method.\n",
      "     |  \n",
      "     |  If positive argument checking is not correct for your RV\n",
      "     |  then you will also need to re-define the ``_argcheck`` method.\n",
      "     |  \n",
      "     |  Correct, but potentially slow defaults exist for the remaining\n",
      "     |  methods but for speed and/or accuracy you can over-ride::\n",
      "     |  \n",
      "     |    _logpdf, _cdf, _logcdf, _ppf, _rvs, _isf, _sf, _logsf\n",
      "     |  \n",
      "     |  Rarely would you override ``_isf``, ``_sf`` or ``_logsf``, but you could.\n",
      "     |  \n",
      "     |  Statistics are computed using numerical integration by default.\n",
      "     |  For speed you can redefine this using ``_stats``:\n",
      "     |  \n",
      "     |   - take shape parameters and return mu, mu2, g1, g2\n",
      "     |   - If you can't compute one of these, return it as None\n",
      "     |   - Can also be defined with a keyword argument ``moments=<str>``,\n",
      "     |     where <str> is a string composed of 'm', 'v', 's',\n",
      "     |     and/or 'k'.  Only the components appearing in string\n",
      "     |     should be computed and returned in the order 'm', 'v',\n",
      "     |     's', or 'k'  with missing values returned as None.\n",
      "     |  \n",
      "     |  Alternatively, you can override ``_munp``, which takes n and shape\n",
      "     |  parameters and returns the nth non-central moment of the distribution.\n",
      "     |  \n",
      "     |  A note on ``shapes``: subclasses need not specify them explicitly. In this\n",
      "     |  case, the `shapes` will be automatically deduced from the signatures of the\n",
      "     |  overridden methods.\n",
      "     |  If, for some reason, you prefer to avoid relying on introspection, you can\n",
      "     |  specify ``shapes`` explicitly as an argument to the instance constructor.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  To create a new Gaussian distribution, we would do the following::\n",
      "     |  \n",
      "     |      class gaussian_gen(rv_continuous):\n",
      "     |          \"Gaussian distribution\"\n",
      "     |          def _pdf(self, x):\n",
      "     |              ...\n",
      "     |          ...\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      rv_continuous\n",
      "     |      rv_generic\n",
      "     |      __builtin__.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, *args, **kwds)\n",
      "     |  \n",
      "     |  __init__(self, momtype=1, a=None, b=None, xtol=1e-14, badvalue=None, name=None, longname=None, shapes=None, extradoc=None)\n",
      "     |  \n",
      "     |  cdf(self, x, *args, **kwds)\n",
      "     |      Cumulative distribution function of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : array_like\n",
      "     |          quantiles\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cdf : ndarray\n",
      "     |          Cumulative distribution function evaluated at `x`\n",
      "     |  \n",
      "     |  entropy(self, *args, **kwds)\n",
      "     |      Differential entropy of the RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter (default=0).\n",
      "     |      scale : array_like, optional\n",
      "     |          Scale parameter (default=1).\n",
      "     |  \n",
      "     |  est_loc_scale(*args, **kwds)\n",
      "     |      `est_loc_scale` is deprecated!\n",
      "     |      \n",
      "     |      This function is deprecated, use self.fit_loc_scale(data) instead.\n",
      "     |  \n",
      "     |  expect(self, func=None, args=(), loc=0, scale=1, lb=None, ub=None, conditional=False, **kwds)\n",
      "     |      Calculate expected value of a function with respect to the distribution\n",
      "     |      \n",
      "     |      The expected value of a function ``f(x)`` with respect to a\n",
      "     |      distribution ``dist`` is defined as::\n",
      "     |      \n",
      "     |                  ubound\n",
      "     |          E[x] = Integral(f(x) * dist.pdf(x))\n",
      "     |                  lbound\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : callable, optional\n",
      "     |          Function for which integral is calculated. Takes only one argument.\n",
      "     |          The default is the identity mapping f(x) = x.\n",
      "     |      args : tuple, optional\n",
      "     |          Argument (parameters) of the distribution.\n",
      "     |      lb, ub : scalar, optional\n",
      "     |          Lower and upper bound for integration. default is set to the support\n",
      "     |          of the distribution.\n",
      "     |      conditional : bool, optional\n",
      "     |          If True, the integral is corrected by the conditional probability\n",
      "     |          of the integration interval.  The return value is the expectation\n",
      "     |          of the function, conditional on being in the given interval.\n",
      "     |          Default is False.\n",
      "     |      \n",
      "     |      Additional keyword arguments are passed to the integration routine.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      expect : float\n",
      "     |          The calculated expected value.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The integration behavior of this function is inherited from\n",
      "     |      `integrate.quad`.\n",
      "     |  \n",
      "     |  fit(self, data, *args, **kwds)\n",
      "     |      Return MLEs for shape, location, and scale parameters from data.\n",
      "     |      \n",
      "     |      MLE stands for Maximum Likelihood Estimate.  Starting estimates for\n",
      "     |      the fit are given by input arguments; for any arguments not provided\n",
      "     |      with starting estimates, ``self._fitstart(data)`` is called to generate\n",
      "     |      such.\n",
      "     |      \n",
      "     |      One can hold some parameters fixed to specific values by passing in\n",
      "     |      keyword arguments ``f0``, ``f1``, ..., ``fn`` (for shape parameters)\n",
      "     |      and ``floc`` and ``fscale`` (for location and scale parameters,\n",
      "     |      respectively).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : array_like\n",
      "     |          Data to use in calculating the MLEs.\n",
      "     |      args : floats, optional\n",
      "     |          Starting value(s) for any shape-characterizing arguments (those not\n",
      "     |          provided will be determined by a call to ``_fitstart(data)``).\n",
      "     |          No default value.\n",
      "     |      kwds : floats, optional\n",
      "     |          Starting values for the location and scale parameters; no default.\n",
      "     |          Special keyword arguments are recognized as holding certain\n",
      "     |          parameters fixed:\n",
      "     |      \n",
      "     |          f0...fn : hold respective shape parameters fixed.\n",
      "     |      \n",
      "     |          floc : hold location parameter fixed to specified value.\n",
      "     |      \n",
      "     |          fscale : hold scale parameter fixed to specified value.\n",
      "     |      \n",
      "     |          optimizer : The optimizer to use.  The optimizer must take func,\n",
      "     |                      and starting position as the first two arguments,\n",
      "     |                      plus args (for extra arguments to pass to the\n",
      "     |                      function to be optimized) and disp=0 to suppress\n",
      "     |                      output as keyword arguments.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      shape, loc, scale : tuple of floats\n",
      "     |          MLEs for any shape statistics, followed by those for location and\n",
      "     |          scale.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This fit is computed by maximizing a log-likelihood function, with\n",
      "     |      penalty applied for samples outside of range of the distribution. The\n",
      "     |      returned answer is not guaranteed to be the globally optimal MLE, it\n",
      "     |      may only be locally optimal, or the optimization may fail altogether.\n",
      "     |  \n",
      "     |  fit_loc_scale(self, data, *args)\n",
      "     |      Estimate loc and scale parameters from data using 1st and 2nd moments.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : array_like\n",
      "     |          Data to fit.\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Lhat : float\n",
      "     |          Estimated location parameter for the data.\n",
      "     |      Shat : float\n",
      "     |          Estimated scale parameter for the data.\n",
      "     |  \n",
      "     |  freeze(self, *args, **kwds)\n",
      "     |      Freeze the distribution for the given arguments.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution.  Should include all\n",
      "     |          the non-optional arguments, may include ``loc`` and ``scale``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      rv_frozen : rv_frozen instance\n",
      "     |          The frozen distribution.\n",
      "     |  \n",
      "     |  isf(self, q, *args, **kwds)\n",
      "     |      Inverse survival function at q of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      q : array_like\n",
      "     |          upper tail probability\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      x : ndarray or scalar\n",
      "     |          Quantile corresponding to the upper tail probability q.\n",
      "     |  \n",
      "     |  logcdf(self, x, *args, **kwds)\n",
      "     |      Log of the cumulative distribution function at x of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : array_like\n",
      "     |          quantiles\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      logcdf : array_like\n",
      "     |          Log of the cumulative distribution function evaluated at x\n",
      "     |  \n",
      "     |  logpdf(self, x, *args, **kwds)\n",
      "     |      Log of the probability density function at x of the given RV.\n",
      "     |      \n",
      "     |      This uses a more numerically accurate calculation if available.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : array_like\n",
      "     |          quantiles\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      logpdf : array_like\n",
      "     |          Log of the probability density function evaluated at x\n",
      "     |  \n",
      "     |  logsf(self, x, *args, **kwds)\n",
      "     |      Log of the survival function of the given RV.\n",
      "     |      \n",
      "     |      Returns the log of the \"survival function,\" defined as (1 - `cdf`),\n",
      "     |      evaluated at `x`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : array_like\n",
      "     |          quantiles\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      logsf : ndarray\n",
      "     |          Log of the survival function evaluated at `x`.\n",
      "     |  \n",
      "     |  moment(self, n, *args, **kwds)\n",
      "     |      n'th order non-central moment of distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int, n>=1\n",
      "     |          Order of moment.\n",
      "     |      arg1, arg2, arg3,... : float\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      kwds : keyword arguments, optional\n",
      "     |          These can include \"loc\" and \"scale\", as well as other keyword\n",
      "     |          arguments relevant for a given distribution.\n",
      "     |  \n",
      "     |  nnlf(self, theta, x)\n",
      "     |      Return negative loglikelihood function\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is ``-sum(log pdf(x, theta), axis=0)`` where theta are the\n",
      "     |      parameters (including loc and scale).\n",
      "     |  \n",
      "     |  pdf(self, x, *args, **kwds)\n",
      "     |      Probability density function at x of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : array_like\n",
      "     |          quantiles\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      pdf : ndarray\n",
      "     |          Probability density function evaluated at x\n",
      "     |  \n",
      "     |  ppf(self, q, *args, **kwds)\n",
      "     |      Percent point function (inverse of cdf) at q of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      q : array_like\n",
      "     |          lower tail probability\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      x : array_like\n",
      "     |          quantile corresponding to the lower tail probability q.\n",
      "     |  \n",
      "     |  sf(self, x, *args, **kwds)\n",
      "     |      Survival function (1-cdf) at x of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : array_like\n",
      "     |          quantiles\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sf : array_like\n",
      "     |          Survival function evaluated at x\n",
      "     |  \n",
      "     |  stats(self, *args, **kwds)\n",
      "     |      Some statistics of the given RV\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      moments : str, optional\n",
      "     |          composed of letters ['mvsk'] defining which moments to compute:\n",
      "     |          'm' = mean,\n",
      "     |          'v' = variance,\n",
      "     |          's' = (Fisher's) skew,\n",
      "     |          'k' = (Fisher's) kurtosis.\n",
      "     |          (default='mv')\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      stats : sequence\n",
      "     |          of requested moments.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from rv_generic:\n",
      "     |  \n",
      "     |  interval(self, alpha, *args, **kwds)\n",
      "     |      Confidence interval with equal areas around the median.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      alpha : array_like of float\n",
      "     |          Probability that an rv will be drawn from the returned range.\n",
      "     |          Each value should be in the range [0, 1].\n",
      "     |      arg1, arg2, ... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter, Default is 0.\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter, Default is 1.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a, b : ndarray of float\n",
      "     |          end-points of range that contain ``100 * alpha %`` of the rv's possible\n",
      "     |          values.\n",
      "     |  \n",
      "     |  mean(self, *args, **kwds)\n",
      "     |      Mean of the distribution\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      mean : float\n",
      "     |          the mean of the distribution\n",
      "     |  \n",
      "     |  median(self, *args, **kwds)\n",
      "     |      Median of the distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter, Default is 0.\n",
      "     |      scale : array_like, optional\n",
      "     |          Scale parameter, Default is 1.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      median : float\n",
      "     |          The median of the distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      stats.distributions.rv_discrete.ppf\n",
      "     |          Inverse of the CDF\n",
      "     |  \n",
      "     |  rvs(self, *args, **kwds)\n",
      "     |      Random variates of given type.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter (default=0).\n",
      "     |      scale : array_like, optional\n",
      "     |          Scale parameter (default=1).\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Defining number of random variates (default=1).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      rvs : ndarray or scalar\n",
      "     |          Random variates of given `size`.\n",
      "     |  \n",
      "     |  std(self, *args, **kwds)\n",
      "     |      Standard deviation of the distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      std : float\n",
      "     |          standard deviation of the distribution\n",
      "     |  \n",
      "     |  var(self, *args, **kwds)\n",
      "     |      Variance of the distribution\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      var : float\n",
      "     |          the variance of the distribution\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from rv_generic:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class rv_discrete(rv_generic)\n",
      "     |  A generic discrete random variable class meant for subclassing.\n",
      "     |  \n",
      "     |  `rv_discrete` is a base class to construct specific distribution classes\n",
      "     |  and instances from for discrete random variables. rv_discrete can be used\n",
      "     |  to construct an arbitrary distribution with defined by a list of support\n",
      "     |  points and the corresponding probabilities.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  a : float, optional\n",
      "     |      Lower bound of the support of the distribution, default: 0\n",
      "     |  b : float, optional\n",
      "     |      Upper bound of the support of the distribution, default: plus infinity\n",
      "     |  moment_tol : float, optional\n",
      "     |      The tolerance for the generic calculation of moments\n",
      "     |  values : tuple of two array_like\n",
      "     |      (xk, pk) where xk are points (integers) with positive probability pk\n",
      "     |      with sum(pk) = 1\n",
      "     |  inc : integer\n",
      "     |      increment for the support of the distribution, default: 1\n",
      "     |      other values have not been tested\n",
      "     |  badvalue : object, optional\n",
      "     |      The value in (masked) arrays that indicates a value that should be\n",
      "     |      ignored.\n",
      "     |  name : str, optional\n",
      "     |      The name of the instance. This string is used to construct the default\n",
      "     |      example for distributions.\n",
      "     |  longname : str, optional\n",
      "     |      This string is used as part of the first line of the docstring returned\n",
      "     |      when a subclass has no docstring of its own. Note: `longname` exists\n",
      "     |      for backwards compatibility, do not use for new subclasses.\n",
      "     |  shapes : str, optional\n",
      "     |      The shape of the distribution. For example ``\"m, n\"`` for a\n",
      "     |      distribution that takes two integers as the first two arguments for all\n",
      "     |      its methods.\n",
      "     |  extradoc :  str, optional\n",
      "     |      This string is used as the last part of the docstring returned when a\n",
      "     |      subclass has no docstring of its own. Note: `extradoc` exists for\n",
      "     |      backwards compatibility, do not use for new subclasses.\n",
      "     |  \n",
      "     |  Methods\n",
      "     |  -------\n",
      "     |  generic.rvs(<shape(s)>, loc=0, size=1)\n",
      "     |      random variates\n",
      "     |  \n",
      "     |  generic.pmf(x, <shape(s)>, loc=0)\n",
      "     |      probability mass function\n",
      "     |  \n",
      "     |  logpmf(x, <shape(s)>, loc=0)\n",
      "     |      log of the probability density function\n",
      "     |  \n",
      "     |  generic.cdf(x, <shape(s)>, loc=0)\n",
      "     |      cumulative density function\n",
      "     |  \n",
      "     |  generic.logcdf(x, <shape(s)>, loc=0)\n",
      "     |      log of the cumulative density function\n",
      "     |  \n",
      "     |  generic.sf(x, <shape(s)>, loc=0)\n",
      "     |      survival function (1-cdf --- sometimes more accurate)\n",
      "     |  \n",
      "     |  generic.logsf(x, <shape(s)>, loc=0, scale=1)\n",
      "     |      log of the survival function\n",
      "     |  \n",
      "     |  generic.ppf(q, <shape(s)>, loc=0)\n",
      "     |      percent point function (inverse of cdf --- percentiles)\n",
      "     |  \n",
      "     |  generic.isf(q, <shape(s)>, loc=0)\n",
      "     |      inverse survival function (inverse of sf)\n",
      "     |  \n",
      "     |  generic.moment(n, <shape(s)>, loc=0)\n",
      "     |      non-central n-th moment of the distribution.  May not work for array arguments.\n",
      "     |  \n",
      "     |  generic.stats(<shape(s)>, loc=0, moments='mv')\n",
      "     |      mean('m', axis=0), variance('v'), skew('s'), and/or kurtosis('k')\n",
      "     |  \n",
      "     |  generic.entropy(<shape(s)>, loc=0)\n",
      "     |      entropy of the RV\n",
      "     |  \n",
      "     |  generic.expect(func=None, args=(), loc=0, lb=None, ub=None, conditional=False)\n",
      "     |      Expected value of a function with respect to the distribution.\n",
      "     |      Additional kwd arguments passed to integrate.quad\n",
      "     |  \n",
      "     |  generic.median(<shape(s)>, loc=0)\n",
      "     |      Median of the distribution.\n",
      "     |  \n",
      "     |  generic.mean(<shape(s)>, loc=0)\n",
      "     |      Mean of the distribution.\n",
      "     |  \n",
      "     |  generic.std(<shape(s)>, loc=0)\n",
      "     |      Standard deviation of the distribution.\n",
      "     |  \n",
      "     |  generic.var(<shape(s)>, loc=0)\n",
      "     |      Variance of the distribution.\n",
      "     |  \n",
      "     |  generic.interval(alpha, <shape(s)>, loc=0)\n",
      "     |      Interval that with `alpha` percent probability contains a random\n",
      "     |      realization of this distribution.\n",
      "     |  \n",
      "     |  generic(<shape(s)>, loc=0)\n",
      "     |      calling a distribution instance returns a frozen distribution\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  \n",
      "     |  You can construct an arbitrary discrete rv where ``P{X=xk} = pk``\n",
      "     |  by passing to the rv_discrete initialization method (through the\n",
      "     |  values=keyword) a tuple of sequences (xk, pk) which describes only those\n",
      "     |  values of X (xk) that occur with nonzero probability (pk).\n",
      "     |  \n",
      "     |  To create a new discrete distribution, we would do the following::\n",
      "     |  \n",
      "     |      class poisson_gen(rv_discrete):\n",
      "     |          #\"Poisson distribution\"\n",
      "     |          def _pmf(self, k, mu):\n",
      "     |              ...\n",
      "     |  \n",
      "     |  and create an instance::\n",
      "     |  \n",
      "     |      poisson = poisson_gen(name=\"poisson\",\n",
      "     |                            longname='A Poisson')\n",
      "     |  \n",
      "     |  The docstring can be created from a template.\n",
      "     |  \n",
      "     |  Alternatively, the object may be called (as a function) to fix the shape\n",
      "     |  and location parameters returning a \"frozen\" discrete RV object::\n",
      "     |  \n",
      "     |      myrv = generic(<shape(s)>, loc=0)\n",
      "     |          - frozen RV object with the same methods but holding the given\n",
      "     |            shape and location fixed.\n",
      "     |  \n",
      "     |  A note on ``shapes``: subclasses need not specify them explicitly. In this\n",
      "     |  case, the `shapes` will be automatically deduced from the signatures of the\n",
      "     |  overridden methods.\n",
      "     |  If, for some reason, you prefer to avoid relying on introspection, you can\n",
      "     |  specify ``shapes`` explicitly as an argument to the instance constructor.\n",
      "     |  \n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  \n",
      "     |  Custom made discrete distribution:\n",
      "     |  \n",
      "     |  >>> import matplotlib.pyplot as plt\n",
      "     |  >>> from scipy import stats\n",
      "     |  >>> xk = np.arange(7)\n",
      "     |  >>> pk = (0.1, 0.2, 0.3, 0.1, 0.1, 0.1, 0.1)\n",
      "     |  >>> custm = stats.rv_discrete(name='custm', values=(xk, pk))\n",
      "     |  >>> h = plt.plot(xk, custm.pmf(xk))\n",
      "     |  \n",
      "     |  Random number generation:\n",
      "     |  \n",
      "     |  >>> R = custm.rvs(size=100)\n",
      "     |  \n",
      "     |  Display frozen pmf:\n",
      "     |  \n",
      "     |  >>> numargs = generic.numargs\n",
      "     |  >>> [ <shape(s)> ] = ['Replace with resonable value', ]*numargs\n",
      "     |  >>> rv = generic(<shape(s)>)\n",
      "     |  >>> x = np.arange(0, np.min(rv.dist.b, 3)+1)\n",
      "     |  >>> h = plt.plot(x, rv.pmf(x))\n",
      "     |  \n",
      "     |  Here, ``rv.dist.b`` is the right endpoint of the support of ``rv.dist``.\n",
      "     |  \n",
      "     |  Check accuracy of cdf and ppf:\n",
      "     |  \n",
      "     |  >>> prb = generic.cdf(x, <shape(s)>)\n",
      "     |  >>> h = plt.semilogy(np.abs(x-generic.ppf(prb, <shape(s)>))+1e-20)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      rv_discrete\n",
      "     |      rv_generic\n",
      "     |      __builtin__.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, *args, **kwds)\n",
      "     |  \n",
      "     |  __init__(self, a=0, b=inf, name=None, badvalue=None, moment_tol=1e-08, values=None, inc=1, longname=None, shapes=None, extradoc=None)\n",
      "     |  \n",
      "     |  cdf(self, k, *args, **kwds)\n",
      "     |      Cumulative distribution function of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      k : array_like, int\n",
      "     |          Quantiles.\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter (default=0).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cdf : ndarray\n",
      "     |          Cumulative distribution function evaluated at `k`.\n",
      "     |  \n",
      "     |  entropy(self, *args, **kwds)\n",
      "     |  \n",
      "     |  expect(self, func=None, args=(), loc=0, lb=None, ub=None, conditional=False)\n",
      "     |      Calculate expected value of a function with respect to the distribution\n",
      "     |      for discrete distribution\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn : function (default: identity mapping)\n",
      "     |          Function for which sum is calculated. Takes only one argument.\n",
      "     |      args : tuple\n",
      "     |          argument (parameters) of the distribution\n",
      "     |      lb, ub : numbers, optional\n",
      "     |          lower and upper bound for integration, default is set to the support\n",
      "     |          of the distribution, lb and ub are inclusive (ul<=k<=ub)\n",
      "     |      conditional : bool, optional\n",
      "     |          Default is False.\n",
      "     |          If true then the expectation is corrected by the conditional\n",
      "     |          probability of the integration interval. The return value is the\n",
      "     |          expectation of the function, conditional on being in the given\n",
      "     |          interval (k such that ul<=k<=ub).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      expect : float\n",
      "     |          Expected value.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      * function is not vectorized\n",
      "     |      * accuracy: uses self.moment_tol as stopping criterium\n",
      "     |        for heavy tailed distribution e.g. zipf(4), accuracy for\n",
      "     |        mean, variance in example is only 1e-5,\n",
      "     |        increasing precision (moment_tol) makes zipf very slow\n",
      "     |      * suppnmin=100 internal parameter for minimum number of points to evaluate\n",
      "     |        could be added as keyword parameter, to evaluate functions with\n",
      "     |        non-monotonic shapes, points include integers in (-suppnmin, suppnmin)\n",
      "     |      * uses maxcount=1000 limits the number of points that are evaluated\n",
      "     |        to break loop for infinite sums\n",
      "     |        (a maximum of suppnmin+1000 positive plus suppnmin+1000 negative\n",
      "     |        integers are evaluated)\n",
      "     |  \n",
      "     |  freeze(self, *args, **kwds)\n",
      "     |  \n",
      "     |  isf(self, q, *args, **kwds)\n",
      "     |      Inverse survival function (1-sf) at q of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      q : array_like\n",
      "     |          Upper tail probability.\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter (default=0).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      k : ndarray or scalar\n",
      "     |          Quantile corresponding to the upper tail probability, q.\n",
      "     |  \n",
      "     |  logcdf(self, k, *args, **kwds)\n",
      "     |      Log of the cumulative distribution function at k of the given RV\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      k : array_like, int\n",
      "     |          Quantiles.\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter (default=0).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      logcdf : array_like\n",
      "     |          Log of the cumulative distribution function evaluated at k.\n",
      "     |  \n",
      "     |  logpmf(self, k, *args, **kwds)\n",
      "     |      Log of the probability mass function at k of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      k : array_like\n",
      "     |          Quantiles.\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter. Default is 0.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      logpmf : array_like\n",
      "     |          Log of the probability mass function evaluated at k.\n",
      "     |  \n",
      "     |  logsf(self, k, *args, **kwds)\n",
      "     |      Log of the survival function of the given RV.\n",
      "     |      \n",
      "     |      Returns the log of the \"survival function,\" defined as ``1 - cdf``,\n",
      "     |      evaluated at `k`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      k : array_like\n",
      "     |          Quantiles.\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter (default=0).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sf : ndarray\n",
      "     |          Survival function evaluated at `k`.\n",
      "     |  \n",
      "     |  moment(self, n, *args, **kwds)\n",
      "     |      n'th non-central moment of the distribution\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int, n>=1\n",
      "     |          order of moment\n",
      "     |      arg1, arg2, arg3,... : float\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : float, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : float, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |  \n",
      "     |  pmf(self, k, *args, **kwds)\n",
      "     |      Probability mass function at k of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      k : array_like\n",
      "     |          quantiles\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter (default=0).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      pmf : array_like\n",
      "     |          Probability mass function evaluated at k\n",
      "     |  \n",
      "     |  ppf(self, q, *args, **kwds)\n",
      "     |      Percent point function (inverse of cdf) at q of the given RV\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      q : array_like\n",
      "     |          Lower tail probability.\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter (default=0).\n",
      "     |      scale : array_like, optional\n",
      "     |          Scale parameter (default=1).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      k : array_like\n",
      "     |          Quantile corresponding to the lower tail probability, q.\n",
      "     |  \n",
      "     |  rvs(self, *args, **kwargs)\n",
      "     |      Random variates of given type.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter (default=0).\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Defining number of random variates (default=1).  Note that `size`\n",
      "     |          has to be given as keyword, not as positional argument.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      rvs : ndarray or scalar\n",
      "     |          Random variates of given `size`.\n",
      "     |  \n",
      "     |  sf(self, k, *args, **kwds)\n",
      "     |      Survival function (1-cdf) at k of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      k : array_like\n",
      "     |          Quantiles.\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter (default=0).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sf : array_like\n",
      "     |          Survival function evaluated at k.\n",
      "     |  \n",
      "     |  stats(self, *args, **kwds)\n",
      "     |      Some statistics of the given discrete RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter (default=0).\n",
      "     |      moments : string, optional\n",
      "     |          Composed of letters ['mvsk'] defining which moments to compute:\n",
      "     |      \n",
      "     |            - 'm' = mean,\n",
      "     |            - 'v' = variance,\n",
      "     |            - 's' = (Fisher's) skew,\n",
      "     |            - 'k' = (Fisher's) kurtosis.\n",
      "     |      \n",
      "     |          The default is'mv'.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      stats : sequence\n",
      "     |          of requested moments.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from rv_generic:\n",
      "     |  \n",
      "     |  interval(self, alpha, *args, **kwds)\n",
      "     |      Confidence interval with equal areas around the median.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      alpha : array_like of float\n",
      "     |          Probability that an rv will be drawn from the returned range.\n",
      "     |          Each value should be in the range [0, 1].\n",
      "     |      arg1, arg2, ... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter, Default is 0.\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter, Default is 1.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a, b : ndarray of float\n",
      "     |          end-points of range that contain ``100 * alpha %`` of the rv's possible\n",
      "     |          values.\n",
      "     |  \n",
      "     |  mean(self, *args, **kwds)\n",
      "     |      Mean of the distribution\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      mean : float\n",
      "     |          the mean of the distribution\n",
      "     |  \n",
      "     |  median(self, *args, **kwds)\n",
      "     |      Median of the distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter, Default is 0.\n",
      "     |      scale : array_like, optional\n",
      "     |          Scale parameter, Default is 1.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      median : float\n",
      "     |          The median of the distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      stats.distributions.rv_discrete.ppf\n",
      "     |          Inverse of the CDF\n",
      "     |  \n",
      "     |  std(self, *args, **kwds)\n",
      "     |      Standard deviation of the distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      std : float\n",
      "     |          standard deviation of the distribution\n",
      "     |  \n",
      "     |  var(self, *args, **kwds)\n",
      "     |      Variance of the distribution\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      var : float\n",
      "     |          the variance of the distribution\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from rv_generic:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    anderson(x, dist='norm')\n",
      "        Anderson-Darling test for data coming from a particular distribution\n",
      "        \n",
      "        The Anderson-Darling test is a modification of the Kolmogorov-\n",
      "        Smirnov test kstest_ for the null hypothesis that a sample is\n",
      "        drawn from a population that follows a particular distribution.\n",
      "        For the Anderson-Darling test, the critical values depend on\n",
      "        which distribution is being tested against.  This function works\n",
      "        for normal, exponential, logistic, or Gumbel (Extreme Value\n",
      "        Type I) distributions.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            array of sample data\n",
      "        dist : {'norm','expon','logistic','gumbel','extreme1'}, optional\n",
      "            the type of distribution to test against.  The default is 'norm'\n",
      "            and 'extreme1' is a synonym for 'gumbel'\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        A2 : float\n",
      "            The Anderson-Darling test statistic\n",
      "        critical : list\n",
      "            The critical values for this distribution\n",
      "        sig : list\n",
      "            The significance levels for the corresponding critical values\n",
      "            in percents.  The function returns critical values for a\n",
      "            differing set of significance levels depending on the\n",
      "            distribution that is being tested against.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Critical values provided are for the following significance levels:\n",
      "        \n",
      "        normal/exponenential\n",
      "            15%, 10%, 5%, 2.5%, 1%\n",
      "        logistic\n",
      "            25%, 10%, 5%, 2.5%, 1%, 0.5%\n",
      "        Gumbel\n",
      "            25%, 10%, 5%, 2.5%, 1%\n",
      "        \n",
      "        If A2 is larger than these critical values then for the corresponding\n",
      "        significance level, the null hypothesis that the data come from the\n",
      "        chosen distribution can be rejected.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] http://www.itl.nist.gov/div898/handbook/prc/section2/prc213.htm\n",
      "        .. [2] Stephens, M. A. (1974). EDF Statistics for Goodness of Fit and\n",
      "               Some Comparisons, Journal of the American Statistical Association,\n",
      "               Vol. 69, pp. 730-737.\n",
      "        .. [3] Stephens, M. A. (1976). Asymptotic Results for Goodness-of-Fit\n",
      "               Statistics with Unknown Parameters, Annals of Statistics, Vol. 4,\n",
      "               pp. 357-369.\n",
      "        .. [4] Stephens, M. A. (1977). Goodness of Fit for the Extreme Value\n",
      "               Distribution, Biometrika, Vol. 64, pp. 583-588.\n",
      "        .. [5] Stephens, M. A. (1977). Goodness of Fit with Special Reference\n",
      "               to Tests for Exponentiality , Technical Report No. 262,\n",
      "               Department of Statistics, Stanford University, Stanford, CA.\n",
      "        .. [6] Stephens, M. A. (1979). Tests of Fit for the Logistic Distribution\n",
      "               Based on the Empirical Distribution Function, Biometrika, Vol. 66,\n",
      "               pp. 591-595.\n",
      "    \n",
      "    ansari(x, y)\n",
      "        Perform the Ansari-Bradley test for equal scale parameters\n",
      "        \n",
      "        The Ansari-Bradley test is a non-parametric test for the equality\n",
      "        of the scale parameter of the distributions from which two\n",
      "        samples were drawn.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x, y : array_like\n",
      "            arrays of sample data\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        AB : float\n",
      "            The Ansari-Bradley test statistic\n",
      "        p-value : float\n",
      "            The p-value of the hypothesis test\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        fligner : A non-parametric test for the equality of k variances\n",
      "        mood : A non-parametric test for the equality of two scale parameters\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The p-value given is exact when the sample sizes are both less than\n",
      "        55 and there are no ties, otherwise a normal approximation for the\n",
      "        p-value is used.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Sprent, Peter and N.C. Smeeton.  Applied nonparametric statistical\n",
      "               methods.  3rd ed. Chapman and Hall/CRC. 2001.  Section 5.8.2.\n",
      "    \n",
      "    bartlett(*args)\n",
      "        Perform Bartlett's test for equal variances\n",
      "        \n",
      "        Bartlett's test tests the null hypothesis that all input samples\n",
      "        are from populations with equal variances.  For samples\n",
      "        from significantly non-normal populations, Levene's test\n",
      "        `levene`_ is more robust.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        sample1, sample2,... : array_like\n",
      "            arrays of sample data.  May be different lengths.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        T : float\n",
      "            The test statistic.\n",
      "        p-value : float\n",
      "            The p-value of the test.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1]  http://www.itl.nist.gov/div898/handbook/eda/section3/eda357.htm\n",
      "        \n",
      "        .. [2]  Snedecor, George W. and Cochran, William G. (1989), Statistical\n",
      "                  Methods, Eighth Edition, Iowa State University Press.\n",
      "    \n",
      "    bayes_mvs(data, alpha=0.9)\n",
      "        Bayesian confidence intervals for the mean, var, and std.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data : array_like\n",
      "            Input data, if multi-dimensional it is flattened to 1-D by `bayes_mvs`.\n",
      "            Requires 2 or more data points.\n",
      "        alpha : float, optional\n",
      "            Probability that the returned confidence interval contains\n",
      "            the true parameter.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        mean_cntr, var_cntr, std_cntr : tuple\n",
      "            The three results are for the mean, variance and standard deviation,\n",
      "            respectively.  Each result is a tuple of the form::\n",
      "        \n",
      "                (center, (lower, upper))\n",
      "        \n",
      "            with `center` the mean of the conditional pdf of the value given the\n",
      "            data, and `(lower, upper)` a confidence interval, centered on the\n",
      "            median, containing the estimate to a probability `alpha`.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Each tuple of mean, variance, and standard deviation estimates represent\n",
      "        the (center, (lower, upper)) with center the mean of the conditional pdf\n",
      "        of the value given the data and (lower, upper) is a confidence interval\n",
      "        centered on the median, containing the estimate to a probability\n",
      "        `alpha`.\n",
      "        \n",
      "        Converts data to 1-D and assumes all data has the same mean and variance.\n",
      "        Uses Jeffrey's prior for variance and std.\n",
      "        \n",
      "        Equivalent to tuple((x.mean(), x.interval(alpha)) for x in mvsdist(dat))\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        T.E. Oliphant, \"A Bayesian perspective on estimating mean, variance, and\n",
      "        standard-deviation from data\", http://hdl.handle.net/1877/438, 2006.\n",
      "    \n",
      "    betai(a, b, x)\n",
      "        Returns the incomplete beta function.\n",
      "        \n",
      "        I_x(a,b) = 1/B(a,b)*(Integral(0,x) of t^(a-1)(1-t)^(b-1) dt)\n",
      "        \n",
      "        where a,b>0 and B(a,b) = G(a)*G(b)/(G(a+b)) where G(a) is the gamma\n",
      "        function of a.\n",
      "        \n",
      "        The standard broadcasting rules apply to a, b, and x.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like or float > 0\n",
      "        \n",
      "        b : array_like or float > 0\n",
      "        \n",
      "        x : array_like or float\n",
      "            x will be clipped to be no greater than 1.0 .\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        betai : ndarray\n",
      "            Incomplete beta function.\n",
      "    \n",
      "    binned_statistic(x, values, statistic='mean', bins=10, range=None)\n",
      "        Compute a binned statistic for a set of data.\n",
      "        \n",
      "        This is a generalization of a histogram function.  A histogram divides\n",
      "        the space into bins, and returns the count of the number of points in\n",
      "        each bin.  This function allows the computation of the sum, mean, median,\n",
      "        or other statistic of the values within each bin.\n",
      "        \n",
      "        .. versionadded:: 0.11.0\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            A sequence of values to be binned.\n",
      "        values : array_like\n",
      "            The values on which the statistic will be computed.  This must be\n",
      "            the same shape as `x`.\n",
      "        statistic : string or callable, optional\n",
      "            The statistic to compute (default is 'mean').\n",
      "            The following statistics are available:\n",
      "        \n",
      "              * 'mean' : compute the mean of values for points within each bin.\n",
      "                Empty bins will be represented by NaN.\n",
      "              * 'median' : compute the median of values for points within each\n",
      "                bin. Empty bins will be represented by NaN.\n",
      "              * 'count' : compute the count of points within each bin.  This is\n",
      "                identical to an unweighted histogram.  `values` array is not\n",
      "                referenced.\n",
      "              * 'sum' : compute the sum of values for points within each bin.\n",
      "                This is identical to a weighted histogram.\n",
      "              * function : a user-defined function which takes a 1D array of\n",
      "                values, and outputs a single numerical statistic. This function\n",
      "                will be called on the values in each bin.  Empty bins will be\n",
      "                represented by function([]), or NaN if this returns an error.\n",
      "        \n",
      "        bins : int or sequence of scalars, optional\n",
      "            If `bins` is an int, it defines the number of equal-width\n",
      "            bins in the given range (10, by default). If `bins` is a sequence,\n",
      "            it defines the bin edges, including the rightmost edge, allowing\n",
      "            for non-uniform bin widths.\n",
      "        range : (float, float), optional\n",
      "            The lower and upper range of the bins.  If not provided, range\n",
      "            is simply ``(x.min(), x.max())``.  Values outside the range are\n",
      "            ignored.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : array\n",
      "            The values of the selected statistic in each bin.\n",
      "        bin_edges : array of dtype float\n",
      "            Return the bin edges ``(length(statistic)+1)``.\n",
      "        binnumber : 1-D ndarray of ints\n",
      "            This assigns to each observation an integer that represents the bin\n",
      "            in which this observation falls. Array has the same length as values.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        numpy.histogram, binned_statistic_2d, binned_statistic_dd\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        All but the last (righthand-most) bin is half-open.  In other words, if\n",
      "        `bins` is::\n",
      "        \n",
      "          [1, 2, 3, 4]\n",
      "        \n",
      "        then the first bin is ``[1, 2)`` (including 1, but excluding 2) and the\n",
      "        second ``[2, 3)``.  The last bin, however, is ``[3, 4]``, which *includes*\n",
      "        4.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> stats.binned_statistic([1, 2, 1, 2, 4], np.arange(5), statistic='mean',\n",
      "        ... bins=3)\n",
      "        (array([ 1.,  2.,  4.]), array([ 1.,  2.,  3.,  4.]), array([1, 2, 1, 2, 3]))\n",
      "        \n",
      "        >>> stats.binned_statistic([1, 2, 1, 2, 4], np.arange(5), statistic='mean', bins=3)\n",
      "        (array([ 1.,  2.,  4.]), array([ 1.,  2.,  3.,  4.]), array([1, 2, 1, 2, 3]))\n",
      "    \n",
      "    binned_statistic_2d(x, y, values, statistic='mean', bins=10, range=None)\n",
      "        Compute a bidimensional binned statistic for a set of data.\n",
      "        \n",
      "        This is a generalization of a histogram2d function.  A histogram divides\n",
      "        the space into bins, and returns the count of the number of points in\n",
      "        each bin.  This function allows the computation of the sum, mean, median,\n",
      "        or other statistic of the values within each bin.\n",
      "        \n",
      "        .. versionadded:: 0.11.0\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : (N,) array_like\n",
      "            A sequence of values to be binned along the first dimension.\n",
      "        y : (M,) array_like\n",
      "            A sequence of values to be binned along the second dimension.\n",
      "        values : (N,) array_like\n",
      "            The values on which the statistic will be computed.  This must be\n",
      "            the same shape as `x`.\n",
      "        statistic : string or callable, optional\n",
      "            The statistic to compute (default is 'mean').\n",
      "            The following statistics are available:\n",
      "        \n",
      "              * 'mean' : compute the mean of values for points within each bin.\n",
      "                Empty bins will be represented by NaN.\n",
      "              * 'median' : compute the median of values for points within each\n",
      "                bin. Empty bins will be represented by NaN.\n",
      "              * 'count' : compute the count of points within each bin.  This is\n",
      "                identical to an unweighted histogram.  `values` array is not\n",
      "                referenced.\n",
      "              * 'sum' : compute the sum of values for points within each bin.\n",
      "                This is identical to a weighted histogram.\n",
      "              * function : a user-defined function which takes a 1D array of\n",
      "                values, and outputs a single numerical statistic. This function\n",
      "                will be called on the values in each bin.  Empty bins will be\n",
      "                represented by function([]), or NaN if this returns an error.\n",
      "        \n",
      "        bins : int or [int, int] or array-like or [array, array], optional\n",
      "            The bin specification:\n",
      "        \n",
      "              * the number of bins for the two dimensions (nx=ny=bins),\n",
      "              * the number of bins in each dimension (nx, ny = bins),\n",
      "              * the bin edges for the two dimensions (x_edges = y_edges = bins),\n",
      "              * the bin edges in each dimension (x_edges, y_edges = bins).\n",
      "        \n",
      "        range : (2,2) array_like, optional\n",
      "            The leftmost and rightmost edges of the bins along each dimension\n",
      "            (if not specified explicitly in the `bins` parameters):\n",
      "            [[xmin, xmax], [ymin, ymax]]. All values outside of this range will be\n",
      "            considered outliers and not tallied in the histogram.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : (nx, ny) ndarray\n",
      "            The values of the selected statistic in each two-dimensional bin\n",
      "        xedges : (nx + 1) ndarray\n",
      "            The bin edges along the first dimension.\n",
      "        yedges : (ny + 1) ndarray\n",
      "            The bin edges along the second dimension.\n",
      "        binnumber : 1-D ndarray of ints\n",
      "            This assigns to each observation an integer that represents the bin\n",
      "            in which this observation falls. Array has the same length as `values`.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        numpy.histogram2d, binned_statistic, binned_statistic_dd\n",
      "    \n",
      "    binned_statistic_dd(sample, values, statistic='mean', bins=10, range=None)\n",
      "        Compute a multidimensional binned statistic for a set of data.\n",
      "        \n",
      "        This is a generalization of a histogramdd function.  A histogram divides\n",
      "        the space into bins, and returns the count of the number of points in\n",
      "        each bin.  This function allows the computation of the sum, mean, median,\n",
      "        or other statistic of the values within each bin.\n",
      "        \n",
      "        .. versionadded:: 0.11.0\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        sample : array_like\n",
      "            Data to histogram passed as a sequence of D arrays of length N, or\n",
      "            as an (N,D) array.\n",
      "        values : array_like\n",
      "            The values on which the statistic will be computed.  This must be\n",
      "            the same shape as x.\n",
      "        statistic : string or callable, optional\n",
      "            The statistic to compute (default is 'mean').\n",
      "            The following statistics are available:\n",
      "        \n",
      "              * 'mean' : compute the mean of values for points within each bin.\n",
      "                Empty bins will be represented by NaN.\n",
      "              * 'median' : compute the median of values for points within each\n",
      "                bin. Empty bins will be represented by NaN.\n",
      "              * 'count' : compute the count of points within each bin.  This is\n",
      "                identical to an unweighted histogram.  `values` array is not\n",
      "                referenced.\n",
      "              * 'sum' : compute the sum of values for points within each bin.\n",
      "                This is identical to a weighted histogram.\n",
      "              * function : a user-defined function which takes a 1D array of\n",
      "                values, and outputs a single numerical statistic. This function\n",
      "                will be called on the values in each bin.  Empty bins will be\n",
      "                represented by function([]), or NaN if this returns an error.\n",
      "        \n",
      "        bins : sequence or int, optional\n",
      "            The bin specification:\n",
      "        \n",
      "              * A sequence of arrays describing the bin edges along each dimension.\n",
      "              * The number of bins for each dimension (nx, ny, ... =bins)\n",
      "              * The number of bins for all dimensions (nx=ny=...=bins).\n",
      "        \n",
      "        range : sequence, optional\n",
      "            A sequence of lower and upper bin edges to be used if the edges are\n",
      "            not given explicitely in `bins`. Defaults to the minimum and maximum\n",
      "            values along each dimension.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : ndarray, shape(nx1, nx2, nx3,...)\n",
      "            The values of the selected statistic in each two-dimensional bin\n",
      "        edges : list of ndarrays\n",
      "            A list of D arrays describing the (nxi + 1) bin edges for each\n",
      "            dimension\n",
      "        binnumber : 1-D ndarray of ints\n",
      "            This assigns to each observation an integer that represents the bin\n",
      "            in which this observation falls. Array has the same length as values.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        np.histogramdd, binned_statistic, binned_statistic_2d\n",
      "    \n",
      "    binom_test(x, n=None, p=0.5)\n",
      "        Perform a test that the probability of success is p.\n",
      "        \n",
      "        This is an exact, two-sided test of the null hypothesis\n",
      "        that the probability of success in a Bernoulli experiment\n",
      "        is `p`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : integer or array_like\n",
      "            the number of successes, or if x has length 2, it is the\n",
      "            number of successes and the number of failures.\n",
      "        n : integer\n",
      "            the number of trials.  This is ignored if x gives both the\n",
      "            number of successes and failures\n",
      "        p : float, optional\n",
      "            The hypothesized probability of success.  0 <= p <= 1. The\n",
      "            default value is p = 0.5\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        p-value : float\n",
      "            The p-value of the hypothesis test\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] http://en.wikipedia.org/wiki/Binomial_test\n",
      "    \n",
      "    boxcox(x, lmbda=None, alpha=None)\n",
      "        Return a positive dataset transformed by a Box-Cox power transformation.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : ndarray\n",
      "            Input array.\n",
      "        lmbda : {None, scalar}, optional\n",
      "            If `lmbda` is not None, do the transformation for that value.\n",
      "        \n",
      "            If `lmbda` is None, find the lambda that maximizes the log-likelihood\n",
      "            function and return it as the second output argument.\n",
      "        alpha : {None, float}, optional\n",
      "            If `alpha` is not None, return the ``100 * (1-alpha)%`` confidence\n",
      "            interval for `lmbda` as the third output argument.\n",
      "        \n",
      "            If `alpha` is not None it must be between 0.0 and 1.0.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        boxcox : ndarray\n",
      "            Box-Cox power transformed array.\n",
      "        maxlog : float, optional\n",
      "            If the `lmbda` parameter is None, the second returned argument is\n",
      "            the lambda that maximizes the log-likelihood function.\n",
      "        (min_ci, max_ci) : tuple of float, optional\n",
      "            If `lmbda` parameter is None and `alpha` is not None, this returned\n",
      "            tuple of floats represents the minimum and maximum confidence limits\n",
      "            given `alpha`.\n",
      "    \n",
      "    boxcox_llf(lmb, data)\n",
      "        The boxcox log-likelihood function.\n",
      "    \n",
      "    boxcox_normmax(x, brack=(-1.0, 1.0))\n",
      "    \n",
      "    boxcox_normplot(x, la, lb, plot=None, N=80)\n",
      "    \n",
      "    callable(...)\n",
      "        callable(object) -> bool\n",
      "        \n",
      "        Return whether the object is callable (i.e., some kind of function).\n",
      "        Note that classes are callable, as are instances with a __call__() method.\n",
      "    \n",
      "    chi2_contingency(observed, correction=True, lambda_=None)\n",
      "        Chi-square test of independence of variables in a contingency table.\n",
      "        \n",
      "        This function computes the chi-square statistic and p-value for the\n",
      "        hypothesis test of independence of the observed frequencies in the\n",
      "        contingency table [1]_ `observed`.  The expected frequencies are computed\n",
      "        based on the marginal sums under the assumption of independence; see\n",
      "        `scipy.stats.contingency.expected_freq`.  The number of degrees of\n",
      "        freedom is (expressed using numpy functions and attributes)::\n",
      "        \n",
      "            dof = observed.size - sum(observed.shape) + observed.ndim - 1\n",
      "        \n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        observed : array_like\n",
      "            The contingency table. The table contains the observed frequencies\n",
      "            (i.e. number of occurrences) in each category.  In the two-dimensional\n",
      "            case, the table is often described as an \"R x C table\".\n",
      "        correction : bool, optional\n",
      "            If True, *and* the degrees of freedom is 1, apply Yates' correction\n",
      "            for continuity.  The effect of the correction is to adjust each\n",
      "            observed value by 0.5 towards the corresponding expected value.\n",
      "        lambda_ : float or str, optional.\n",
      "            By default, the statistic computed in this test is Pearson's\n",
      "            chi-squared statistic [2]_.  `lambda_` allows a statistic from the\n",
      "            Cressie-Read power divergence family [3]_ to be used instead.  See\n",
      "            `power_divergence` for details.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        chi2 : float\n",
      "            The test statistic.\n",
      "        p : float\n",
      "            The p-value of the test\n",
      "        dof : int\n",
      "            Degrees of freedom\n",
      "        expected : ndarray, same shape as `observed`\n",
      "            The expected frequencies, based on the marginal sums of the table.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        contingency.expected_freq\n",
      "        fisher_exact\n",
      "        chisquare\n",
      "        power_divergence\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        An often quoted guideline for the validity of this calculation is that\n",
      "        the test should be used only if the observed and expected frequency in\n",
      "        each cell is at least 5.\n",
      "        \n",
      "        This is a test for the independence of different categories of a\n",
      "        population. The test is only meaningful when the dimension of\n",
      "        `observed` is two or more.  Applying the test to a one-dimensional\n",
      "        table will always result in `expected` equal to `observed` and a\n",
      "        chi-square statistic equal to 0.\n",
      "        \n",
      "        This function does not handle masked arrays, because the calculation\n",
      "        does not make sense with missing values.\n",
      "        \n",
      "        Like stats.chisquare, this function computes a chi-square statistic;\n",
      "        the convenience this function provides is to figure out the expected\n",
      "        frequencies and degrees of freedom from the given contingency table.\n",
      "        If these were already known, and if the Yates' correction was not\n",
      "        required, one could use stats.chisquare.  That is, if one calls::\n",
      "        \n",
      "            chi2, p, dof, ex = chi2_contingency(obs, correction=False)\n",
      "        \n",
      "        then the following is true::\n",
      "        \n",
      "            (chi2, p) == stats.chisquare(obs.ravel(), f_exp=ex.ravel(),\n",
      "                                         ddof=obs.size - 1 - dof)\n",
      "        \n",
      "        The `lambda_` argument was added in version 0.13.0 of scipy.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] \"Contingency table\", http://en.wikipedia.org/wiki/Contingency_table\n",
      "        .. [2] \"Pearson's chi-squared test\",\n",
      "               http://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test\n",
      "        .. [3] Cressie, N. and Read, T. R. C., \"Multinomial Goodness-of-Fit\n",
      "               Tests\", J. Royal Stat. Soc. Series B, Vol. 46, No. 3 (1984),\n",
      "               pp. 440-464.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        A two-way example (2 x 3):\n",
      "        \n",
      "        >>> obs = np.array([[10, 10, 20], [20, 20, 20]])\n",
      "        >>> chi2_contingency(obs)\n",
      "        (2.7777777777777777,\n",
      "         0.24935220877729619,\n",
      "         2,\n",
      "         array([[ 12.,  12.,  16.],\n",
      "                [ 18.,  18.,  24.]]))\n",
      "        \n",
      "        Perform the test using the log-likelihood ratio (i.e. the \"G-test\")\n",
      "        instead of Pearson's chi-squared statistic.\n",
      "        \n",
      "        >>> g, p, dof, expctd = chi2_contingency(obs, lambda_=\"log-likelihood\")\n",
      "        >>> g, p\n",
      "        (2.7688587616781319, 0.25046668010954165)\n",
      "        \n",
      "        A four-way example (2 x 2 x 2 x 2):\n",
      "        \n",
      "        >>> obs = np.array(\n",
      "        ...     [[[[12, 17],\n",
      "        ...        [11, 16]],\n",
      "        ...       [[11, 12],\n",
      "        ...        [15, 16]]],\n",
      "        ...      [[[23, 15],\n",
      "        ...        [30, 22]],\n",
      "        ...       [[14, 17],\n",
      "        ...        [15, 16]]]])\n",
      "        >>> chi2_contingency(obs)\n",
      "        (8.7584514426741897,\n",
      "         0.64417725029295503,\n",
      "         11,\n",
      "         array([[[[ 14.15462386,  14.15462386],\n",
      "                  [ 16.49423111,  16.49423111]],\n",
      "                 [[ 11.2461395 ,  11.2461395 ],\n",
      "                  [ 13.10500554,  13.10500554]]],\n",
      "                [[[ 19.5591166 ,  19.5591166 ],\n",
      "                  [ 22.79202844,  22.79202844]],\n",
      "                 [[ 15.54012004,  15.54012004],\n",
      "                  [ 18.10873492,  18.10873492]]]]))\n",
      "    \n",
      "    chisqprob(chisq, df)\n",
      "        Probability value (1-tail) for the Chi^2 probability distribution.\n",
      "        \n",
      "        Broadcasting rules apply.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        chisq : array_like or float > 0\n",
      "        \n",
      "        df : array_like or float, probably int >= 1\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        chisqprob : ndarray\n",
      "            The area from `chisq` to infinity under the Chi^2 probability\n",
      "            distribution with degrees of freedom `df`.\n",
      "    \n",
      "    chisquare(f_obs, f_exp=None, ddof=0, axis=0)\n",
      "        Calculates a one-way chi square test.\n",
      "        \n",
      "        The chi square test tests the null hypothesis that the categorical data\n",
      "        has the given frequencies.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        f_obs : array\n",
      "            Observed frequencies in each category.\n",
      "        f_exp : array, optional\n",
      "            Expected frequencies in each category.  By default the categories are\n",
      "            assumed to be equally likely.\n",
      "        ddof : int, optional\n",
      "            \"Delta degrees of freedom\": adjustment to the degrees of freedom\n",
      "            for the p-value.  The p-value is computed using a chi-squared\n",
      "            distribution with ``k - 1 - ddof`` degrees of freedom, where `k`\n",
      "            is the number of observed frequencies.  The default value of `ddof`\n",
      "            is 0.\n",
      "        axis : int or None, optional\n",
      "            The axis of the broadcast result of `f_obs` and `f_exp` along which to\n",
      "            apply the test.  If axis is None, all values in `f_obs` are treated\n",
      "            as a single data set.  Default is 0.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        chisq : float or ndarray\n",
      "            The chi-squared test statistic.  The value is a float if `axis` is\n",
      "            None or `f_obs` and `f_exp` are 1-D.\n",
      "        p : float or ndarray\n",
      "            The p-value of the test.  The value is a float if `ddof` and the\n",
      "            return value `chisq` are scalars.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        power_divergence\n",
      "        mstats.chisquare\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This test is invalid when the observed or expected frequencies in each\n",
      "        category are too small.  A typical rule is that all of the observed\n",
      "        and expected frequencies should be at least 5.\n",
      "        \n",
      "        The default degrees of freedom, k-1, are for the case when no parameters\n",
      "        of the distribution are estimated. If p parameters are estimated by\n",
      "        efficient maximum likelihood then the correct degrees of freedom are\n",
      "        k-1-p. If the parameters are estimated in a different way, then the\n",
      "        dof can be between k-1-p and k-1. However, it is also possible that\n",
      "        the asymptotic distribution is not a chisquare, in which case this\n",
      "        test is not appropriate.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Lowry, Richard.  \"Concepts and Applications of Inferential\n",
      "               Statistics\". Chapter 8. http://faculty.vassar.edu/lowry/ch8pt1.html\n",
      "        .. [2] \"Chi-squared test\", http://en.wikipedia.org/wiki/Chi-squared_test\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        When just `f_obs` is given, it is assumed that the expected frequencies\n",
      "        are uniform and given by the mean of the observed frequencies.\n",
      "        \n",
      "        >>> chisquare([16, 18, 16, 14, 12, 12])\n",
      "        (2.0, 0.84914503608460956)\n",
      "        \n",
      "        With `f_exp` the expected frequencies can be given.\n",
      "        \n",
      "        >>> chisquare([16, 18, 16, 14, 12, 12], f_exp=[16, 16, 16, 16, 16, 8])\n",
      "        (3.5, 0.62338762774958223)\n",
      "        \n",
      "        When `f_obs` is 2-D, by default the test is applied to each column.\n",
      "        \n",
      "        >>> obs = np.array([[16, 18, 16, 14, 12, 12], [32, 24, 16, 28, 20, 24]]).T\n",
      "        >>> obs.shape\n",
      "        (6, 2)\n",
      "        >>> chisquare(obs)\n",
      "        (array([ 2.        ,  6.66666667]), array([ 0.84914504,  0.24663415]))\n",
      "        \n",
      "        By setting ``axis=None``, the test is applied to all data in the array,\n",
      "        which is equivalent to applying the test to the flattened array.\n",
      "        \n",
      "        >>> chisquare(obs, axis=None)\n",
      "        (23.31034482758621, 0.015975692534127565)\n",
      "        >>> chisquare(obs.ravel())\n",
      "        (23.31034482758621, 0.015975692534127565)\n",
      "        \n",
      "        `ddof` is the change to make to the default degrees of freedom.\n",
      "        \n",
      "        >>> chisquare([16, 18, 16, 14, 12, 12], ddof=1)\n",
      "        (2.0, 0.73575888234288467)\n",
      "        \n",
      "        The calculation of the p-values is done by broadcasting the\n",
      "        chi-squared statistic with `ddof`.\n",
      "        \n",
      "        >>> chisquare([16, 18, 16, 14, 12, 12], ddof=[0,1,2])\n",
      "        (2.0, array([ 0.84914504,  0.73575888,  0.5724067 ]))\n",
      "        \n",
      "        `f_obs` and `f_exp` are also broadcast.  In the following, `f_obs` has\n",
      "        shape (6,) and `f_exp` has shape (2, 6), so the result of broadcasting\n",
      "        `f_obs` and `f_exp` has shape (2, 6).  To compute the desired chi-squared\n",
      "        statistics, we use ``axis=1``:\n",
      "        \n",
      "        >>> chisquare([16, 18, 16, 14, 12, 12],\n",
      "        ...           f_exp=[[16, 16, 16, 16, 16, 8], [8, 20, 20, 16, 12, 12]],\n",
      "        ...           axis=1)\n",
      "        (array([ 3.5 ,  9.25]), array([ 0.62338763,  0.09949846]))\n",
      "    \n",
      "    circmean(samples, high=6.283185307179586, low=0, axis=None)\n",
      "        Compute the circular mean for samples in a range.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        samples : array_like\n",
      "            Input array.\n",
      "        high : float or int, optional\n",
      "            High boundary for circular mean range.  Default is ``2*pi``.\n",
      "        low : float or int, optional\n",
      "            Low boundary for circular mean range.  Default is 0.\n",
      "        axis : int, optional\n",
      "            Axis along which means are computed.  The default is to compute\n",
      "            the mean of the flattened array.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        circmean : float\n",
      "            Circular mean.\n",
      "    \n",
      "    circstd(samples, high=6.283185307179586, low=0, axis=None)\n",
      "        Compute the circular standard deviation for samples assumed to be in the\n",
      "        range [low to high].\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        samples : array_like\n",
      "            Input array.\n",
      "        low : float or int, optional\n",
      "            Low boundary for circular standard deviation range.  Default is 0.\n",
      "        high : float or int, optional\n",
      "            High boundary for circular standard deviation range.\n",
      "            Default is ``2*pi``.\n",
      "        axis : int, optional\n",
      "            Axis along which standard deviations are computed.  The default is\n",
      "            to compute the standard deviation of the flattened array.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        circstd : float\n",
      "            Circular standard deviation.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This uses a definition of circular standard deviation that in the limit of\n",
      "        small angles returns a number close to the 'linear' standard deviation.\n",
      "    \n",
      "    circvar(samples, high=6.283185307179586, low=0, axis=None)\n",
      "        Compute the circular variance for samples assumed to be in a range\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        samples : array_like\n",
      "            Input array.\n",
      "        low : float or int, optional\n",
      "            Low boundary for circular variance range.  Default is 0.\n",
      "        high : float or int, optional\n",
      "            High boundary for circular variance range.  Default is ``2*pi``.\n",
      "        axis : int, optional\n",
      "            Axis along which variances are computed.  The default is to compute\n",
      "            the variance of the flattened array.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        circvar : float\n",
      "            Circular variance.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This uses a definition of circular variance that in the limit of small\n",
      "        angles returns a number close to the 'linear' variance.\n",
      "    \n",
      "    cmedian(*args, **kwds)\n",
      "        `cmedian` is deprecated!\n",
      "        Deprecated in scipy 0.13.0 - use numpy.median instead.\n",
      "        \n",
      "        \n",
      "            Returns the computed median value of an array.\n",
      "        \n",
      "            All of the values in the input array are used. The input array is first\n",
      "            histogrammed using `numbins` bins. The bin containing the median is\n",
      "            selected by searching for the halfway point in the cumulative histogram.\n",
      "            The median value is then computed by linearly interpolating across that\n",
      "            bin.\n",
      "        \n",
      "            Parameters\n",
      "            ----------\n",
      "            a : array_like\n",
      "                Input array.\n",
      "            numbins : int\n",
      "                The number of bins used to histogram the data. More bins give greater\n",
      "                accuracy to the approximation of the median.\n",
      "        \n",
      "            Returns\n",
      "            -------\n",
      "            cmedian : float\n",
      "                An approximation of the median.\n",
      "        \n",
      "            References\n",
      "            ----------\n",
      "            [CRCProbStat2000]_ Section 2.2.6\n",
      "        \n",
      "            .. [CRCProbStat2000] Zwillinger, D. and Kokoska, S. (2000). CRC Standard\n",
      "               Probability and Statistics Tables and Formulae. Chapman & Hall: New\n",
      "               York. 2000.\n",
      "    \n",
      "    cumfreq(a, numbins=10, defaultreallimits=None, weights=None)\n",
      "        Returns a cumulative frequency histogram, using the histogram function.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Input array.\n",
      "        numbins : int, optional\n",
      "            The number of bins to use for the histogram. Default is 10.\n",
      "        defaultlimits : tuple (lower, upper), optional\n",
      "            The lower and upper values for the range of the histogram.\n",
      "            If no value is given, a range slightly larger than the range of the\n",
      "            values in `a` is used. Specifically ``(a.min() - s, a.max() + s)``,\n",
      "            where ``s = (1/2)(a.max() - a.min()) / (numbins - 1)``.\n",
      "        weights : array_like, optional\n",
      "            The weights for each value in `a`. Default is None, which gives each\n",
      "            value a weight of 1.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        cumfreq : ndarray\n",
      "            Binned values of cumulative frequency.\n",
      "        lowerreallimit : float\n",
      "            Lower real limit\n",
      "        binsize : float\n",
      "            Width of each bin.\n",
      "        extrapoints : int\n",
      "            Extra points.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> x = [1, 4, 2, 1, 3, 1]\n",
      "        >>> cumfreqs, lowlim, binsize, extrapoints = sp.stats.cumfreq(x, numbins=4)\n",
      "        >>> cumfreqs\n",
      "        array([ 3.,  4.,  5.,  6.])\n",
      "        >>> cumfreqs, lowlim, binsize, extrapoints =     ...     sp.stats.cumfreq(x, numbins=4, defaultreallimits=(1.5, 5))\n",
      "        >>> cumfreqs\n",
      "        array([ 1.,  2.,  3.,  3.])\n",
      "        >>> extrapoints\n",
      "        3\n",
      "    \n",
      "    describe(a, axis=0)\n",
      "        Computes several descriptive statistics of the passed array.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "           data\n",
      "        axis : int or None\n",
      "           axis along which statistics are calculated. If axis is None, then data\n",
      "           array is raveled. The default axis is zero.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        size of the data : int\n",
      "           length of data along axis\n",
      "        (min, max): tuple of ndarrays or floats\n",
      "           minimum and maximum value of data array\n",
      "        arithmetic mean : ndarray or float\n",
      "           mean of data along axis\n",
      "        unbiased variance : ndarray or float\n",
      "           variance of the data along axis, denominator is number of observations\n",
      "           minus one.\n",
      "        biased skewness : ndarray or float\n",
      "           skewness, based on moment calculations with denominator equal to the\n",
      "           number of observations, i.e. no degrees of freedom correction\n",
      "        biased kurtosis : ndarray or float\n",
      "           kurtosis (Fisher), the kurtosis is normalized so that it is zero for the\n",
      "           normal distribution. No degrees of freedom or bias correction is used.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        skew\n",
      "        kurtosis\n",
      "    \n",
      "    entropy(pk, qk=None, base=None)\n",
      "        Calculate the entropy of a distribution for given probability values.\n",
      "        \n",
      "        If only probabilities `pk` are given, the entropy is calculated as\n",
      "        ``S = -sum(pk * log(pk), axis=0)``.\n",
      "        \n",
      "        If `qk` is not None, then compute a relative entropy (also known as\n",
      "        Kullback-Leibler divergence or Kullback-Leibler distance)\n",
      "        ``S = sum(pk * log(pk / qk), axis=0)``.\n",
      "        \n",
      "        This routine will normalize `pk` and `qk` if they don't sum to 1.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        pk : sequence\n",
      "            Defines the (discrete) distribution. ``pk[i]`` is the (possibly\n",
      "            unnormalized) probability of event ``i``.\n",
      "        qk : sequence, optional\n",
      "            Sequence against which the relative entropy is computed. Should be in\n",
      "            the same format as `pk`.\n",
      "        base : float, optional\n",
      "            The logarithmic base to use, defaults to ``e`` (natural logarithm).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        S : float\n",
      "            The calculated entropy.\n",
      "    \n",
      "    f_oneway(*args)\n",
      "        Performs a 1-way ANOVA.\n",
      "        \n",
      "        The one-way ANOVA tests the null hypothesis that two or more groups have\n",
      "        the same population mean.  The test is applied to samples from two or\n",
      "        more groups, possibly with differing sizes.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        sample1, sample2, ... : array_like\n",
      "            The sample measurements for each group.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        F-value : float\n",
      "            The computed F-value of the test.\n",
      "        p-value : float\n",
      "            The associated p-value from the F-distribution.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The ANOVA test has important assumptions that must be satisfied in order\n",
      "        for the associated p-value to be valid.\n",
      "        \n",
      "        1. The samples are independent.\n",
      "        2. Each sample is from a normally distributed population.\n",
      "        3. The population standard deviations of the groups are all equal.  This\n",
      "           property is known as homoscedasticity.\n",
      "        \n",
      "        If these assumptions are not true for a given set of data, it may still be\n",
      "        possible to use the Kruskal-Wallis H-test (`scipy.stats.kruskal`) although\n",
      "        with some loss of power.\n",
      "        \n",
      "        The algorithm is from Heiman[2], pp.394-7.\n",
      "        \n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Lowry, Richard.  \"Concepts and Applications of Inferential\n",
      "               Statistics\". Chapter 14.\n",
      "               http://faculty.vassar.edu/lowry/ch14pt1.html\n",
      "        \n",
      "        .. [2] Heiman, G.W.  Research Methods in Statistics. 2002.\n",
      "    \n",
      "    f_value(ER, EF, dfR, dfF)\n",
      "        Returns an F-statistic for a restricted vs. unrestricted model.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        ER : float\n",
      "             `ER` is the sum of squared residuals for the restricted model\n",
      "              or null hypothesis\n",
      "        \n",
      "        EF : float\n",
      "             `EF` is the sum of squared residuals for the unrestricted model\n",
      "              or alternate hypothesis\n",
      "        \n",
      "        dfR : int\n",
      "              `dfR` is the degrees of freedom in the restricted model\n",
      "        \n",
      "        dfF : int\n",
      "              `dfF` is the degrees of freedom in the unrestricted model\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        F-statistic : float\n",
      "    \n",
      "    f_value_multivariate(ER, EF, dfnum, dfden)\n",
      "        Returns a multivariate F-statistic.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        ER : ndarray\n",
      "            Error associated with the null hypothesis (the Restricted model).\n",
      "            From a multivariate F calculation.\n",
      "        EF : ndarray\n",
      "            Error associated with the alternate hypothesis (the Full model)\n",
      "            From a multivariate F calculation.\n",
      "        dfnum : int\n",
      "            Degrees of freedom the Restricted model.\n",
      "        dfden : int\n",
      "            Degrees of freedom associated with the Restricted model.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        fstat : float\n",
      "            The computed F-statistic.\n",
      "    \n",
      "    f_value_wilks_lambda(ER, EF, dfnum, dfden, a, b)\n",
      "        Calculation of Wilks lambda F-statistic for multivarite data, per\n",
      "        Maxwell & Delaney p.657.\n",
      "    \n",
      "    fastsort(a)\n",
      "        Sort an array and provide the argsort.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Input array.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        fastsort : ndarray of type int\n",
      "            sorted indices into the original array\n",
      "    \n",
      "    find_repeats(arr)\n",
      "        Find repeats and repeat counts.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        arr : array_like\n",
      "            Input array\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        find_repeats : tuple\n",
      "            Returns a tuple of two 1-D ndarrays.  The first ndarray are the repeats\n",
      "            as sorted, unique values that are repeated in `arr`.  The second\n",
      "            ndarray are the counts mapped one-to-one of the repeated values\n",
      "            in the first ndarray.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "            >>> sp.stats.find_repeats([2, 1, 2, 3, 2, 2, 5])\n",
      "            (array([ 2. ]), array([ 4 ], dtype=int32)\n",
      "        \n",
      "            >>> sp.stats.find_repeats([[10, 20, 1, 2], [5, 5, 4, 4]])\n",
      "            (array([ 4., 5.]), array([2, 2], dtype=int32))\n",
      "    \n",
      "    fisher_exact(table, alternative='two-sided')\n",
      "        Performs a Fisher exact test on a 2x2 contingency table.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        table : array_like of ints\n",
      "            A 2x2 contingency table.  Elements should be non-negative integers.\n",
      "        alternative : {'two-sided', 'less', 'greater'}, optional\n",
      "            Which alternative hypothesis to the null hypothesis the test uses.\n",
      "            Default is 'two-sided'.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        oddsratio : float\n",
      "            This is prior odds ratio and not a posterior estimate.\n",
      "        p_value : float\n",
      "            P-value, the probability of obtaining a distribution at least as\n",
      "            extreme as the one that was actually observed, assuming that the\n",
      "            null hypothesis is true.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        chi2_contingency : Chi-square test of independence of variables in a\n",
      "            contingency table.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The calculated odds ratio is different from the one R uses. In R language,\n",
      "        this implementation returns the (more common) \"unconditional Maximum\n",
      "        Likelihood Estimate\", while R uses the \"conditional Maximum Likelihood\n",
      "        Estimate\".\n",
      "        \n",
      "        For tables with large numbers the (inexact) chi-square test implemented\n",
      "        in the function `chi2_contingency` can also be used.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Say we spend a few days counting whales and sharks in the Atlantic and\n",
      "        Indian oceans. In the Atlantic ocean we find 8 whales and 1 shark, in the\n",
      "        Indian ocean 2 whales and 5 sharks. Then our contingency table is::\n",
      "        \n",
      "                    Atlantic  Indian\n",
      "            whales     8        2\n",
      "            sharks     1        5\n",
      "        \n",
      "        We use this table to find the p-value:\n",
      "        \n",
      "        >>> oddsratio, pvalue = stats.fisher_exact([[8, 2], [1, 5]])\n",
      "        >>> pvalue\n",
      "        0.0349...\n",
      "        \n",
      "        The probability that we would observe this or an even more imbalanced ratio\n",
      "        by chance is about 3.5%.  A commonly used significance level is 5%, if we\n",
      "        adopt that we can therefore conclude that our observed imbalance is\n",
      "        statistically significant; whales prefer the Atlantic while sharks prefer\n",
      "        the Indian ocean.\n",
      "    \n",
      "    fligner(*args, **kwds)\n",
      "        Perform Fligner's test for equal variances.\n",
      "        \n",
      "        Fligner's test tests the null hypothesis that all input samples\n",
      "        are from populations with equal variances.  Fligner's test is\n",
      "        non-parametric in contrast to Bartlett's test `bartlett` and\n",
      "        Levene's test `levene`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        sample1, sample2, ... : array_like\n",
      "            arrays of sample data.  Need not be the same length\n",
      "        center : {'mean', 'median', 'trimmed'}, optional\n",
      "            keyword argument controlling which function of the data\n",
      "            is used in computing the test statistic.  The default\n",
      "            is 'median'.\n",
      "        proportiontocut : float, optional\n",
      "            When `center` is 'trimmed', this gives the proportion of data points\n",
      "            to cut from each end. (See `scipy.stats.trim_mean`.)\n",
      "            Default is 0.05.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        Xsq : float\n",
      "            the test statistic\n",
      "        p-value : float\n",
      "            the p-value for the hypothesis test\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        As with Levene's test there are three variants\n",
      "        of Fligner's test that differ by the measure of central\n",
      "        tendency used in the test.  See `levene` for more information.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] http://www.stat.psu.edu/~bgl/center/tr/TR993.ps\n",
      "        \n",
      "        .. [2] Fligner, M.A. and Killeen, T.J. (1976). Distribution-free two-sample\n",
      "               tests for scale. 'Journal of the American Statistical Association.'\n",
      "               71(353), 210-213.\n",
      "    \n",
      "    friedmanchisquare(*args)\n",
      "        Computes the Friedman test for repeated measurements\n",
      "        \n",
      "        The Friedman test tests the null hypothesis that repeated measurements of\n",
      "        the same individuals have the same distribution.  It is often used\n",
      "        to test for consistency among measurements obtained in different ways.\n",
      "        For example, if two measurement techniques are used on the same set of\n",
      "        individuals, the Friedman test can be used to determine if the two\n",
      "        measurement techniques are consistent.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        measurements1, measurements2, measurements3... : array_like\n",
      "            Arrays of measurements.  All of the arrays must have the same number\n",
      "            of elements.  At least 3 sets of measurements must be given.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        friedman chi-square statistic : float\n",
      "            the test statistic, correcting for ties\n",
      "        p-value : float\n",
      "            the associated p-value assuming that the test statistic has a chi\n",
      "            squared distribution\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Due to the assumption that the test statistic has a chi squared\n",
      "        distribution, the p-value is only reliable for n > 10 and more than\n",
      "        6 repeated measurements.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] http://en.wikipedia.org/wiki/Friedman_test\n",
      "    \n",
      "    glm(*args, **kwds)\n",
      "        `glm` is deprecated!\n",
      "        `glm` is deprecated in scipy 0.13.0 and will be removed in 0.14.0.\n",
      "        Use `ttest_ind` for the same functionality in scipy.stats, or `statsmodels.OLS`\n",
      "        for a more full-featured general linear model.\n",
      "        \n",
      "        \n",
      "            Calculates a linear model fit ...\n",
      "            anova/ancova/lin-regress/t-test/etc. Taken from:\n",
      "        \n",
      "            Returns\n",
      "            -------\n",
      "            statistic, p-value ???\n",
      "        \n",
      "            References\n",
      "            ----------\n",
      "            Peterson et al. Statistical limitations in functional neuroimaging\n",
      "            I. Non-inferential methods and statistical models.  Phil Trans Royal Soc\n",
      "            Lond B 354: 1239-1260.\n",
      "    \n",
      "    gmean(a, axis=0, dtype=None)\n",
      "        Compute the geometric mean along the specified axis.\n",
      "        \n",
      "        Returns the geometric average of the array elements.\n",
      "        That is:  n-th root of (x1 * x2 * ... * xn)\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Input array or object that can be converted to an array.\n",
      "        axis : int, optional, default axis=0\n",
      "            Axis along which the geometric mean is computed.\n",
      "        dtype : dtype, optional\n",
      "            Type of the returned array and of the accumulator in which the\n",
      "            elements are summed. If dtype is not specified, it defaults to the\n",
      "            dtype of a, unless a has an integer dtype with a precision less than\n",
      "            that of the default platform integer. In that case, the default\n",
      "            platform integer is used.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        gmean : ndarray\n",
      "            see dtype parameter above\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        numpy.mean : Arithmetic average\n",
      "        numpy.average : Weighted average\n",
      "        hmean : Harmonic mean\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The geometric average is computed over a single dimension of the input\n",
      "        array, axis=0 by default, or all values in the array if axis=None.\n",
      "        float64 intermediate and return values are used for integer inputs.\n",
      "        \n",
      "        Use masked arrays to ignore any non-finite values in the input or that\n",
      "        arise in the calculations such as Not a Number and infinity because masked\n",
      "        arrays automatically mask any non-finite values.\n",
      "    \n",
      "    histogram(a, numbins=10, defaultlimits=None, weights=None, printextras=False)\n",
      "        Separates the range into several bins and returns the number of instances\n",
      "        in each bin.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Array of scores which will be put into bins.\n",
      "        numbins : int, optional\n",
      "            The number of bins to use for the histogram. Default is 10.\n",
      "        defaultlimits : tuple (lower, upper), optional\n",
      "            The lower and upper values for the range of the histogram.\n",
      "            If no value is given, a range slightly larger then the range of the\n",
      "            values in a is used. Specifically ``(a.min() - s, a.max() + s)``,\n",
      "                where ``s = (1/2)(a.max() - a.min()) / (numbins - 1)``.\n",
      "        weights : array_like, optional\n",
      "            The weights for each value in `a`. Default is None, which gives each\n",
      "            value a weight of 1.0\n",
      "        printextras : bool, optional\n",
      "            If True, the number of extra points is printed to standard output.\n",
      "            Default is False.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        histogram : ndarray\n",
      "            Number of points (or sum of weights) in each bin.\n",
      "        low_range : float\n",
      "            Lowest value of histogram, the lower limit of the first bin.\n",
      "        binsize : float\n",
      "            The size of the bins (all bins have the same size).\n",
      "        extrapoints : int\n",
      "            The number of points outside the range of the histogram.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        numpy.histogram\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This histogram is based on numpy's histogram but has a larger range by\n",
      "        default if default limits is not set.\n",
      "    \n",
      "    histogram2(a, bins)\n",
      "        Compute histogram using divisions in bins.\n",
      "        \n",
      "        Count the number of times values from array `a` fall into\n",
      "        numerical ranges defined by `bins`.  Range x is given by\n",
      "        bins[x] <= range_x < bins[x+1] where x =0,N and N is the\n",
      "        length of the `bins` array.  The last range is given by\n",
      "        bins[N] <= range_N < infinity.  Values less than bins[0] are\n",
      "        not included in the histogram.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like of rank 1\n",
      "            The array of values to be assigned into bins\n",
      "        bins : array_like of rank 1\n",
      "            Defines the ranges of values to use during histogramming.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        histogram2 : ndarray of rank 1\n",
      "            Each value represents the occurrences for a given bin (range) of\n",
      "            values.\n",
      "    \n",
      "    hmean(a, axis=0, dtype=None)\n",
      "        Calculates the harmonic mean along the specified axis.\n",
      "        \n",
      "        That is:  n / (1/x1 + 1/x2 + ... + 1/xn)\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Input array, masked array or object that can be converted to an array.\n",
      "        axis : int, optional, default axis=0\n",
      "            Axis along which the harmonic mean is computed.\n",
      "        dtype : dtype, optional\n",
      "            Type of the returned array and of the accumulator in which the\n",
      "            elements are summed. If `dtype` is not specified, it defaults to the\n",
      "            dtype of `a`, unless `a` has an integer `dtype` with a precision less\n",
      "            than that of the default platform integer. In that case, the default\n",
      "            platform integer is used.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        hmean : ndarray\n",
      "            see `dtype` parameter above\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        numpy.mean : Arithmetic average\n",
      "        numpy.average : Weighted average\n",
      "        gmean : Geometric mean\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The harmonic mean is computed over a single dimension of the input\n",
      "        array, axis=0 by default, or all values in the array if axis=None.\n",
      "        float64 intermediate and return values are used for integer inputs.\n",
      "        \n",
      "        Use masked arrays to ignore any non-finite values in the input or that\n",
      "        arise in the calculations such as Not a Number and infinity.\n",
      "    \n",
      "    itemfreq(a)\n",
      "        Returns a 2D array of item frequencies.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : (N,) array_like\n",
      "            Input array.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        itemfreq : (2,K) ndarray\n",
      "            A 2D frequency table (col [0:n-1]=scores, col n=frequencies).\n",
      "            Column 1 contains sorted, unique values from `a`, column 2 contains\n",
      "            their respective counts.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This uses a loop that is only reasonably fast if the number of unique\n",
      "        elements is not large. For integers, numpy.bincount is much faster.\n",
      "        This function currently does not support strings or multi-dimensional\n",
      "        scores.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> a = np.array([1, 1, 5, 0, 1, 2, 2, 0, 1, 4])\n",
      "        >>> stats.itemfreq(a)\n",
      "        array([[ 0.,  2.],\n",
      "               [ 1.,  4.],\n",
      "               [ 2.,  2.],\n",
      "               [ 4.,  1.],\n",
      "               [ 5.,  1.]])\n",
      "        >>> np.bincount(a)\n",
      "        array([2, 4, 2, 0, 1, 1])\n",
      "        \n",
      "        >>> stats.itemfreq(a/10.)\n",
      "        array([[ 0. ,  2. ],\n",
      "               [ 0.1,  4. ],\n",
      "               [ 0.2,  2. ],\n",
      "               [ 0.4,  1. ],\n",
      "               [ 0.5,  1. ]])\n",
      "    \n",
      "    jarque_bera(x)\n",
      "        Perform the Jarque-Bera goodness of fit test on sample data.\n",
      "        \n",
      "        The Jarque-Bera test tests whether the sample data has the skewness and\n",
      "        kurtosis matching a normal distribution.\n",
      "        \n",
      "        Note that this test only works for a large enough number of data samples\n",
      "        (>2000) as the test statistic asymptotically has a Chi-squared distribution\n",
      "        with 2 degrees of freedom.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Observations of a random variable.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        jb_value : float\n",
      "            The test statistic.\n",
      "        p : float\n",
      "            The p-value for the hypothesis test.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Jarque, C. and Bera, A. (1980) \"Efficient tests for normality,\n",
      "               homoscedasticity and serial independence of regression residuals\",\n",
      "               6 Econometric Letters 255-259.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> np.random.seed(987654321)\n",
      "        >>> x = np.random.normal(0, 1, 100000)\n",
      "        >>> y = np.random.rayleigh(1, 100000)\n",
      "        >>> stats.jarque_bera(x)\n",
      "        (4.7165707989581342, 0.09458225503041906)\n",
      "        >>> stats.jarque_bera(y)\n",
      "        (6713.7098548143422, 0.0)\n",
      "    \n",
      "    kendalltau(x, y, initial_lexsort=True)\n",
      "        Calculates Kendall's tau, a correlation measure for ordinal data.\n",
      "        \n",
      "        Kendall's tau is a measure of the correspondence between two rankings.\n",
      "        Values close to 1 indicate strong agreement, values close to -1 indicate\n",
      "        strong disagreement.  This is the tau-b version of Kendall's tau which\n",
      "        accounts for ties.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x, y : array_like\n",
      "            Arrays of rankings, of the same shape. If arrays are not 1-D, they will\n",
      "            be flattened to 1-D.\n",
      "        initial_lexsort : bool, optional\n",
      "            Whether to use lexsort or quicksort as the sorting method for the\n",
      "            initial sort of the inputs. Default is lexsort (True), for which\n",
      "            `kendalltau` is of complexity O(n log(n)). If False, the complexity is\n",
      "            O(n^2), but with a smaller pre-factor (so quicksort may be faster for\n",
      "            small arrays).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        Kendall's tau : float\n",
      "           The tau statistic.\n",
      "        p-value : float\n",
      "           The two-sided p-value for a hypothesis test whose null hypothesis is\n",
      "           an absence of association, tau = 0.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The definition of Kendall's tau that is used is::\n",
      "        \n",
      "          tau = (P - Q) / sqrt((P + Q + T) * (P + Q + U))\n",
      "        \n",
      "        where P is the number of concordant pairs, Q the number of discordant\n",
      "        pairs, T the number of ties only in `x`, and U the number of ties only in\n",
      "        `y`.  If a tie occurs for the same pair in both `x` and `y`, it is not\n",
      "        added to either T or U.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        W.R. Knight, \"A Computer Method for Calculating Kendall's Tau with\n",
      "        Ungrouped Data\", Journal of the American Statistical Association, Vol. 61,\n",
      "        No. 314, Part 1, pp. 436-439, 1966.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> x1 = [12, 2, 1, 12, 2]\n",
      "        >>> x2 = [1, 4, 7, 1, 0]\n",
      "        >>> tau, p_value = sp.stats.kendalltau(x1, x2)\n",
      "        >>> tau\n",
      "        -0.47140452079103173\n",
      "        >>> p_value\n",
      "        0.24821309157521476\n",
      "    \n",
      "    kruskal(*args)\n",
      "        Compute the Kruskal-Wallis H-test for independent samples\n",
      "        \n",
      "        The Kruskal-Wallis H-test tests the null hypothesis that the population\n",
      "        median of all of the groups are equal.  It is a non-parametric version of\n",
      "        ANOVA.  The test works on 2 or more independent samples, which may have\n",
      "        different sizes.  Note that rejecting the null hypothesis does not\n",
      "        indicate which of the groups differs.  Post-hoc comparisons between\n",
      "        groups are required to determine which groups are different.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        sample1, sample2, ... : array_like\n",
      "           Two or more arrays with the sample measurements can be given as\n",
      "           arguments.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        H-statistic : float\n",
      "           The Kruskal-Wallis H statistic, corrected for ties\n",
      "        p-value : float\n",
      "           The p-value for the test using the assumption that H has a chi\n",
      "           square distribution\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Due to the assumption that H has a chi square distribution, the number\n",
      "        of samples in each group must not be too small.  A typical rule is\n",
      "        that each sample must have at least 5 measurements.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] http://en.wikipedia.org/wiki/Kruskal-Wallis_one-way_analysis_of_variance\n",
      "    \n",
      "    ks_2samp(data1, data2)\n",
      "        Computes the Kolmogorov-Smirnov statistic on 2 samples.\n",
      "        \n",
      "        This is a two-sided test for the null hypothesis that 2 independent samples\n",
      "        are drawn from the same continuous distribution.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a, b : sequence of 1-D ndarrays\n",
      "            two arrays of sample observations assumed to be drawn from a continuous\n",
      "            distribution, sample sizes can be different\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        D : float\n",
      "            KS statistic\n",
      "        p-value : float\n",
      "            two-tailed p-value\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This tests whether 2 samples are drawn from the same distribution. Note\n",
      "        that, like in the case of the one-sample K-S test, the distribution is\n",
      "        assumed to be continuous.\n",
      "        \n",
      "        This is the two-sided test, one-sided tests are not implemented.\n",
      "        The test uses the two-sided asymptotic Kolmogorov-Smirnov distribution.\n",
      "        \n",
      "        If the K-S statistic is small or the p-value is high, then we cannot\n",
      "        reject the hypothesis that the distributions of the two samples\n",
      "        are the same.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> np.random.seed(12345678)  #fix random seed to get the same result\n",
      "        >>> n1 = 200  # size of first sample\n",
      "        >>> n2 = 300  # size of second sample\n",
      "        \n",
      "        For a different distribution, we can reject the null hypothesis since the\n",
      "        pvalue is below 1%:\n",
      "        \n",
      "        >>> rvs1 = stats.norm.rvs(size=n1, loc=0., scale=1)\n",
      "        >>> rvs2 = stats.norm.rvs(size=n2, loc=0.5, scale=1.5)\n",
      "        >>> stats.ks_2samp(rvs1, rvs2)\n",
      "        (0.20833333333333337, 4.6674975515806989e-005)\n",
      "        \n",
      "        For a slightly different distribution, we cannot reject the null hypothesis\n",
      "        at a 10% or lower alpha since the p-value at 0.144 is higher than 10%\n",
      "        \n",
      "        >>> rvs3 = stats.norm.rvs(size=n2, loc=0.01, scale=1.0)\n",
      "        >>> stats.ks_2samp(rvs1, rvs3)\n",
      "        (0.10333333333333333, 0.14498781825751686)\n",
      "        \n",
      "        For an identical distribution, we cannot reject the null hypothesis since\n",
      "        the p-value is high, 41%:\n",
      "        \n",
      "        >>> rvs4 = stats.norm.rvs(size=n2, loc=0.0, scale=1.0)\n",
      "        >>> stats.ks_2samp(rvs1, rvs4)\n",
      "        (0.07999999999999996, 0.41126949729859719)\n",
      "    \n",
      "    kstat(data, n=2)\n",
      "        Return the nth k-statistic (1<=n<=4 so far).\n",
      "        \n",
      "        The nth k-statistic is the unique symmetric unbiased estimator of the nth\n",
      "        cumulant kappa_n.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data : array_like\n",
      "            Input array.\n",
      "        n : int, {1, 2, 3, 4}, optional\n",
      "            Default is equal to 2.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        kstat : float\n",
      "            The nth k-statistic.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        kstatvar: Returns an unbiased estimator of the variance of the k-statistic.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The cumulants are related to central moments but are specifically defined\n",
      "        using a power series expansion of the logarithm of the characteristic\n",
      "        function (which is the Fourier transform of the PDF).\n",
      "        In particular let phi(t) be the characteristic function, then::\n",
      "        \n",
      "            ln phi(t) = > kappa_n (it)^n / n!    (sum from n=0 to inf)\n",
      "        \n",
      "        The first few cumulants (kappa_n)  in terms of central moments (mu_n) are::\n",
      "        \n",
      "            kappa_1 = mu_1\n",
      "            kappa_2 = mu_2\n",
      "            kappa_3 = mu_3\n",
      "            kappa_4 = mu_4 - 3*mu_2**2\n",
      "            kappa_5 = mu_5 - 10*mu_2 * mu_3\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        http://mathworld.wolfram.com/k-Statistic.html\n",
      "        \n",
      "        http://mathworld.wolfram.com/Cumulant.html\n",
      "    \n",
      "    kstatvar(data, n=2)\n",
      "        Returns an unbiased estimator of the variance of the k-statistic.\n",
      "        \n",
      "        See `kstat` for more details of the k-statistic.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data : array_like\n",
      "            Input array.\n",
      "        n : int, {1, 2}, optional\n",
      "            Default is equal to 2.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        kstatvar : float\n",
      "            The nth k-statistic variance.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        kstat\n",
      "    \n",
      "    kstest(rvs, cdf, args=(), N=20, alternative='two-sided', mode='approx')\n",
      "        Perform the Kolmogorov-Smirnov test for goodness of fit.\n",
      "        \n",
      "        This performs a test of the distribution G(x) of an observed\n",
      "        random variable against a given distribution F(x). Under the null\n",
      "        hypothesis the two distributions are identical, G(x)=F(x). The\n",
      "        alternative hypothesis can be either 'two-sided' (default), 'less'\n",
      "        or 'greater'. The KS test is only valid for continuous distributions.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        rvs : str, array or callable\n",
      "            If a string, it should be the name of a distribution in `scipy.stats`.\n",
      "            If an array, it should be a 1-D array of observations of random\n",
      "            variables.\n",
      "            If a callable, it should be a function to generate random variables;\n",
      "            it is required to have a keyword argument `size`.\n",
      "        cdf : str or callable\n",
      "            If a string, it should be the name of a distribution in `scipy.stats`.\n",
      "            If `rvs` is a string then `cdf` can be False or the same as `rvs`.\n",
      "            If a callable, that callable is used to calculate the cdf.\n",
      "        args : tuple, sequence, optional\n",
      "            Distribution parameters, used if `rvs` or `cdf` are strings.\n",
      "        N : int, optional\n",
      "            Sample size if `rvs` is string or callable.  Default is 20.\n",
      "        alternative : {'two-sided', 'less','greater'}, optional\n",
      "            Defines the alternative hypothesis (see explanation above).\n",
      "            Default is 'two-sided'.\n",
      "        mode : 'approx' (default) or 'asymp', optional\n",
      "            Defines the distribution used for calculating the p-value.\n",
      "        \n",
      "              - 'approx' : use approximation to exact distribution of test statistic\n",
      "              - 'asymp' : use asymptotic distribution of test statistic\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        D : float\n",
      "            KS test statistic, either D, D+ or D-.\n",
      "        p-value :  float\n",
      "            One-tailed or two-tailed p-value.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        In the one-sided test, the alternative is that the empirical\n",
      "        cumulative distribution function of the random variable is \"less\"\n",
      "        or \"greater\" than the cumulative distribution function F(x) of the\n",
      "        hypothesis, ``G(x)<=F(x)``, resp. ``G(x)>=F(x)``.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        \n",
      "        >>> x = np.linspace(-15, 15, 9)\n",
      "        >>> stats.kstest(x, 'norm')\n",
      "        (0.44435602715924361, 0.038850142705171065)\n",
      "        \n",
      "        >>> np.random.seed(987654321) # set random seed to get the same result\n",
      "        >>> stats.kstest('norm', False, N=100)\n",
      "        (0.058352892479417884, 0.88531190944151261)\n",
      "        \n",
      "        The above lines are equivalent to:\n",
      "        \n",
      "        >>> np.random.seed(987654321)\n",
      "        >>> stats.kstest(stats.norm.rvs(size=100), 'norm')\n",
      "        (0.058352892479417884, 0.88531190944151261)\n",
      "        \n",
      "        *Test against one-sided alternative hypothesis*\n",
      "        \n",
      "        Shift distribution to larger values, so that ``cdf_dgp(x) < norm.cdf(x)``:\n",
      "        \n",
      "        >>> np.random.seed(987654321)\n",
      "        >>> x = stats.norm.rvs(loc=0.2, size=100)\n",
      "        >>> stats.kstest(x,'norm', alternative = 'less')\n",
      "        (0.12464329735846891, 0.040989164077641749)\n",
      "        \n",
      "        Reject equal distribution against alternative hypothesis: less\n",
      "        \n",
      "        >>> stats.kstest(x,'norm', alternative = 'greater')\n",
      "        (0.0072115233216311081, 0.98531158590396395)\n",
      "        \n",
      "        Don't reject equal distribution against alternative hypothesis: greater\n",
      "        \n",
      "        >>> stats.kstest(x,'norm', mode='asymp')\n",
      "        (0.12464329735846891, 0.08944488871182088)\n",
      "        \n",
      "        *Testing t distributed random variables against normal distribution*\n",
      "        \n",
      "        With 100 degrees of freedom the t distribution looks close to the normal\n",
      "        distribution, and the K-S test does not reject the hypothesis that the\n",
      "        sample came from the normal distribution:\n",
      "        \n",
      "        >>> np.random.seed(987654321)\n",
      "        >>> stats.kstest(stats.t.rvs(100,size=100),'norm')\n",
      "        (0.072018929165471257, 0.67630062862479168)\n",
      "        \n",
      "        With 3 degrees of freedom the t distribution looks sufficiently different\n",
      "        from the normal distribution, that we can reject the hypothesis that the\n",
      "        sample came from the normal distribution at the 10% level:\n",
      "        \n",
      "        >>> np.random.seed(987654321)\n",
      "        >>> stats.kstest(stats.t.rvs(3,size=100),'norm')\n",
      "        (0.131016895759829, 0.058826222555312224)\n",
      "    \n",
      "    kurtosis(a, axis=0, fisher=True, bias=True)\n",
      "        Computes the kurtosis (Fisher or Pearson) of a dataset.\n",
      "        \n",
      "        Kurtosis is the fourth central moment divided by the square of the\n",
      "        variance. If Fisher's definition is used, then 3.0 is subtracted from\n",
      "        the result to give 0.0 for a normal distribution.\n",
      "        \n",
      "        If bias is False then the kurtosis is calculated using k statistics to\n",
      "        eliminate bias coming from biased moment estimators\n",
      "        \n",
      "        Use `kurtosistest` to see if result is close enough to normal.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array\n",
      "            data for which the kurtosis is calculated\n",
      "        axis : int or None\n",
      "            Axis along which the kurtosis is calculated\n",
      "        fisher : bool\n",
      "            If True, Fisher's definition is used (normal ==> 0.0). If False,\n",
      "            Pearson's definition is used (normal ==> 3.0).\n",
      "        bias : bool\n",
      "            If False, then the calculations are corrected for statistical bias.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        kurtosis : array\n",
      "            The kurtosis of values along an axis. If all values are equal,\n",
      "            return -3 for Fisher's definition and 0 for Pearson's definition.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Zwillinger, D. and Kokoska, S. (2000). CRC Standard\n",
      "           Probability and Statistics Tables and Formulae. Chapman & Hall: New\n",
      "           York. 2000.\n",
      "    \n",
      "    kurtosistest(a, axis=0)\n",
      "        Tests whether a dataset has normal kurtosis\n",
      "        \n",
      "        This function tests the null hypothesis that the kurtosis\n",
      "        of the population from which the sample was drawn is that\n",
      "        of the normal distribution: ``kurtosis = 3(n-1)/(n+1)``.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array\n",
      "            array of the sample data\n",
      "        axis : int or None\n",
      "            the axis to operate along, or None to work on the whole array.\n",
      "            The default is the first axis.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        z-score : float\n",
      "            The computed z-score for this test.\n",
      "        p-value : float\n",
      "            The 2-sided p-value for the hypothesis test\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Valid only for n>20.  The Z-score is set to 0 for bad entries.\n",
      "    \n",
      "    levene(*args, **kwds)\n",
      "        Perform Levene test for equal variances.\n",
      "        \n",
      "        The Levene test tests the null hypothesis that all input samples\n",
      "        are from populations with equal variances.  Levene's test is an\n",
      "        alternative to Bartlett's test `bartlett` in the case where\n",
      "        there are significant deviations from normality.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        sample1, sample2, ... : array_like\n",
      "            The sample data, possibly with different lengths\n",
      "        center : {'mean', 'median', 'trimmed'}, optional\n",
      "            Which function of the data to use in the test.  The default\n",
      "            is 'median'.\n",
      "        proportiontocut : float, optional\n",
      "            When `center` is 'trimmed', this gives the proportion of data points\n",
      "            to cut from each end. (See `scipy.stats.trim_mean`.)\n",
      "            Default is 0.05.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        W : float\n",
      "            The test statistic.\n",
      "        p-value : float\n",
      "            The p-value for the test.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Three variations of Levene's test are possible.  The possibilities\n",
      "        and their recommended usages are:\n",
      "        \n",
      "          * 'median' : Recommended for skewed (non-normal) distributions>\n",
      "          * 'mean' : Recommended for symmetric, moderate-tailed distributions.\n",
      "          * 'trimmed' : Recommended for heavy-tailed distributions.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1]  http://www.itl.nist.gov/div898/handbook/eda/section3/eda35a.htm\n",
      "        .. [2]   Levene, H. (1960). In Contributions to Probability and Statistics:\n",
      "                   Essays in Honor of Harold Hotelling, I. Olkin et al. eds.,\n",
      "                   Stanford University Press, pp. 278-292.\n",
      "        .. [3]  Brown, M. B. and Forsythe, A. B. (1974), Journal of the American\n",
      "                  Statistical Association, 69, 364-367\n",
      "    \n",
      "    linregress(x, y=None)\n",
      "        Calculate a regression line\n",
      "        \n",
      "        This computes a least-squares regression for two sets of measurements.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x, y : array_like\n",
      "            two sets of measurements.  Both arrays should have the same length.\n",
      "            If only x is given (and y=None), then it must be a two-dimensional\n",
      "            array where one dimension has length 2.  The two sets of measurements\n",
      "            are then found by splitting the array along the length-2 dimension.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        slope : float\n",
      "            slope of the regression line\n",
      "        intercept : float\n",
      "            intercept of the regression line\n",
      "        r-value : float\n",
      "            correlation coefficient\n",
      "        p-value : float\n",
      "            two-sided p-value for a hypothesis test whose null hypothesis is\n",
      "            that the slope is zero.\n",
      "        stderr : float\n",
      "            Standard error of the estimate\n",
      "        \n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> import numpy as np\n",
      "        >>> x = np.random.random(10)\n",
      "        >>> y = np.random.random(10)\n",
      "        >>> slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
      "        \n",
      "        # To get coefficient of determination (r_squared)\n",
      "        \n",
      "        >>> print \"r-squared:\", r_value**2\n",
      "        r-squared: 0.15286643777\n",
      "    \n",
      "    mannwhitneyu(x, y, use_continuity=True)\n",
      "        Computes the Mann-Whitney rank test on samples x and y.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x, y : array_like\n",
      "            Array of samples, should be one-dimensional.\n",
      "        use_continuity : bool, optional\n",
      "                Whether a continuity correction (1/2.) should be taken into\n",
      "                account. Default is True.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        u : float\n",
      "            The Mann-Whitney statistics.\n",
      "        prob : float\n",
      "            One-sided p-value assuming a asymptotic normal distribution.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Use only when the number of observation in each sample is > 20 and\n",
      "        you have 2 independent samples of ranks. Mann-Whitney U is\n",
      "        significant if the u-obtained is LESS THAN or equal to the critical\n",
      "        value of U.\n",
      "        \n",
      "        This test corrects for ties and by default uses a continuity correction.\n",
      "        The reported p-value is for a one-sided hypothesis, to get the two-sided\n",
      "        p-value multiply the returned p-value by 2.\n",
      "    \n",
      "    mode(a, axis=0)\n",
      "        Returns an array of the modal (most common) value in the passed array.\n",
      "        \n",
      "        If there is more than one such value, only the first is returned.\n",
      "        The bin-count for the modal bins is also returned.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            n-dimensional array of which to find mode(s).\n",
      "        axis : int, optional\n",
      "            Axis along which to operate. Default is 0, i.e. the first axis.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        vals : ndarray\n",
      "            Array of modal values.\n",
      "        counts : ndarray\n",
      "            Array of counts for each mode.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> a = np.array([[6, 8, 3, 0],\n",
      "                          [3, 2, 1, 7],\n",
      "                          [8, 1, 8, 4],\n",
      "                          [5, 3, 0, 5],\n",
      "                          [4, 7, 5, 9]])\n",
      "        >>> from scipy import stats\n",
      "        >>> stats.mode(a)\n",
      "        (array([[ 3.,  1.,  0.,  0.]]), array([[ 1.,  1.,  1.,  1.]]))\n",
      "        \n",
      "        To get mode of whole array, specify axis=None:\n",
      "        \n",
      "        >>> stats.mode(a, axis=None)\n",
      "        (array([ 3.]), array([ 3.]))\n",
      "    \n",
      "    moment(a, moment=1, axis=0)\n",
      "        Calculates the nth moment about the mean for a sample.\n",
      "        \n",
      "        Generally used to calculate coefficients of skewness and\n",
      "        kurtosis.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "           data\n",
      "        moment : int\n",
      "           order of central moment that is returned\n",
      "        axis : int or None\n",
      "           Axis along which the central moment is computed. If None, then the data\n",
      "           array is raveled. The default axis is zero.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        n-th central moment : ndarray or float\n",
      "           The appropriate moment along the given axis or over all values if axis\n",
      "           is None. The denominator for the moment calculation is the number of\n",
      "           observations, no degrees of freedom correction is done.\n",
      "    \n",
      "    mood(x, y, axis=0)\n",
      "        Perform Mood's test for equal scale parameters.\n",
      "        \n",
      "        Mood's two-sample test for scale parameters is a non-parametric\n",
      "        test for the null hypothesis that two samples are drawn from the\n",
      "        same distribution with the same scale parameter.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x, y : array_like\n",
      "            Arrays of sample data.\n",
      "        axis: int, optional\n",
      "            The axis along which the samples are tested.  `x` and `y` can be of\n",
      "            different length along `axis`.\n",
      "            If `axis` is None, `x` and `y` are flattened and the test is done on\n",
      "            all values in the flattened arrays.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        z : scalar or ndarray\n",
      "            The z-score for the hypothesis test.  For 1-D inputs a scalar is\n",
      "            returned;\n",
      "        p-value : scalar ndarray\n",
      "            The p-value for the hypothesis test.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        fligner : A non-parametric test for the equality of k variances\n",
      "        ansari : A non-parametric test for the equality of 2 variances\n",
      "        bartlett : A parametric test for equality of k variances in normal samples\n",
      "        levene : A parametric test for equality of k variances\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The data are assumed to be drawn from probability distributions ``f(x)``\n",
      "        and ``f(x/s) / s`` respectively, for some probability density function f.\n",
      "        The null hypothesis is that ``s == 1``.\n",
      "        \n",
      "        For multi-dimensional arrays, if the inputs are of shapes\n",
      "        ``(n0, n1, n2, n3)``  and ``(n0, m1, n2, n3)``, then if ``axis=1``, the\n",
      "        resulting z and p values will have shape ``(n0, n2, n3)``.  Note that\n",
      "        ``n1`` and ``m1`` don't have to be equal, but the other dimensions do.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> x2 = np.random.randn(2, 45, 6, 7)\n",
      "        >>> x1 = np.random.randn(2, 30, 6, 7)\n",
      "        >>> z, p = stats.mood(x1, x2, axis=1)\n",
      "        >>> p.shape\n",
      "        (2, 6, 7)\n",
      "        \n",
      "        Find the number of points where the difference in scale is not significant:\n",
      "        \n",
      "        >>> (p > 0.1).sum()\n",
      "        74\n",
      "        \n",
      "        Perform the test with different scales:\n",
      "        \n",
      "        >>> x1 = np.random.randn(2, 30)\n",
      "        >>> x2 = np.random.randn(2, 35) * 10.0\n",
      "        >>> stats.mood(x1, x2, axis=1)\n",
      "        (array([-5.84332354, -5.6840814 ]), array([5.11694980e-09, 1.31517628e-08]))\n",
      "    \n",
      "    mvsdist(data)\n",
      "        'Frozen' distributions for mean, variance, and standard deviation of data.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data : array_like\n",
      "            Input array. Converted to 1-D using ravel.\n",
      "            Requires 2 or more data-points.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        mdist : \"frozen\" distribution object\n",
      "            Distribution object representing the mean of the data\n",
      "        vdist : \"frozen\" distribution object\n",
      "            Distribution object representing the variance of the data\n",
      "        sdist : \"frozen\" distribution object\n",
      "            Distribution object representing the standard deviation of the data\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The return values from bayes_mvs(data) is equivalent to\n",
      "        ``tuple((x.mean(), x.interval(0.90)) for x in mvsdist(data))``.\n",
      "        \n",
      "        In other words, calling ``<dist>.mean()`` and ``<dist>.interval(0.90)``\n",
      "        on the three distribution objects returned from this function will give\n",
      "        the same results that are returned from `bayes_mvs`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.stats import mvsdist\n",
      "        >>> data = [6, 9, 12, 7, 8, 8, 13]\n",
      "        >>> mean, var, std = mvsdist(data)\n",
      "        \n",
      "        We now have frozen distribution objects \"mean\", \"var\" and \"std\" that we can\n",
      "        examine:\n",
      "        \n",
      "        >>> mean.mean()\n",
      "        9.0\n",
      "        >>> mean.interval(0.95)\n",
      "        (6.6120585482655692, 11.387941451734431)\n",
      "        >>> mean.std()\n",
      "        1.1952286093343936\n",
      "    \n",
      "    nanmean(x, axis=0)\n",
      "        Compute the mean over the given axis ignoring nans.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : ndarray\n",
      "            Input array.\n",
      "        axis : int, optional\n",
      "            Axis along which the mean is computed. Default is 0, i.e. the\n",
      "            first axis.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        m : float\n",
      "            The mean of `x`, ignoring nans.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        nanstd, nanmedian\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> a = np.linspace(0, 4, 3)\n",
      "        >>> a\n",
      "        array([ 0.,  2.,  4.])\n",
      "        >>> a[-1] = np.nan\n",
      "        >>> stats.nanmean(a)\n",
      "        1.0\n",
      "    \n",
      "    nanmedian(x, axis=0)\n",
      "        Compute the median along the given axis ignoring nan values.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Input array.\n",
      "        axis : int, optional\n",
      "            Axis along which the median is computed. Default is 0, i.e. the\n",
      "            first axis.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        m : float\n",
      "            The median of `x` along `axis`.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        nanstd, nanmean\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> a = np.array([0, 3, 1, 5, 5, np.nan])\n",
      "        >>> stats.nanmedian(a)\n",
      "        array(3.0)\n",
      "        \n",
      "        >>> b = np.array([0, 3, 1, 5, 5, np.nan, 5])\n",
      "        >>> stats.nanmedian(b)\n",
      "        array(4.0)\n",
      "        \n",
      "        Example with axis:\n",
      "        \n",
      "        >>> c = np.arange(30.).reshape(5,6)\n",
      "        >>> idx = np.array([False, False, False, True, False] * 6).reshape(5,6)\n",
      "        >>> c[idx] = np.nan\n",
      "        >>> c\n",
      "        array([[  0.,   1.,   2.,  nan,   4.,   5.],\n",
      "               [  6.,   7.,  nan,   9.,  10.,  11.],\n",
      "               [ 12.,  nan,  14.,  15.,  16.,  17.],\n",
      "               [ nan,  19.,  20.,  21.,  22.,  nan],\n",
      "               [ 24.,  25.,  26.,  27.,  nan,  29.]])\n",
      "        >>> stats.nanmedian(c, axis=1)\n",
      "        array([  2. ,   9. ,  15. ,  20.5,  26. ])\n",
      "    \n",
      "    nanstd(x, axis=0, bias=False)\n",
      "        Compute the standard deviation over the given axis, ignoring nans.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Input array.\n",
      "        axis : int or None, optional\n",
      "            Axis along which the standard deviation is computed. Default is 0.\n",
      "            If None, compute over the whole array `x`.\n",
      "        bias : bool, optional\n",
      "            If True, the biased (normalized by N) definition is used. If False\n",
      "            (default), the unbiased definition is used.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        s : float\n",
      "            The standard deviation.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        nanmean, nanmedian\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> a = np.arange(10, dtype=float)\n",
      "        >>> a[1:3] = np.nan\n",
      "        >>> np.std(a)\n",
      "        nan\n",
      "        >>> stats.nanstd(a)\n",
      "        2.9154759474226504\n",
      "        >>> stats.nanstd(a.reshape(2, 5), axis=1)\n",
      "        array([ 2.0817,  1.5811])\n",
      "        >>> stats.nanstd(a.reshape(2, 5), axis=None)\n",
      "        2.9154759474226504\n",
      "    \n",
      "    normaltest(a, axis=0)\n",
      "        Tests whether a sample differs from a normal distribution.\n",
      "        \n",
      "        This function tests the null hypothesis that a sample comes\n",
      "        from a normal distribution.  It is based on D'Agostino and\n",
      "        Pearson's [1]_, [2]_ test that combines skew and kurtosis to\n",
      "        produce an omnibus test of normality.\n",
      "        \n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            The array containing the data to be tested.\n",
      "        axis : int or None\n",
      "            If None, the array is treated as a single data set, regardless of\n",
      "            its shape.  Otherwise, each 1-d array along axis `axis` is tested.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        k2 : float or array\n",
      "            `s^2 + k^2`, where `s` is the z-score returned by `skewtest` and\n",
      "            `k` is the z-score returned by `kurtosistest`.\n",
      "        p-value : float or array\n",
      "           A 2-sided chi squared probability for the hypothesis test.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] D'Agostino, R. B. (1971), \"An omnibus test of normality for\n",
      "               moderate and large sample size,\" Biometrika, 58, 341-348\n",
      "        \n",
      "        .. [2] D'Agostino, R. and Pearson, E. S. (1973), \"Testing for\n",
      "               departures from normality,\" Biometrika, 60, 613-622\n",
      "    \n",
      "    obrientransform(*args)\n",
      "        Computes the O'Brien transform on input data (any number of arrays).\n",
      "        \n",
      "        Used to test for homogeneity of variance prior to running one-way stats.\n",
      "        Each array in ``*args`` is one level of a factor.\n",
      "        If `f_oneway` is run on the transformed data and found significant,\n",
      "        the variances are unequal.  From Maxwell and Delaney [1]_, p.112.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        args : tuple of array_like\n",
      "            Any number of arrays.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        obrientransform : ndarray\n",
      "            Transformed data for use in an ANOVA.  The first dimension\n",
      "            of the result corresponds to the sequence of transformed\n",
      "            arrays.  If the arrays given are all 1-D of the same length,\n",
      "            the return value is a 2-D array; otherwise it is a 1-D array\n",
      "            of type object, with each element being an ndarray.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] S. E. Maxwell and H. D. Delaney, \"Designing Experiments and\n",
      "               Analyzing Data: A Model Comparison Perspective\", Wadsworth, 1990.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        We'll test the following data sets for differences in their variance.\n",
      "        \n",
      "        >>> x = [10, 11, 13, 9, 7, 12, 12, 9, 10]\n",
      "        >>> y = [13, 21, 5, 10, 8, 14, 10, 12, 7, 15]\n",
      "        \n",
      "        Apply the O'Brien transform to the data.\n",
      "        \n",
      "        >>> tx, ty = obrientransform(x, y)\n",
      "        \n",
      "        Use `scipy.stats.f_oneway` to apply a one-way ANOVA test to the\n",
      "        transformed data.\n",
      "        \n",
      "        >>> from scipy.stats import f_oneway\n",
      "        >>> F, p = f_oneway(tx, ty)\n",
      "        >>> p\n",
      "        0.1314139477040335\n",
      "        \n",
      "        If we require that ``p < 0.05`` for significance, we cannot conclude\n",
      "        that the variances are different.\n",
      "    \n",
      "    oneway(*args, **kwds)\n",
      "        `oneway` is deprecated!\n",
      "        `oneway` was deprecated in scipy 0.13.0 and will be removed in 0.14.0.  Use `f_oneway` instead.\n",
      "        \n",
      "        Test for equal means in two or more samples from the\n",
      "            normal distribution.\n",
      "        \n",
      "            If the keyword parameter <equal_var> is true then the variances\n",
      "            are assumed to be equal, otherwise they are not assumed to\n",
      "            be equal (default).\n",
      "        \n",
      "            Return test statistic and the p-value giving the probability\n",
      "            of error if the null hypothesis (equal means) is rejected at this value.\n",
      "    \n",
      "    pdf_fromgamma(g1, g2, g3=0.0, g4=None)\n",
      "    \n",
      "    pearsonr(x, y)\n",
      "        Calculates a Pearson correlation coefficient and the p-value for testing\n",
      "        non-correlation.\n",
      "        \n",
      "        The Pearson correlation coefficient measures the linear relationship\n",
      "        between two datasets. Strictly speaking, Pearson's correlation requires\n",
      "        that each dataset be normally distributed. Like other correlation\n",
      "        coefficients, this one varies between -1 and +1 with 0 implying no\n",
      "        correlation. Correlations of -1 or +1 imply an exact linear\n",
      "        relationship. Positive correlations imply that as x increases, so does\n",
      "        y. Negative correlations imply that as x increases, y decreases.\n",
      "        \n",
      "        The p-value roughly indicates the probability of an uncorrelated system\n",
      "        producing datasets that have a Pearson correlation at least as extreme\n",
      "        as the one computed from these datasets. The p-values are not entirely\n",
      "        reliable but are probably reasonable for datasets larger than 500 or so.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : (N,) array_like\n",
      "            Input\n",
      "        y : (N,) array_like\n",
      "            Input\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        (Pearson's correlation coefficient,\n",
      "         2-tailed p-value)\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        http://www.statsoft.com/textbook/glosp.html#Pearson%20Correlation\n",
      "    \n",
      "    percentileofscore(a, score, kind='rank')\n",
      "        The percentile rank of a score relative to a list of scores.\n",
      "        \n",
      "        A `percentileofscore` of, for example, 80% means that 80% of the\n",
      "        scores in `a` are below the given score. In the case of gaps or\n",
      "        ties, the exact definition depends on the optional keyword, `kind`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Array of scores to which `score` is compared.\n",
      "        score : int or float\n",
      "            Score that is compared to the elements in `a`.\n",
      "        kind : {'rank', 'weak', 'strict', 'mean'}, optional\n",
      "            This optional parameter specifies the interpretation of the\n",
      "            resulting score:\n",
      "        \n",
      "            - \"rank\": Average percentage ranking of score.  In case of\n",
      "                      multiple matches, average the percentage rankings of\n",
      "                      all matching scores.\n",
      "            - \"weak\": This kind corresponds to the definition of a cumulative\n",
      "                      distribution function.  A percentileofscore of 80%\n",
      "                      means that 80% of values are less than or equal\n",
      "                      to the provided score.\n",
      "            - \"strict\": Similar to \"weak\", except that only values that are\n",
      "                        strictly less than the given score are counted.\n",
      "            - \"mean\": The average of the \"weak\" and \"strict\" scores, often used in\n",
      "                      testing.  See\n",
      "        \n",
      "                      http://en.wikipedia.org/wiki/Percentile_rank\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        pcos : float\n",
      "            Percentile-position of score (0-100) relative to `a`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Three-quarters of the given values lie below a given score:\n",
      "        \n",
      "        >>> percentileofscore([1, 2, 3, 4], 3)\n",
      "        75.0\n",
      "        \n",
      "        With multiple matches, note how the scores of the two matches, 0.6\n",
      "        and 0.8 respectively, are averaged:\n",
      "        \n",
      "        >>> percentileofscore([1, 2, 3, 3, 4], 3)\n",
      "        70.0\n",
      "        \n",
      "        Only 2/5 values are strictly less than 3:\n",
      "        \n",
      "        >>> percentileofscore([1, 2, 3, 3, 4], 3, kind='strict')\n",
      "        40.0\n",
      "        \n",
      "        But 4/5 values are less than or equal to 3:\n",
      "        \n",
      "        >>> percentileofscore([1, 2, 3, 3, 4], 3, kind='weak')\n",
      "        80.0\n",
      "        \n",
      "        The average between the weak and the strict scores is\n",
      "        \n",
      "        >>> percentileofscore([1, 2, 3, 3, 4], 3, kind='mean')\n",
      "        60.0\n",
      "    \n",
      "    pointbiserialr(x, y)\n",
      "        Calculates a point biserial correlation coefficient and the associated\n",
      "        p-value.\n",
      "        \n",
      "        The point biserial correlation is used to measure the relationship\n",
      "        between a binary variable, x, and a continuous variable, y. Like other\n",
      "        correlation coefficients, this one varies between -1 and +1 with 0\n",
      "        implying no correlation. Correlations of -1 or +1 imply a determinative\n",
      "        relationship.\n",
      "        \n",
      "        This function uses a shortcut formula but produces the same result as\n",
      "        `pearsonr`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like of bools\n",
      "            Input array.\n",
      "        y : array_like\n",
      "            Input array.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        r : float\n",
      "            R value\n",
      "        p-value : float\n",
      "            2-tailed p-value\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        http://en.wikipedia.org/wiki/Point-biserial_correlation_coefficient\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> a = np.array([0, 0, 0, 1, 1, 1, 1])\n",
      "        >>> b = np.arange(7)\n",
      "        >>> stats.pointbiserialr(a, b)\n",
      "        (0.8660254037844386, 0.011724811003954652)\n",
      "        >>> stats.pearsonr(a, b)\n",
      "        (0.86602540378443871, 0.011724811003954626)\n",
      "        >>> np.corrcoef(a, b)\n",
      "        array([[ 1.       ,  0.8660254],\n",
      "               [ 0.8660254,  1.       ]])\n",
      "    \n",
      "    power_divergence(f_obs, f_exp=None, ddof=0, axis=0, lambda_=None)\n",
      "        Cressie-Read power divergence statistic and goodness of fit test.\n",
      "        \n",
      "        This function tests the null hypothesis that the categorical data\n",
      "        has the given frequencies, using the Cressie-Read power divergence\n",
      "        statistic.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        f_obs : array\n",
      "            Observed frequencies in each category.\n",
      "        f_exp : array, optional\n",
      "            Expected frequencies in each category.  By default the categories are\n",
      "            assumed to be equally likely.\n",
      "        ddof : int, optional\n",
      "            \"Delta degrees of freedom\": adjustment to the degrees of freedom\n",
      "            for the p-value.  The p-value is computed using a chi-squared\n",
      "            distribution with ``k - 1 - ddof`` degrees of freedom, where `k`\n",
      "            is the number of observed frequencies.  The default value of `ddof`\n",
      "            is 0.\n",
      "        axis : int or None, optional\n",
      "            The axis of the broadcast result of `f_obs` and `f_exp` along which to\n",
      "            apply the test.  If axis is None, all values in `f_obs` are treated\n",
      "            as a single data set.  Default is 0.\n",
      "        lambda_ : float or str, optional\n",
      "            `lambda_` gives the power in the Cressie-Read power divergence\n",
      "            statistic.  The default is 1.  For convenience, `lambda_` may be\n",
      "            assigned one of the following strings, in which case the\n",
      "            corresponding numerical value is used::\n",
      "        \n",
      "                String              Value   Description\n",
      "                \"pearson\"             1     Pearson's chi-squared statistic.\n",
      "                                            In this case, the function is\n",
      "                                            equivalent to `stats.chisquare`.\n",
      "                \"log-likelihood\"      0     Log-likelihood ratio. Also known as\n",
      "                                            the G-test [3]_.\n",
      "                \"freeman-tukey\"      -1/2   Freeman-Tukey statistic.\n",
      "                \"mod-log-likelihood\" -1     Modified log-likelihood ratio.\n",
      "                \"neyman\"             -2     Neyman's statistic.\n",
      "                \"cressie-read\"        2/3   The power recommended in [5]_.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        stat : float or ndarray\n",
      "            The Cressie-Read power divergence test statistic.  The value is\n",
      "            a float if `axis` is None or if` `f_obs` and `f_exp` are 1-D.\n",
      "        p : float or ndarray\n",
      "            The p-value of the test.  The value is a float if `ddof` and the\n",
      "            return value `stat` are scalars.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        chisquare\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This test is invalid when the observed or expected frequencies in each\n",
      "        category are too small.  A typical rule is that all of the observed\n",
      "        and expected frequencies should be at least 5.\n",
      "        \n",
      "        When `lambda_` is less than zero, the formula for the statistic involves\n",
      "        dividing by `f_obs`, so a warning or error may be generated if any value\n",
      "        in `f_obs` is 0.\n",
      "        \n",
      "        Similarly, a warning or error may be generated if any value in `f_exp` is\n",
      "        zero when `lambda_` >= 0.\n",
      "        \n",
      "        The default degrees of freedom, k-1, are for the case when no parameters\n",
      "        of the distribution are estimated. If p parameters are estimated by\n",
      "        efficient maximum likelihood then the correct degrees of freedom are\n",
      "        k-1-p. If the parameters are estimated in a different way, then the\n",
      "        dof can be between k-1-p and k-1. However, it is also possible that\n",
      "        the asymptotic distribution is not a chisquare, in which case this\n",
      "        test is not appropriate.\n",
      "        \n",
      "        This function handles masked arrays.  If an element of `f_obs` or `f_exp`\n",
      "        is masked, then data at that position is ignored, and does not count\n",
      "        towards the size of the data set.\n",
      "        \n",
      "        .. versionadded:: 0.13.0\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Lowry, Richard.  \"Concepts and Applications of Inferential\n",
      "               Statistics\". Chapter 8. http://faculty.vassar.edu/lowry/ch8pt1.html\n",
      "        .. [2] \"Chi-squared test\", http://en.wikipedia.org/wiki/Chi-squared_test\n",
      "        .. [3] \"G-test\", http://en.wikipedia.org/wiki/G-test\n",
      "        .. [4] Sokal, R. R. and Rohlf, F. J. \"Biometry: the principles and\n",
      "               practice of statistics in biological research\", New York: Freeman\n",
      "               (1981)\n",
      "        .. [5] Cressie, N. and Read, T. R. C., \"Multinomial Goodness-of-Fit\n",
      "               Tests\", J. Royal Stat. Soc. Series B, Vol. 46, No. 3 (1984),\n",
      "               pp. 440-464.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        \n",
      "        (See `chisquare` for more examples.)\n",
      "        \n",
      "        When just `f_obs` is given, it is assumed that the expected frequencies\n",
      "        are uniform and given by the mean of the observed frequencies.  Here we\n",
      "        perform a G-test (i.e. use the log-likelihood ratio statistic):\n",
      "        \n",
      "        >>> power_divergence([16, 18, 16, 14, 12, 12], method='log-likelihood')\n",
      "        (2.006573162632538, 0.84823476779463769)\n",
      "        \n",
      "        The expected frequencies can be given with the `f_exp` argument:\n",
      "        \n",
      "        >>> power_divergence([16, 18, 16, 14, 12, 12],\n",
      "        ...                  f_exp=[16, 16, 16, 16, 16, 8],\n",
      "        ...                  lambda_='log-likelihood')\n",
      "        (3.5, 0.62338762774958223)\n",
      "        \n",
      "        When `f_obs` is 2-D, by default the test is applied to each column.\n",
      "        \n",
      "        >>> obs = np.array([[16, 18, 16, 14, 12, 12], [32, 24, 16, 28, 20, 24]]).T\n",
      "        >>> obs.shape\n",
      "        (6, 2)\n",
      "        >>> power_divergence(obs, lambda_=\"log-likelihood\")\n",
      "        (array([ 2.00657316,  6.77634498]), array([ 0.84823477,  0.23781225]))\n",
      "        \n",
      "        By setting ``axis=None``, the test is applied to all data in the array,\n",
      "        which is equivalent to applying the test to the flattened array.\n",
      "        \n",
      "        >>> power_divergence(obs, axis=None)\n",
      "        (23.31034482758621, 0.015975692534127565)\n",
      "        >>> power_divergence(obs.ravel())\n",
      "        (23.31034482758621, 0.015975692534127565)\n",
      "        \n",
      "        `ddof` is the change to make to the default degrees of freedom.\n",
      "        \n",
      "        >>> power_divergence([16, 18, 16, 14, 12, 12], ddof=1)\n",
      "        (2.0, 0.73575888234288467)\n",
      "        \n",
      "        The calculation of the p-values is done by broadcasting the\n",
      "        test statistic with `ddof`.\n",
      "        \n",
      "        >>> power_divergence([16, 18, 16, 14, 12, 12], ddof=[0,1,2])\n",
      "        (2.0, array([ 0.84914504,  0.73575888,  0.5724067 ]))\n",
      "        \n",
      "        `f_obs` and `f_exp` are also broadcast.  In the following, `f_obs` has\n",
      "        shape (6,) and `f_exp` has shape (2, 6), so the result of broadcasting\n",
      "        `f_obs` and `f_exp` has shape (2, 6).  To compute the desired chi-squared\n",
      "        statistics, we must use ``axis=1``:\n",
      "        \n",
      "        >>> power_divergence([16, 18, 16, 14, 12, 12],\n",
      "        ...                  f_exp=[[16, 16, 16, 16, 16, 8],\n",
      "        ...                         [8, 20, 20, 16, 12, 12]],\n",
      "        ...                  axis=1)\n",
      "        (array([ 3.5 ,  9.25]), array([ 0.62338763,  0.09949846]))\n",
      "    \n",
      "    ppcc_max(x, brack=(0.0, 1.0), dist='tukeylambda')\n",
      "        Returns the shape parameter that maximizes the probability plot\n",
      "        correlation coefficient for the given data to a one-parameter\n",
      "        family of distributions.\n",
      "        \n",
      "        See also ppcc_plot\n",
      "    \n",
      "    ppcc_plot(x, a, b, dist='tukeylambda', plot=None, N=80)\n",
      "        Returns (shape, ppcc), and optionally plots shape vs. ppcc\n",
      "        (probability plot correlation coefficient) as a function of shape\n",
      "        parameter for a one-parameter family of distributions from shape\n",
      "        value a to b.\n",
      "        \n",
      "        See also ppcc_max\n",
      "    \n",
      "    probplot(x, sparams=(), dist='norm', fit=True, plot=None)\n",
      "        Calculate quantiles for a probability plot of sample data against a\n",
      "        specified theoretical distribution.\n",
      "        \n",
      "        `probplot` optionally calculates a best-fit line for the data and plots the\n",
      "        results using Matplotlib or a given plot function.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Sample/response data from which `probplot` creates the plot.\n",
      "        sparams : tuple, optional\n",
      "            Distribution-specific shape parameters (location(s) and scale(s)).\n",
      "        dist : str, optional\n",
      "            Distribution function name. The default is 'norm' for a normal\n",
      "            probability plot.\n",
      "        fit : bool, optional\n",
      "            Fit a least-squares regression (best-fit) line to the sample data if\n",
      "            True (default).\n",
      "        plot : object, optional\n",
      "            If given, plots the quantiles and least squares fit.\n",
      "            `plot` is an object with methods \"plot\", \"title\", \"xlabel\", \"ylabel\"\n",
      "            and \"text\". The matplotlib.pyplot module or a Matplotlib axes object\n",
      "            can be used, or a custom object with the same methods.\n",
      "            By default, no plot is created.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        (osm, osr) : tuple of ndarrays\n",
      "            Tuple of theoretical quantiles (osm, or order statistic medians) and\n",
      "            ordered responses (osr).\n",
      "        (slope, intercept, r) : tuple of floats, optional\n",
      "            Tuple  containing the result of the least-squares fit, if that is\n",
      "            performed by `probplot`. `r` is the square root of the coefficient of\n",
      "            determination.  If ``fit=False`` and ``plot=None``, this tuple is not\n",
      "            returned.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Even if `plot` is given, the figure is not shown or saved by `probplot`;\n",
      "        ``plot.show()`` or ``plot.savefig('figname.png')`` should be used after\n",
      "        calling `probplot`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import scipy.stats as stats\n",
      "        >>> nsample = 100\n",
      "        >>> np.random.seed(7654321)\n",
      "        \n",
      "        A t distribution with small degrees of freedom:\n",
      "        \n",
      "        >>> ax1 = plt.subplot(221)\n",
      "        >>> x = stats.t.rvs(3, size=nsample)\n",
      "        >>> res = stats.probplot(x, plot=plt)\n",
      "        \n",
      "        A t distribution with larger degrees of freedom:\n",
      "        \n",
      "        >>> ax2 = plt.subplot(222)\n",
      "        >>> x = stats.t.rvs(25, size=nsample)\n",
      "        >>> res = stats.probplot(x, plot=plt)\n",
      "        \n",
      "        A mixture of 2 normal distributions with broadcasting:\n",
      "        \n",
      "        >>> ax3 = plt.subplot(223)\n",
      "        >>> x = stats.norm.rvs(loc=[0,5], scale=[1,1.5],\n",
      "        ...                    size=(nsample/2.,2)).ravel()\n",
      "        >>> res = stats.probplot(x, plot=plt)\n",
      "        \n",
      "        A standard normal distribution:\n",
      "        \n",
      "        >>> ax4 = plt.subplot(224)\n",
      "        >>> x = stats.norm.rvs(loc=0, scale=1, size=nsample)\n",
      "        >>> res = stats.probplot(x, plot=plt)\n",
      "    \n",
      "    randwcdf(cdf, mean=1.0, args=(), size=None)\n",
      "        Returns an array of randomly distributed integers given a CDF.\n",
      "        \n",
      "        Given a cumulative distribution function (CDF) returns an array of\n",
      "        randomly distributed integers that would satisfy the CDF.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        cdf : function\n",
      "            CDF function that accepts a single value and `args`, and returns\n",
      "            an single value.\n",
      "        mean : float, optional\n",
      "            The mean of the distribution which helps the solver.  Defaults\n",
      "            to 1.0.\n",
      "        args : tuple, optional\n",
      "            Extra arguments to the cdf function (i.e. shape, location, scale)\n",
      "        size : {int, None}, optional\n",
      "            Is the size of the output.  If None, only 1 value will be returned.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        randwcdf : ndarray\n",
      "            Array of random numbers.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Can use the ``scipy.stats.distributions.*.cdf`` functions for the\n",
      "        `cdf` parameter.\n",
      "    \n",
      "    randwppf(ppf, args=(), size=None)\n",
      "        returns an array of randomly distributed integers of a distribution\n",
      "        whose percent point function (inverse of the CDF or quantile function)\n",
      "        is given.\n",
      "        \n",
      "        args is a tuple of extra arguments to the ppf function (i.e. shape,\n",
      "        location, scale), and size is the size of the output.  Note the ppf\n",
      "        function must accept an array of q values to compute over.\n",
      "    \n",
      "    rankdata(...)\n",
      "        rankdata(a, method='average')\n",
      "        \n",
      "        Assign ranks to data, dealing with ties appropriately.\n",
      "        \n",
      "        Ranks begin at 1.  The `method` argument controls how ranks are assigned\n",
      "        to equal values.  See [1]_ for further discussion of ranking methods.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            The array of values to be ranked.  The array is first flattened.\n",
      "        method : str, optional\n",
      "            The method used to assign ranks to tied elements.\n",
      "            The options are 'average', 'min', 'max', 'dense' and 'ordinal'.\n",
      "        \n",
      "            'average':\n",
      "                The average of the ranks that would have been assigned to\n",
      "                all the tied values is assigned to each value.\n",
      "            'min':\n",
      "                The minimum of the ranks that would have been assigned to all\n",
      "                the tied values is assigned to each value.  (This is also\n",
      "                referred to as \"competition\" ranking.)\n",
      "            'max':\n",
      "                The maximum of the ranks that would have been assigned to all\n",
      "                the tied values is assigned to each value.\n",
      "            'dense':\n",
      "                Like 'min', but the rank of the next highest element is assigned\n",
      "                the rank immediately after those assigned to the tied elements.\n",
      "            'ordinal':\n",
      "                All values are given a distinct rank, corresponding to the order\n",
      "                that the values occur in `a`.\n",
      "        \n",
      "            The default is 'average'.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        ranks : ndarray\n",
      "             An array of length equal to the size of `a`, containing rank\n",
      "             scores.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        All floating point types are converted to numpy.float64 before ranking.\n",
      "        This may result in spurious ties if an input array of floats has a wider\n",
      "        data type than numpy.float64 (e.g. numpy.float128).\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] \"Ranking\", http://en.wikipedia.org/wiki/Ranking\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> rankdata([0, 2, 3, 2])\n",
      "        array([ 1. ,  2.5,  4. ,  2.5])\n",
      "        >>> rankdata([0, 2, 3, 2], method='min')\n",
      "        array([ 1.,  2.,  4.,  2.])\n",
      "        >>> rankdata([0, 2, 3, 2], method='max')\n",
      "        array([ 1.,  3.,  4.,  3.])\n",
      "        >>> rankdata([0, 2, 3, 2], method='dense')\n",
      "        array([ 1.,  2.,  3.,  2.])\n",
      "        >>> rankdata([0, 2, 3, 2], method='ordinal')\n",
      "        array([ 1.,  2.,  4.,  3.])\n",
      "    \n",
      "    ranksums(x, y)\n",
      "        Compute the Wilcoxon rank-sum statistic for two samples.\n",
      "        \n",
      "        The Wilcoxon rank-sum test tests the null hypothesis that two sets\n",
      "        of measurements are drawn from the same distribution.  The alternative\n",
      "        hypothesis is that values in one sample are more likely to be\n",
      "        larger than the values in the other sample.\n",
      "        \n",
      "        This test should be used to compare two samples from continuous\n",
      "        distributions.  It does not handle ties between measurements\n",
      "        in x and y.  For tie-handling and an optional continuity correction\n",
      "        see `scipy.stats.mannwhitneyu`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x,y : array_like\n",
      "            The data from the two samples\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        z-statistic : float\n",
      "            The test statistic under the large-sample approximation that the\n",
      "            rank sum statistic is normally distributed\n",
      "        p-value : float\n",
      "            The two-sided p-value of the test\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] http://en.wikipedia.org/wiki/Wilcoxon_rank-sum_test\n",
      "    \n",
      "    relfreq(a, numbins=10, defaultreallimits=None, weights=None)\n",
      "        Returns a relative frequency histogram, using the histogram function.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Input array.\n",
      "        numbins : int, optional\n",
      "            The number of bins to use for the histogram. Default is 10.\n",
      "        defaultreallimits : tuple (lower, upper), optional\n",
      "            The lower and upper values for the range of the histogram.\n",
      "            If no value is given, a range slightly larger then the range of the\n",
      "            values in a is used. Specifically ``(a.min() - s, a.max() + s)``,\n",
      "                where ``s = (1/2)(a.max() - a.min()) / (numbins - 1)``.\n",
      "        weights : array_like, optional\n",
      "            The weights for each value in `a`. Default is None, which gives each\n",
      "            value a weight of 1.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        relfreq : ndarray\n",
      "            Binned values of relative frequency.\n",
      "        lowerreallimit : float\n",
      "            Lower real limit\n",
      "        binsize : float\n",
      "            Width of each bin.\n",
      "        extrapoints : int\n",
      "            Extra points.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> a = np.array([1, 4, 2, 1, 3, 1])\n",
      "        >>> relfreqs, lowlim, binsize, extrapoints = sp.stats.relfreq(a, numbins=4)\n",
      "        >>> relfreqs\n",
      "        array([ 0.5       ,  0.16666667,  0.16666667,  0.16666667])\n",
      "        >>> np.sum(relfreqs)  # relative frequencies should add up to 1\n",
      "        0.99999999999999989\n",
      "    \n",
      "    scoreatpercentile(a, per, limit=(), interpolation_method='fraction', axis=None)\n",
      "        Calculate the score at a given percentile of the input sequence.\n",
      "        \n",
      "        For example, the score at `per=50` is the median. If the desired quantile\n",
      "        lies between two data points, we interpolate between them, according to\n",
      "        the value of `interpolation`. If the parameter `limit` is provided, it\n",
      "        should be a tuple (lower, upper) of two values.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            A 1-D array of values from which to extract score.\n",
      "        per : array_like\n",
      "            Percentile(s) at which to extract score.  Values should be in range\n",
      "            [0,100].\n",
      "        limit : tuple, optional\n",
      "            Tuple of two scalars, the lower and upper limits within which to\n",
      "            compute the percentile. Values of `a` outside\n",
      "            this (closed) interval will be ignored.\n",
      "        interpolation : {'fraction', 'lower', 'higher'}, optional\n",
      "            This optional parameter specifies the interpolation method to use,\n",
      "            when the desired quantile lies between two data points `i` and `j`\n",
      "        \n",
      "              - fraction: ``i + (j - i) * fraction`` where ``fraction`` is the\n",
      "                fractional part of the index surrounded by ``i`` and ``j``.\n",
      "              - lower: ``i``.\n",
      "              - higher: ``j``.\n",
      "        \n",
      "        axis : int, optional\n",
      "            Axis along which the percentiles are computed. The default (None)\n",
      "            is to compute the median along a flattened version of the array.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        score : float (or sequence of floats)\n",
      "            Score at percentile.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        percentileofscore\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> a = np.arange(100)\n",
      "        >>> stats.scoreatpercentile(a, 50)\n",
      "        49.5\n",
      "    \n",
      "    sem(a, axis=0, ddof=1)\n",
      "        Calculates the standard error of the mean (or standard error of\n",
      "        measurement) of the values in the input array.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            An array containing the values for which the standard error is\n",
      "            returned.\n",
      "        axis : int or None, optional.\n",
      "            If axis is None, ravel `a` first. If axis is an integer, this will be\n",
      "            the axis over which to operate. Defaults to 0.\n",
      "        ddof : int, optional\n",
      "            Delta degrees-of-freedom. How many degrees of freedom to adjust\n",
      "            for bias in limited samples relative to the population estimate\n",
      "            of variance. Defaults to 1.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        s : ndarray or float\n",
      "            The standard error of the mean in the sample(s), along the input axis.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The default value for `ddof` is different to the default (0) used by other\n",
      "        ddof containing routines, such as np.std nd stats.nanstd.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Find standard error along the first axis:\n",
      "        \n",
      "        >>> from scipy import stats\n",
      "        >>> a = np.arange(20).reshape(5,4)\n",
      "        >>> stats.sem(a)\n",
      "        array([ 2.8284,  2.8284,  2.8284,  2.8284])\n",
      "        \n",
      "        Find standard error across the whole array, using n degrees of freedom:\n",
      "        \n",
      "        >>> stats.sem(a, axis=None, ddof=0)\n",
      "        1.2893796958227628\n",
      "    \n",
      "    shapiro(x, a=None, reta=False)\n",
      "        Perform the Shapiro-Wilk test for normality.\n",
      "        \n",
      "        The Shapiro-Wilk test tests the null hypothesis that the\n",
      "        data was drawn from a normal distribution.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Array of sample data.\n",
      "        a : array_like, optional\n",
      "            Array of internal parameters used in the calculation.  If these\n",
      "            are not given, they will be computed internally.  If x has length\n",
      "            n, then a must have length n/2.\n",
      "        reta : bool, optional\n",
      "            Whether or not to return the internally computed a values.  The\n",
      "            default is False.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        W : float\n",
      "            The test statistic.\n",
      "        p-value : float\n",
      "            The p-value for the hypothesis test.\n",
      "        a : array_like, optional\n",
      "            If `reta` is True, then these are the internally computed \"a\"\n",
      "            values that may be passed into this function on future calls.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        anderson : The Anderson-Darling test for normality\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] http://www.itl.nist.gov/div898/handbook/prc/section2/prc213.htm\n",
      "    \n",
      "    sigmaclip(a, low=4.0, high=4.0)\n",
      "        Iterative sigma-clipping of array elements.\n",
      "        \n",
      "        The output array contains only those elements of the input array `c`\n",
      "        that satisfy the conditions ::\n",
      "        \n",
      "            mean(c) - std(c)*low < c < mean(c) + std(c)*high\n",
      "        \n",
      "        Starting from the full sample, all elements outside the critical range are\n",
      "        removed. The iteration continues with a new critical range until no\n",
      "        elements are outside the range.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Data array, will be raveled if not 1-D.\n",
      "        low : float, optional\n",
      "            Lower bound factor of sigma clipping. Default is 4.\n",
      "        high : float, optional\n",
      "            Upper bound factor of sigma clipping. Default is 4.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        c : ndarray\n",
      "            Input array with clipped elements removed.\n",
      "        critlower : float\n",
      "            Lower threshold value use for clipping.\n",
      "        critlupper : float\n",
      "            Upper threshold value use for clipping.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> a = np.concatenate((np.linspace(9.5,10.5,31), np.linspace(0,20,5)))\n",
      "        >>> fact = 1.5\n",
      "        >>> c, low, upp = sigmaclip(a, fact, fact)\n",
      "        >>> c\n",
      "        array([  9.96666667,  10.        ,  10.03333333,  10.        ])\n",
      "        >>> c.var(), c.std()\n",
      "        (0.00055555555555555165, 0.023570226039551501)\n",
      "        >>> low, c.mean() - fact*c.std(), c.min()\n",
      "        (9.9646446609406727, 9.9646446609406727, 9.9666666666666668)\n",
      "        >>> upp, c.mean() + fact*c.std(), c.max()\n",
      "        (10.035355339059327, 10.035355339059327, 10.033333333333333)\n",
      "        \n",
      "        >>> a = np.concatenate((np.linspace(9.5,10.5,11),\n",
      "            np.linspace(-100,-50,3)))\n",
      "        >>> c, low, upp = sigmaclip(a, 1.8, 1.8)\n",
      "        >>> (c == np.linspace(9.5,10.5,11)).all()\n",
      "        True\n",
      "    \n",
      "    signaltonoise(a, axis=0, ddof=0)\n",
      "        The signal-to-noise ratio of the input data.\n",
      "        \n",
      "        Returns the signal-to-noise ratio of `a`, here defined as the mean\n",
      "        divided by the standard deviation.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            An array_like object containing the sample data.\n",
      "        axis : int or None, optional\n",
      "            If axis is equal to None, the array is first ravel'd. If axis is an\n",
      "            integer, this is the axis over which to operate. Default is 0.\n",
      "        ddof : int, optional\n",
      "            Degrees of freedom correction for standard deviation. Default is 0.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        s2n : ndarray\n",
      "            The mean to standard deviation ratio(s) along `axis`, or 0 where the\n",
      "            standard deviation is 0.\n",
      "    \n",
      "    skew(a, axis=0, bias=True)\n",
      "        Computes the skewness of a data set.\n",
      "        \n",
      "        For normally distributed data, the skewness should be about 0. A skewness\n",
      "        value > 0 means that there is more weight in the left tail of the\n",
      "        distribution. The function `skewtest` can be used to determine if the\n",
      "        skewness value is close enough to 0, statistically speaking.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : ndarray\n",
      "            data\n",
      "        axis : int or None\n",
      "            axis along which skewness is calculated\n",
      "        bias : bool\n",
      "            If False, then the calculations are corrected for statistical bias.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        skewness : ndarray\n",
      "            The skewness of values along an axis, returning 0 where all values are\n",
      "            equal.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        [CRCProbStat2000]_ Section 2.2.24.1\n",
      "        \n",
      "        .. [CRCProbStat2000] Zwillinger, D. and Kokoska, S. (2000). CRC Standard\n",
      "           Probability and Statistics Tables and Formulae. Chapman & Hall: New\n",
      "           York. 2000.\n",
      "    \n",
      "    skewtest(a, axis=0)\n",
      "        Tests whether the skew is different from the normal distribution.\n",
      "        \n",
      "        This function tests the null hypothesis that the skewness of\n",
      "        the population that the sample was drawn from is the same\n",
      "        as that of a corresponding normal distribution.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array\n",
      "        axis : int or None\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        z-score : float\n",
      "            The computed z-score for this test.\n",
      "        p-value : float\n",
      "            a 2-sided p-value for the hypothesis test\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The sample size must be at least 8.\n",
      "    \n",
      "    spearmanr(a, b=None, axis=0)\n",
      "        Calculates a Spearman rank-order correlation coefficient and the p-value\n",
      "        to test for non-correlation.\n",
      "        \n",
      "        The Spearman correlation is a nonparametric measure of the monotonicity\n",
      "        of the relationship between two datasets. Unlike the Pearson correlation,\n",
      "        the Spearman correlation does not assume that both datasets are normally\n",
      "        distributed. Like other correlation coefficients, this one varies\n",
      "        between -1 and +1 with 0 implying no correlation. Correlations of -1 or\n",
      "        +1 imply an exact monotonic relationship. Positive correlations imply that\n",
      "        as x increases, so does y. Negative correlations imply that as x\n",
      "        increases, y decreases.\n",
      "        \n",
      "        The p-value roughly indicates the probability of an uncorrelated system\n",
      "        producing datasets that have a Spearman correlation at least as extreme\n",
      "        as the one computed from these datasets. The p-values are not entirely\n",
      "        reliable but are probably reasonable for datasets larger than 500 or so.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a, b : 1D or 2D array_like, b is optional\n",
      "            One or two 1-D or 2-D arrays containing multiple variables and\n",
      "            observations. Each column of `a` and `b` represents a variable, and\n",
      "            each row entry a single observation of those variables. See also\n",
      "            `axis`. Both arrays need to have the same length in the `axis`\n",
      "            dimension.\n",
      "        axis : int or None, optional\n",
      "            If axis=0 (default), then each column represents a variable, with\n",
      "            observations in the rows. If axis=0, the relationship is transposed:\n",
      "            each row represents a variable, while the columns contain observations.\n",
      "            If axis=None, then both arrays will be raveled.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        rho : float or ndarray (2-D square)\n",
      "            Spearman correlation matrix or correlation coefficient (if only 2\n",
      "            variables are given as parameters. Correlation matrix is square with\n",
      "            length equal to total number of variables (columns or rows) in a and b\n",
      "            combined.\n",
      "        p-value : float\n",
      "            The two-sided p-value for a hypothesis test whose null hypothesis is\n",
      "            that two sets of data are uncorrelated, has same dimension as rho.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Changes in scipy 0.8.0: rewrite to add tie-handling, and axis.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        [CRCProbStat2000]_ Section  14.7\n",
      "        \n",
      "        .. [CRCProbStat2000] Zwillinger, D. and Kokoska, S. (2000). CRC Standard\n",
      "           Probability and Statistics Tables and Formulae. Chapman & Hall: New\n",
      "           York. 2000.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> spearmanr([1,2,3,4,5],[5,6,7,8,7])\n",
      "        (0.82078268166812329, 0.088587005313543798)\n",
      "        >>> np.random.seed(1234321)\n",
      "        >>> x2n=np.random.randn(100,2)\n",
      "        >>> y2n=np.random.randn(100,2)\n",
      "        >>> spearmanr(x2n)\n",
      "        (0.059969996999699973, 0.55338590803773591)\n",
      "        >>> spearmanr(x2n[:,0], x2n[:,1])\n",
      "        (0.059969996999699973, 0.55338590803773591)\n",
      "        >>> rho, pval = spearmanr(x2n,y2n)\n",
      "        >>> rho\n",
      "        array([[ 1.        ,  0.05997   ,  0.18569457,  0.06258626],\n",
      "               [ 0.05997   ,  1.        ,  0.110003  ,  0.02534653],\n",
      "               [ 0.18569457,  0.110003  ,  1.        ,  0.03488749],\n",
      "               [ 0.06258626,  0.02534653,  0.03488749,  1.        ]])\n",
      "        >>> pval\n",
      "        array([[ 0.        ,  0.55338591,  0.06435364,  0.53617935],\n",
      "               [ 0.55338591,  0.        ,  0.27592895,  0.80234077],\n",
      "               [ 0.06435364,  0.27592895,  0.        ,  0.73039992],\n",
      "               [ 0.53617935,  0.80234077,  0.73039992,  0.        ]])\n",
      "        >>> rho, pval = spearmanr(x2n.T, y2n.T, axis=1)\n",
      "        >>> rho\n",
      "        array([[ 1.        ,  0.05997   ,  0.18569457,  0.06258626],\n",
      "               [ 0.05997   ,  1.        ,  0.110003  ,  0.02534653],\n",
      "               [ 0.18569457,  0.110003  ,  1.        ,  0.03488749],\n",
      "               [ 0.06258626,  0.02534653,  0.03488749,  1.        ]])\n",
      "        >>> spearmanr(x2n, y2n, axis=None)\n",
      "        (0.10816770419260482, 0.1273562188027364)\n",
      "        >>> spearmanr(x2n.ravel(), y2n.ravel())\n",
      "        (0.10816770419260482, 0.1273562188027364)\n",
      "        \n",
      "        >>> xint = np.random.randint(10,size=(100,2))\n",
      "        >>> spearmanr(xint)\n",
      "        (0.052760927029710199, 0.60213045837062351)\n",
      "    \n",
      "    square_of_sums(a, axis=0)\n",
      "        Sums elements of the input array, and returns the square(s) of that sum.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Input array.\n",
      "        axis : int or None, optional\n",
      "            If axis is None, ravel `a` first. If `axis` is an integer, this will\n",
      "            be the axis over which to operate. Defaults to 0.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        square_of_sums : float or ndarray\n",
      "            The square of the sum over `axis`.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        ss : The sum of squares (the opposite of `square_of_sums`).\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> a = np.arange(20).reshape(5,4)\n",
      "        >>> stats.square_of_sums(a)\n",
      "        array([ 1600.,  2025.,  2500.,  3025.])\n",
      "        >>> stats.square_of_sums(a, axis=None)\n",
      "        36100.0\n",
      "    \n",
      "    ss(a, axis=0)\n",
      "        Squares each element of the input array, and returns the sum(s) of that.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Input array.\n",
      "        axis : int or None, optional\n",
      "            The axis along which to calculate. If None, use whole array.\n",
      "            Default is 0, i.e. along the first axis.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        ss : ndarray\n",
      "            The sum along the given axis for (a**2).\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        square_of_sums : The square(s) of the sum(s) (the opposite of `ss`).\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> a = np.array([1., 2., 5.])\n",
      "        >>> stats.ss(a)\n",
      "        30.0\n",
      "        \n",
      "        And calculating along an axis:\n",
      "        \n",
      "        >>> b = np.array([[1., 2., 5.], [2., 5., 6.]])\n",
      "        >>> stats.ss(b, axis=1)\n",
      "        array([ 30., 65.])\n",
      "    \n",
      "    threshold(a, threshmin=None, threshmax=None, newval=0)\n",
      "        Clip array to a given value.\n",
      "        \n",
      "        Similar to numpy.clip(), except that values less than `threshmin` or\n",
      "        greater than `threshmax` are replaced by `newval`, instead of by\n",
      "        `threshmin` and `threshmax` respectively.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Data to threshold.\n",
      "        threshmin : float, int or None, optional\n",
      "            Minimum threshold, defaults to None.\n",
      "        threshmax : float, int or None, optional\n",
      "            Maximum threshold, defaults to None.\n",
      "        newval : float or int, optional\n",
      "            Value to put in place of values in `a` outside of bounds.\n",
      "            Defaults to 0.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray\n",
      "            The clipped input array, with values less than `threshmin` or\n",
      "            greater than `threshmax` replaced with `newval`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> a = np.array([9, 9, 6, 3, 1, 6, 1, 0, 0, 8])\n",
      "        >>> from scipy import stats\n",
      "        >>> stats.threshold(a, threshmin=2, threshmax=8, newval=-1)\n",
      "        array([-1, -1,  6,  3, -1,  6, -1, -1, -1,  8])\n",
      "    \n",
      "    tiecorrect(...)\n",
      "        tiecorrect(rankvals)\n",
      "        \n",
      "        Tie correction factor for ties in the Mann-Whitney U and\n",
      "        Kruskal-Wallis H tests.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        rankvals : array_like\n",
      "            A 1-D sequence of ranks.  Typically this will be the array\n",
      "            returned by `stats.rankdata`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        factor : float\n",
      "            Correction factor for U or H.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        rankdata : Assign ranks to the data\n",
      "        mannwhitneyu : Mann-Whitney rank test\n",
      "        kruskal : Kruskal-Wallis H test\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Siegel, S. (1956) Nonparametric Statistics for the Behavioral\n",
      "               Sciences.  New York: McGraw-Hill.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> tiecorrect([1, 2.5, 2.5, 4])\n",
      "        0.9\n",
      "        >>> ranks = rankdata([1, 3, 2, 4, 5, 7, 2, 8, 4])\n",
      "        >>> ranks\n",
      "        array([ 1. ,  4. ,  2.5,  5.5,  7. ,  8. ,  2.5,  9. ,  5.5])\n",
      "        >>> tiecorrect(ranks)\n",
      "        0.9833333333333333\n",
      "    \n",
      "    tmax(a, upperlimit, axis=0, inclusive=True)\n",
      "        Compute the trimmed maximum\n",
      "        \n",
      "        This function computes the maximum value of an array along a given axis,\n",
      "        while ignoring values larger than a specified upper limit.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            array of values\n",
      "        upperlimit : None or float, optional\n",
      "            Values in the input array greater than the given limit will be ignored.\n",
      "            When upperlimit is None, then all values are used. The default value\n",
      "            is None.\n",
      "        axis : None or int, optional\n",
      "            Operate along this axis.  None means to use the flattened array and\n",
      "            the default is zero.\n",
      "        inclusive : {True, False}, optional\n",
      "            This flag determines whether values exactly equal to the upper limit\n",
      "            are included.  The default value is True.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        tmax : float\n",
      "    \n",
      "    tmean(a, limits=None, inclusive=(True, True))\n",
      "        Compute the trimmed mean\n",
      "        \n",
      "        This function finds the arithmetic mean of given values, ignoring values\n",
      "        outside the given `limits`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            array of values\n",
      "        limits : None or (lower limit, upper limit), optional\n",
      "            Values in the input array less than the lower limit or greater than the\n",
      "            upper limit will be ignored. When limits is None, then all values are\n",
      "            used. Either of the limit values in the tuple can also be None\n",
      "            representing a half-open interval.  The default value is None.\n",
      "        inclusive : (bool, bool), optional\n",
      "            A tuple consisting of the (lower flag, upper flag).  These flags\n",
      "            determine whether values exactly equal to the lower or upper limits\n",
      "            are included.  The default value is (True, True).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        tmean : float\n",
      "    \n",
      "    tmin(a, lowerlimit=None, axis=0, inclusive=True)\n",
      "        Compute the trimmed minimum\n",
      "        \n",
      "        This function finds the miminum value of an array `a` along the\n",
      "        specified axis, but only considering values greater than a specified\n",
      "        lower limit.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            array of values\n",
      "        lowerlimit : None or float, optional\n",
      "            Values in the input array less than the given limit will be ignored.\n",
      "            When lowerlimit is None, then all values are used. The default value\n",
      "            is None.\n",
      "        axis : None or int, optional\n",
      "            Operate along this axis.  None means to use the flattened array and\n",
      "            the default is zero\n",
      "        inclusive : {True, False}, optional\n",
      "            This flag determines whether values exactly equal to the lower limit\n",
      "            are included.  The default value is True.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        tmin : float\n",
      "    \n",
      "    trim1(a, proportiontocut, tail='right')\n",
      "        Slices off a proportion of items from ONE end of the passed array\n",
      "        distribution.\n",
      "        \n",
      "        If `proportiontocut` = 0.1, slices off 'leftmost' or 'rightmost'\n",
      "        10% of scores.  Slices off LESS if proportion results in a non-integer\n",
      "        slice index (i.e., conservatively slices off `proportiontocut` ).\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Input array\n",
      "        proportiontocut : float\n",
      "            Fraction to cut off of 'left' or 'right' of distribution\n",
      "        tail : {'left', 'right'}, optional\n",
      "            Defaults to 'right'.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        trim1 : ndarray\n",
      "            Trimmed version of array `a`\n",
      "    \n",
      "    trim_mean(a, proportiontocut, axis=0)\n",
      "        Return mean of array after trimming distribution from both lower and upper\n",
      "        tails.\n",
      "        \n",
      "        If `proportiontocut` = 0.1, slices off 'leftmost' and 'rightmost' 10% of\n",
      "        scores. Slices off LESS if proportion results in a non-integer slice\n",
      "        index (i.e., conservatively slices off `proportiontocut` ).\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Input array\n",
      "        proportiontocut : float\n",
      "            Fraction to cut off of both tails of the distribution\n",
      "        axis : int or None, optional\n",
      "            Axis along which the trimmed means are computed. The default is axis=0.\n",
      "            If axis is None then the trimmed mean will be computed for the\n",
      "            flattened array.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        trim_mean : ndarray\n",
      "            Mean of trimmed array.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        trimboth\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> x = np.arange(20)\n",
      "        >>> stats.trim_mean(x, 0.1)\n",
      "        9.5\n",
      "        >>> x2 = x.reshape(5, 4)\n",
      "        >>> x2\n",
      "        array([[ 0,  1,  2,  3],\n",
      "               [ 4,  5,  6,  7],\n",
      "               [ 8,  9, 10, 11],\n",
      "               [12, 13, 14, 15],\n",
      "               [16, 17, 18, 19]])\n",
      "        >>> stats.trim_mean(x2, 0.25)\n",
      "        array([  8.,   9.,  10.,  11.])\n",
      "        >>> stats.trim_mean(x2, 0.25, axis=1)\n",
      "        array([  1.5,   5.5,   9.5,  13.5,  17.5])\n",
      "    \n",
      "    trimboth(a, proportiontocut, axis=0)\n",
      "        Slices off a proportion of items from both ends of an array.\n",
      "        \n",
      "        Slices off the passed proportion of items from both ends of the passed\n",
      "        array (i.e., with `proportiontocut` = 0.1, slices leftmost 10% **and**\n",
      "        rightmost 10% of scores).  You must pre-sort the array if you want\n",
      "        'proper' trimming.  Slices off less if proportion results in a\n",
      "        non-integer slice index (i.e., conservatively slices off\n",
      "        `proportiontocut`).\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Data to trim.\n",
      "        proportiontocut : float\n",
      "            Proportion (in range 0-1) of total data set to trim of each end.\n",
      "        axis : int or None, optional\n",
      "            Axis along which the observations are trimmed. The default is to trim\n",
      "            along axis=0. If axis is None then the array will be flattened before\n",
      "            trimming.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray\n",
      "            Trimmed version of array `a`.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        trim_mean\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> a = np.arange(20)\n",
      "        >>> b = stats.trimboth(a, 0.1)\n",
      "        >>> b.shape\n",
      "        (16,)\n",
      "    \n",
      "    tsem(a, limits=None, inclusive=(True, True))\n",
      "        Compute the trimmed standard error of the mean\n",
      "        \n",
      "        This function finds the standard error of the mean for given\n",
      "        values, ignoring values outside the given `limits`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            array of values\n",
      "        limits : None or (lower limit, upper limit), optional\n",
      "            Values in the input array less than the lower limit or greater than the\n",
      "            upper limit will be ignored. When limits is None, then all values are\n",
      "            used. Either of the limit values in the tuple can also be None\n",
      "            representing a half-open interval.  The default value is None.\n",
      "        inclusive : (bool, bool), optional\n",
      "            A tuple consisting of the (lower flag, upper flag).  These flags\n",
      "            determine whether values exactly equal to the lower or upper limits\n",
      "            are included.  The default value is (True, True).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        tsem : float\n",
      "    \n",
      "    tstd(a, limits=None, inclusive=(True, True))\n",
      "        Compute the trimmed sample standard deviation\n",
      "        \n",
      "        This function finds the sample standard deviation of given values,\n",
      "        ignoring values outside the given `limits`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            array of values\n",
      "        limits : None or (lower limit, upper limit), optional\n",
      "            Values in the input array less than the lower limit or greater than the\n",
      "            upper limit will be ignored. When limits is None, then all values are\n",
      "            used. Either of the limit values in the tuple can also be None\n",
      "            representing a half-open interval.  The default value is None.\n",
      "        inclusive : (bool, bool), optional\n",
      "            A tuple consisting of the (lower flag, upper flag).  These flags\n",
      "            determine whether values exactly equal to the lower or upper limits\n",
      "            are included.  The default value is (True, True).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        tstd : float\n",
      "    \n",
      "    ttest_1samp(a, popmean, axis=0)\n",
      "        Calculates the T-test for the mean of ONE group of scores.\n",
      "        \n",
      "        This is a two-sided test for the null hypothesis that the expected value\n",
      "        (mean) of a sample of independent observations `a` is equal to the given\n",
      "        population mean, `popmean`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            sample observation\n",
      "        popmean : float or array_like\n",
      "            expected value in null hypothesis, if array_like than it must have the\n",
      "            same shape as `a` excluding the axis dimension\n",
      "        axis : int, optional, (default axis=0)\n",
      "            Axis can equal None (ravel array first), or an integer (the axis\n",
      "            over which to operate on a).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        t : float or array\n",
      "            t-statistic\n",
      "        prob : float or array\n",
      "            two-tailed p-value\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        \n",
      "        >>> np.random.seed(7654567)  # fix seed to get the same result\n",
      "        >>> rvs = stats.norm.rvs(loc=5, scale=10, size=(50,2))\n",
      "        \n",
      "        Test if mean of random sample is equal to true mean, and different mean.\n",
      "        We reject the null hypothesis in the second case and don't reject it in\n",
      "        the first case.\n",
      "        \n",
      "        >>> stats.ttest_1samp(rvs,5.0)\n",
      "        (array([-0.68014479, -0.04323899]), array([ 0.49961383,  0.96568674]))\n",
      "        >>> stats.ttest_1samp(rvs,0.0)\n",
      "        (array([ 2.77025808,  4.11038784]), array([ 0.00789095,  0.00014999]))\n",
      "        \n",
      "        Examples using axis and non-scalar dimension for population mean.\n",
      "        \n",
      "        >>> stats.ttest_1samp(rvs,[5.0,0.0])\n",
      "        (array([-0.68014479,  4.11038784]), array([  4.99613833e-01,   1.49986458e-04]))\n",
      "        >>> stats.ttest_1samp(rvs.T,[5.0,0.0],axis=1)\n",
      "        (array([-0.68014479,  4.11038784]), array([  4.99613833e-01,   1.49986458e-04]))\n",
      "        >>> stats.ttest_1samp(rvs,[[5.0],[0.0]])\n",
      "        (array([[-0.68014479, -0.04323899],\n",
      "               [ 2.77025808,  4.11038784]]), array([[  4.99613833e-01,   9.65686743e-01],\n",
      "               [  7.89094663e-03,   1.49986458e-04]]))\n",
      "    \n",
      "    ttest_ind(a, b, axis=0, equal_var=True)\n",
      "        Calculates the T-test for the means of TWO INDEPENDENT samples of scores.\n",
      "        \n",
      "        This is a two-sided test for the null hypothesis that 2 independent samples\n",
      "        have identical average (expected) values. This test assumes that the\n",
      "        populations have identical variances.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a, b : array_like\n",
      "            The arrays must have the same shape, except in the dimension\n",
      "            corresponding to `axis` (the first, by default).\n",
      "        axis : int, optional\n",
      "            Axis can equal None (ravel array first), or an integer (the axis\n",
      "            over which to operate on a and b).\n",
      "        equal_var : bool, optional\n",
      "            If True (default), perform a standard independent 2 sample test\n",
      "            that assumes equal population variances [1]_.\n",
      "            If False, perform Welch's t-test, which does not assume equal\n",
      "            population variance [2]_.\n",
      "        \n",
      "            .. versionadded:: 0.11.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        t : float or array\n",
      "            The calculated t-statistic.\n",
      "        prob : float or array\n",
      "            The two-tailed p-value.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        We can use this test, if we observe two independent samples from\n",
      "        the same or different population, e.g. exam scores of boys and\n",
      "        girls or of two ethnic groups. The test measures whether the\n",
      "        average (expected) value differs significantly across samples. If\n",
      "        we observe a large p-value, for example larger than 0.05 or 0.1,\n",
      "        then we cannot reject the null hypothesis of identical average scores.\n",
      "        If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%,\n",
      "        then we reject the null hypothesis of equal averages.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] http://en.wikipedia.org/wiki/T-test#Independent_two-sample_t-test\n",
      "        \n",
      "        .. [2] http://en.wikipedia.org/wiki/Welch%27s_t_test\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> np.random.seed(12345678)\n",
      "        \n",
      "        Test with sample with identical means:\n",
      "        \n",
      "        >>> rvs1 = stats.norm.rvs(loc=5,scale=10,size=500)\n",
      "        >>> rvs2 = stats.norm.rvs(loc=5,scale=10,size=500)\n",
      "        >>> stats.ttest_ind(rvs1,rvs2)\n",
      "        (0.26833823296239279, 0.78849443369564776)\n",
      "        >>> stats.ttest_ind(rvs1,rvs2, equal_var = False)\n",
      "        (0.26833823296239279, 0.78849452749500748)\n",
      "        \n",
      "        `ttest_ind` underestimates p for unequal variances:\n",
      "        \n",
      "        >>> rvs3 = stats.norm.rvs(loc=5, scale=20, size=500)\n",
      "        >>> stats.ttest_ind(rvs1, rvs3)\n",
      "        (-0.46580283298287162, 0.64145827413436174)\n",
      "        >>> stats.ttest_ind(rvs1, rvs3, equal_var = False)\n",
      "        (-0.46580283298287162, 0.64149646246569292)\n",
      "        \n",
      "        When n1 != n2, the equal variance t-statistic is no longer equal to the\n",
      "        unequal variance t-statistic:\n",
      "        \n",
      "        >>> rvs4 = stats.norm.rvs(loc=5, scale=20, size=100)\n",
      "        >>> stats.ttest_ind(rvs1, rvs4)\n",
      "        (-0.99882539442782481, 0.3182832709103896)\n",
      "        >>> stats.ttest_ind(rvs1, rvs4, equal_var = False)\n",
      "        (-0.69712570584654099, 0.48716927725402048)\n",
      "        \n",
      "        T-test with different means, variance, and n:\n",
      "        \n",
      "        >>> rvs5 = stats.norm.rvs(loc=8, scale=20, size=100)\n",
      "        >>> stats.ttest_ind(rvs1, rvs5)\n",
      "        (-1.4679669854490653, 0.14263895620529152)\n",
      "        >>> stats.ttest_ind(rvs1, rvs5, equal_var = False)\n",
      "        (-0.94365973617132992, 0.34744170334794122)\n",
      "    \n",
      "    ttest_rel(a, b, axis=0)\n",
      "        Calculates the T-test on TWO RELATED samples of scores, a and b.\n",
      "        \n",
      "        This is a two-sided test for the null hypothesis that 2 related or\n",
      "        repeated samples have identical average (expected) values.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a, b : array_like\n",
      "            The arrays must have the same shape.\n",
      "        axis : int, optional, (default axis=0)\n",
      "            Axis can equal None (ravel array first), or an integer (the axis\n",
      "            over which to operate on a and b).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        t : float or array\n",
      "            t-statistic\n",
      "        prob : float or array\n",
      "            two-tailed p-value\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Examples for the use are scores of the same set of student in\n",
      "        different exams, or repeated sampling from the same units. The\n",
      "        test measures whether the average score differs significantly\n",
      "        across samples (e.g. exams). If we observe a large p-value, for\n",
      "        example greater than 0.05 or 0.1 then we cannot reject the null\n",
      "        hypothesis of identical average scores. If the p-value is smaller\n",
      "        than the threshold, e.g. 1%, 5% or 10%, then we reject the null\n",
      "        hypothesis of equal averages. Small p-values are associated with\n",
      "        large t-statistics.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        http://en.wikipedia.org/wiki/T-test#Dependent_t-test\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> np.random.seed(12345678) # fix random seed to get same numbers\n",
      "        \n",
      "        >>> rvs1 = stats.norm.rvs(loc=5,scale=10,size=500)\n",
      "        >>> rvs2 = (stats.norm.rvs(loc=5,scale=10,size=500) +\n",
      "        ...         stats.norm.rvs(scale=0.2,size=500))\n",
      "        >>> stats.ttest_rel(rvs1,rvs2)\n",
      "        (0.24101764965300962, 0.80964043445811562)\n",
      "        >>> rvs3 = (stats.norm.rvs(loc=8,scale=10,size=500) +\n",
      "        ...         stats.norm.rvs(scale=0.2,size=500))\n",
      "        >>> stats.ttest_rel(rvs1,rvs3)\n",
      "        (-3.9995108708727933, 7.3082402191726459e-005)\n",
      "    \n",
      "    tvar(a, limits=None, inclusive=(True, True))\n",
      "        Compute the trimmed variance\n",
      "        \n",
      "        This function computes the sample variance of an array of values,\n",
      "        while ignoring values which are outside of given `limits`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            array of values\n",
      "        limits : None or (lower limit, upper limit), optional\n",
      "            Values in the input array less than the lower limit or greater than the\n",
      "            upper limit will be ignored. When limits is None, then all values are\n",
      "            used. Either of the limit values in the tuple can also be None\n",
      "            representing a half-open interval.  The default value is None.\n",
      "        inclusive : (bool, bool), optional\n",
      "            A tuple consisting of the (lower flag, upper flag).  These flags\n",
      "            determine whether values exactly equal to the lower or upper limits\n",
      "            are included.  The default value is (True, True).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        tvar : float\n",
      "            Trimmed variance.\n",
      "    \n",
      "    variation(a, axis=0)\n",
      "        Computes the coefficient of variation, the ratio of the biased standard\n",
      "        deviation to the mean.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Input array.\n",
      "        axis : int or None\n",
      "            Axis along which to calculate the coefficient of variation.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Zwillinger, D. and Kokoska, S. (2000). CRC Standard\n",
      "           Probability and Statistics Tables and Formulae. Chapman & Hall: New\n",
      "           York. 2000.\n",
      "    \n",
      "    wilcoxon(x, y=None, zero_method='wilcox', correction=False)\n",
      "        Calculate the Wilcoxon signed-rank test.\n",
      "        \n",
      "        The Wilcoxon signed-rank test tests the null hypothesis that two\n",
      "        related paired samples come from the same distribution. In particular,\n",
      "        it tests whether the distribution of the differences x - y is symmetric\n",
      "        about zero. It is a non-parametric version of the paired T-test.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            The first set of measurements.\n",
      "        y : array_like, optional\n",
      "            The second set of measurements.  If `y` is not given, then the `x`\n",
      "            array is considered to be the differences between the two sets of\n",
      "            measurements.\n",
      "        zero_method : string, {\"pratt\", \"wilcox\", \"zsplit\"}, optional\n",
      "            \"pratt\":\n",
      "                Pratt treatment: includes zero-differences in the ranking process\n",
      "                (more conservative)\n",
      "            \"wilcox\":\n",
      "                Wilcox treatment: discards all zero-differences\n",
      "            \"zsplit\":\n",
      "                Zero rank split: just like Pratt, but spliting the zero rank\n",
      "                between positive and negative ones\n",
      "        correction : bool, optional\n",
      "            If True, apply continuity correction by adjusting the Wilcoxon rank\n",
      "            statistic by 0.5 towards the mean value when computing the\n",
      "            z-statistic.  Default is False.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        T : float\n",
      "            The sum of the ranks of the differences above or below zero, whichever\n",
      "            is smaller.\n",
      "        p-value : float\n",
      "            The two-sided p-value for the test.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Because the normal approximation is used for the calculations, the\n",
      "        samples used should be large.  A typical rule is to require that\n",
      "        n > 20.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] http://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test\n",
      "    \n",
      "    zmap(scores, compare, axis=0, ddof=0)\n",
      "        Calculates the relative z-scores.\n",
      "        \n",
      "        Returns an array of z-scores, i.e., scores that are standardized to zero\n",
      "        mean and unit variance, where mean and variance are calculated from the\n",
      "        comparison array.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        scores : array_like\n",
      "            The input for which z-scores are calculated.\n",
      "        compare : array_like\n",
      "            The input from which the mean and standard deviation of the\n",
      "            normalization are taken; assumed to have the same dimension as\n",
      "            `scores`.\n",
      "        axis : int or None, optional\n",
      "            Axis over which mean and variance of `compare` are calculated.\n",
      "            Default is 0.\n",
      "        ddof : int, optional\n",
      "            Degrees of freedom correction in the calculation of the\n",
      "            standard deviation. Default is 0.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        zscore : array_like\n",
      "            Z-scores, in the same shape as `scores`.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This function preserves ndarray subclasses, and works also with\n",
      "        matrices and masked arrays (it uses `asanyarray` instead of `asarray`\n",
      "        for parameters).\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> a = [0.5, 2.0, 2.5, 3]\n",
      "        >>> b = [0, 1, 2, 3, 4]\n",
      "        >>> zmap(a, b)\n",
      "        array([-1.06066017,  0.        ,  0.35355339,  0.70710678])\n",
      "    \n",
      "    zscore(a, axis=0, ddof=0)\n",
      "        Calculates the z score of each value in the sample, relative to the sample\n",
      "        mean and standard deviation.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            An array like object containing the sample data.\n",
      "        axis : int or None, optional\n",
      "            If `axis` is equal to None, the array is first raveled. If `axis` is\n",
      "            an integer, this is the axis over which to operate. Default is 0.\n",
      "        ddof : int, optional\n",
      "            Degrees of freedom correction in the calculation of the\n",
      "            standard deviation. Default is 0.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        zscore : array_like\n",
      "            The z-scores, standardized by mean and standard deviation of input\n",
      "            array `a`.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This function preserves ndarray subclasses, and works also with\n",
      "        matrices and masked arrays (it uses `asanyarray` instead of `asarray`\n",
      "        for parameters).\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> a = np.array([ 0.7972,  0.0767,  0.4383,  0.7866,  0.8091,  0.1954,\n",
      "                           0.6307, 0.6599,  0.1065,  0.0508])\n",
      "        >>> from scipy import stats\n",
      "        >>> stats.zscore(a)\n",
      "        array([ 1.1273, -1.247 , -0.0552,  1.0923,  1.1664, -0.8559,  0.5786,\n",
      "                0.6748, -1.1488, -1.3324])\n",
      "        \n",
      "        Computing along a specified axis, using n-1 degrees of freedom (``ddof=1``)\n",
      "        to calculate the standard deviation:\n",
      "        \n",
      "        >>> b = np.array([[ 0.3148,  0.0478,  0.6243,  0.4608],\n",
      "                          [ 0.7149,  0.0775,  0.6072,  0.9656],\n",
      "                          [ 0.6341,  0.1403,  0.9759,  0.4064],\n",
      "                          [ 0.5918,  0.6948,  0.904 ,  0.3721],\n",
      "                          [ 0.0921,  0.2481,  0.1188,  0.1366]])\n",
      "        >>> stats.zscore(b, axis=1, ddof=1)\n",
      "        array([[-0.19264823, -1.28415119,  1.07259584,  0.40420358],\n",
      "               [ 0.33048416, -1.37380874,  0.04251374,  1.00081084],\n",
      "               [ 0.26796377, -1.12598418,  1.23283094, -0.37481053],\n",
      "               [-0.22095197,  0.24468594,  1.19042819, -1.21416216],\n",
      "               [-0.82780366,  1.4457416 , -0.43867764, -0.1792603 ]])\n",
      "\n",
      "DATA\n",
      "    __all__ = ['absolute_import', 'alpha', 'anderson', 'anglit', 'ansari',...\n",
      "    absolute_import = _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0...\n",
      "    alpha = <scipy.stats.distributions.alpha_gen object>\n",
      "    anglit = <scipy.stats.distributions.anglit_gen object>\n",
      "    arcsine = <scipy.stats.distributions.arcsine_gen object>\n",
      "    bernoulli = <scipy.stats.distributions.bernoulli_gen object>\n",
      "    beta = <scipy.stats.distributions.beta_gen object>\n",
      "    betaprime = <scipy.stats.distributions.betaprime_gen object>\n",
      "    binom = <scipy.stats.distributions.binom_gen object>\n",
      "    boltzmann = <scipy.stats.distributions.boltzmann_gen object>\n",
      "    bradford = <scipy.stats.distributions.bradford_gen object>\n",
      "    burr = <scipy.stats.distributions.burr_gen object>\n",
      "    cauchy = <scipy.stats.distributions.cauchy_gen object>\n",
      "    chi = <scipy.stats.distributions.chi_gen object>\n",
      "    chi2 = <scipy.stats.distributions.chi2_gen object>\n",
      "    cosine = <scipy.stats.distributions.cosine_gen object>\n",
      "    dgamma = <scipy.stats.distributions.dgamma_gen object>\n",
      "    division = _Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 8192...\n",
      "    dlaplace = <scipy.stats.distributions.dlaplace_gen object>\n",
      "    dweibull = <scipy.stats.distributions.dweibull_gen object>\n",
      "    erlang = <scipy.stats.distributions.erlang_gen object>\n",
      "    expon = <scipy.stats.distributions.expon_gen object>\n",
      "    exponpow = <scipy.stats.distributions.exponpow_gen object>\n",
      "    exponweib = <scipy.stats.distributions.exponweib_gen object>\n",
      "    f = <scipy.stats.distributions.f_gen object>\n",
      "    fatiguelife = <scipy.stats.distributions.fatiguelife_gen object>\n",
      "    fisk = <scipy.stats.distributions.fisk_gen object>\n",
      "    foldcauchy = <scipy.stats.distributions.foldcauchy_gen object>\n",
      "    foldnorm = <scipy.stats.distributions.foldnorm_gen object>\n",
      "    fprob = <ufunc 'fdtrc'>\n",
      "    frechet_l = <scipy.stats.distributions.frechet_l_gen object>\n",
      "    frechet_r = <scipy.stats.distributions.frechet_r_gen object>\n",
      "    gamma = <scipy.stats.distributions.gamma_gen object>\n",
      "    gausshyper = <scipy.stats.distributions.gausshyper_gen object>\n",
      "    genexpon = <scipy.stats.distributions.genexpon_gen object>\n",
      "    genextreme = <scipy.stats.distributions.genextreme_gen object>\n",
      "    gengamma = <scipy.stats.distributions.gengamma_gen object>\n",
      "    genhalflogistic = <scipy.stats.distributions.genhalflogistic_gen objec...\n",
      "    genlogistic = <scipy.stats.distributions.genlogistic_gen object>\n",
      "    genpareto = <scipy.stats.distributions.genpareto_gen object>\n",
      "    geom = <scipy.stats.distributions.geom_gen object>\n",
      "    gilbrat = <scipy.stats.distributions.gilbrat_gen object>\n",
      "    gompertz = <scipy.stats.distributions.gompertz_gen object>\n",
      "    gumbel_l = <scipy.stats.distributions.gumbel_l_gen object>\n",
      "    gumbel_r = <scipy.stats.distributions.gumbel_r_gen object>\n",
      "    halfcauchy = <scipy.stats.distributions.halfcauchy_gen object>\n",
      "    halflogistic = <scipy.stats.distributions.halflogistic_gen object>\n",
      "    halfnorm = <scipy.stats.distributions.halfnorm_gen object>\n",
      "    hypergeom = <scipy.stats.distributions.hypergeom_gen object>\n",
      "    hypsecant = <scipy.stats.distributions.hypsecant_gen object>\n",
      "    invgamma = <scipy.stats.distributions.invgamma_gen object>\n",
      "    invgauss = <scipy.stats.distributions.invgauss_gen object>\n",
      "    invweibull = <scipy.stats.distributions.invweibull_gen object>\n",
      "    johnsonsb = <scipy.stats.distributions.johnsonsb_gen object>\n",
      "    johnsonsu = <scipy.stats.distributions.johnsonsu_gen object>\n",
      "    ksone = <scipy.stats.distributions.ksone_gen object>\n",
      "    ksprob = <ufunc 'kolmogorov'>\n",
      "    kstwobign = <scipy.stats.distributions.kstwobign_gen object>\n",
      "    laplace = <scipy.stats.distributions.laplace_gen object>\n",
      "    levy = <scipy.stats.distributions.levy_gen object>\n",
      "    levy_l = <scipy.stats.distributions.levy_l_gen object>\n",
      "    levy_stable = <scipy.stats.distributions.levy_stable_gen object>\n",
      "    loggamma = <scipy.stats.distributions.loggamma_gen object>\n",
      "    logistic = <scipy.stats.distributions.logistic_gen object>\n",
      "    loglaplace = <scipy.stats.distributions.loglaplace_gen object>\n",
      "    lognorm = <scipy.stats.distributions.lognorm_gen object>\n",
      "    logser = <scipy.stats.distributions.logser_gen object>\n",
      "    lomax = <scipy.stats.distributions.lomax_gen object>\n",
      "    maxwell = <scipy.stats.distributions.maxwell_gen object>\n",
      "    mielke = <scipy.stats.distributions.mielke_gen object>\n",
      "    nakagami = <scipy.stats.distributions.nakagami_gen object>\n",
      "    nbinom = <scipy.stats.distributions.nbinom_gen object>\n",
      "    ncf = <scipy.stats.distributions.ncf_gen object>\n",
      "    nct = <scipy.stats.distributions.nct_gen object>\n",
      "    ncx2 = <scipy.stats.distributions.ncx2_gen object>\n",
      "    norm = <scipy.stats.distributions.norm_gen object>\n",
      "    pareto = <scipy.stats.distributions.pareto_gen object>\n",
      "    pearson3 = <scipy.stats.distributions.pearson3_gen object>\n",
      "    planck = <scipy.stats.distributions.planck_gen object>\n",
      "    poisson = <scipy.stats.distributions.poisson_gen object>\n",
      "    powerlaw = <scipy.stats.distributions.powerlaw_gen object>\n",
      "    powerlognorm = <scipy.stats.distributions.powerlognorm_gen object>\n",
      "    powernorm = <scipy.stats.distributions.powernorm_gen object>\n",
      "    print_function = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0)...\n",
      "    randint = <scipy.stats.distributions.randint_gen object>\n",
      "    rayleigh = <scipy.stats.distributions.rayleigh_gen object>\n",
      "    rdist = <scipy.stats.distributions.rdist_gen object>\n",
      "    recipinvgauss = <scipy.stats.distributions.recipinvgauss_gen object>\n",
      "    reciprocal = <scipy.stats.distributions.reciprocal_gen object>\n",
      "    rice = <scipy.stats.distributions.rice_gen object>\n",
      "    semicircular = <scipy.stats.distributions.semicircular_gen object>\n",
      "    skellam = <scipy.stats.distributions.skellam_gen object>\n",
      "    t = <scipy.stats.distributions.t_gen object>\n",
      "    triang = <scipy.stats.distributions.triang_gen object>\n",
      "    truncexpon = <scipy.stats.distributions.truncexpon_gen object>\n",
      "    truncnorm = <scipy.stats.distributions.truncnorm_gen object>\n",
      "    tukeylambda = <scipy.stats.distributions.tukeylambda_gen object>\n",
      "    uniform = <scipy.stats.distributions.uniform_gen object>\n",
      "    vonmises = <scipy.stats.distributions.vonmises_gen object>\n",
      "    wald = <scipy.stats.distributions.wald_gen object>\n",
      "    weibull_max = <scipy.stats.distributions.frechet_l_gen object>\n",
      "    weibull_min = <scipy.stats.distributions.frechet_r_gen object>\n",
      "    wrapcauchy = <scipy.stats.distributions.wrapcauchy_gen object>\n",
      "    zipf = <scipy.stats.distributions.zipf_gen object>\n",
      "    zprob = <ufunc 'ndtr'>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI8AAAASCAYAAABim40OAAAABHNCSVQICAgIfAhkiAAABX9JREFU\naIHt2XmoVVUUB+DvpWZWapmaTWSpjVCpZdJE80BREdFANkPRHJQUZRNWNtBIYVSQlpVRUVRCA5QV\nWBlkI9GE2axPbFArraf9sfbl7Xc6V++5vtDg/eBw7l5n77XWPmftNV260IUm0fIf8FwXb2OniutG\n4XL0wuaYiavxfWHetpiAOViO/hiLuSU8t8G1+ANL0v1aLGySHyvf32cYj9ewGLumfV2AT5uQOxpn\nJ917Jfk34oNszmG4L9Fqe12WPX8X91bUb2tcgz/RhvVwGX6qs+9Vxm5J0eUV143Ay9ggjdfHG5iH\nwdm8vvgOYzLaFfgYaxd47oBvsEcaD8JsYTzN8KOx/S0vXEtxXmFOo3KH4wWsk9Em4jfsktEuKZGb\nX4dV1G8rzMcxGW2MMM7uZZteFWyPaZgkTmVV45mGoQXa8MRnaka7QRhUvoF++AvnZLTu4oRdnNG2\nQCsuaoJflf3Nwf14BrektUU0KveOJOv4jHZEot2d0SaK/fXAWhl9T9zThH7PYkGBVy/hhU4rmd9p\nmKS68SwSXmJggf6zOAE1fI7nS9Z/hFez8RniRG1QMjdHo/xyTLLi/U1ficwqck/Brzgoo52Q5N+U\n0YoGQnjvF0WYq6Lf2sKIZ5Y8+0x4QnS0rNWJ2dhYxNUcS4TFQ28ME0ZWxA8YmY1PxJf4ZQUyq/Dr\nTFSR+7AIca9ktBEiB3k8o51fwutWkbP8XlG/fsIj/lny7FeRm+I/iF9NYrR4qXkytqkwqOlpvGW6\n/1ayfjH6oKfwOHuJk7MPDhancDCuw6yK/JZU3EtPXIWNxAkeIhLSzztB7lY4FefqmDAXsSe64Z0m\n9GsVBrdOydpNMUDYzd9rivEsTleOC0XFcGUa90n3pXXWE2GqTWx8oEiax6Vn+4okfDQ+qcCvXtVV\nDwNEaPs2jcfgTewsDkczco/A7jgKd+HBlehwN45tUr82PIEjRTVeC9GDhPEQ3mnemhK2ihgqXPEE\nzEi0tnQvyzd6pHu3dBGndHI2Z7pwuzdX5FcV22j/MER46S2qqWblviC8xQjsJ95J/zryDxChfnaT\n+hEl+QKclcbdxfd4P99D7nl2FhbZaO9nFk5vcG4V9MRjoiIYl9FbV7Cmlist1B6rvxQ9jxzfieSz\nZwV+VbGsMG5Lso4S3nRV5P4tejSvi75OmXc5V1SEzeonjXdP49tFGHsAh4r3u4COxvOBKI9XJ1rw\nkKgSri48mytO64Yl69YTyXHtpbeKSq2IJaKa6FeRX6N4Q+xh7wK9m3ZPUUXudknfD7M5tdN/jMjl\nFmXPeuAQEdqa1a+Gn0WOmGNj4fWWs+ZUWzWMF13O3HBOSffFwtttUbJuqPaXSpy8MrdeS0RbK/Jr\nFMPFBy2iv+ivqCC3T5r3nkhqa6iFvRb/Dm+jhAHOV45G9KuHAaLz/2SNsDqMZ5j28jvH6cKlji/Q\n98p+TxPuNA+tQ8SHeCqjPS6qmlxOizjJzwn3X4Vfo3gRBxZow4XRTqm4j6UiMszW0YvWmnozRQ6X\no9ZoLSuzq+h3sWhibp7RThV/FU2qw7tTMFW4tWJziiidl+GlAn1/cVqmFK6pOvYzNhFu/eSMdqeo\nnvK2/lp4C5dmtOOExxncBL8cK9rfbuLj1561iF7NDPGBqsq9UfznlBvZIyKsjSiRPzbpdmYd3RvV\nbxy+FhUWYWBztf/Vg87r8wwUm9oMOybaHPFfzYN4NNHmig/4VWH906I8PamE9/XZ7x9FyX2DeHm9\nRf5yqI6l7zIcLpK9J0U/o0WU6V83wa/R/b0r8o3JIlnvI7rGZ+nYt2lU7hXi74DHhLccJJLVkdr7\nMjm+EN6oXg+oUf1uE83JCUm3vjhaHMgudKELXehCF/6P+Aesr6yasp39VQAAAABJRU5ErkJggg==\n",
      "text/latex": [
       "$$-1.20601503759$$"
      ],
      "text/plain": [
       "-1.20601503759"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.stats.kurtosis(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4  5  6  7  8]\n",
      " [ 2  4  6  8 10 12 14 16]]\n",
      "\n",
      "\n",
      "[[ 1  3  5  7]\n",
      " [ 2  6 10 14]]\n",
      "\n",
      "\n",
      "[ 1  4  6 12]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1, 2, 3, 4, 5, 6, 7, 8], [2, 4, 6, 8,10, 12, 14, 16]])\n",
    "print A\n",
    "print '\\n'\n",
    "print A[0 : 2, 0 : 8 : 2]\n",
    "print '\\n'\n",
    "print A[[0, 0, 1, 1], [0, 3, 2, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([11, 13, 15, 17, 19, 18, 16, 14, 12, 10])\n",
    "#A.argsort(kind = 'megasort')\n",
    "A.sort()\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 5 7]\n",
      " [2 4 6]\n",
      " [1 3 5]] \n",
      "\n",
      "Axis 0 is along columns  [ 2.  4.  6.] \n",
      "\n",
      "Axis 1 is along rows  [ 5.  4.  3.]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[3, 5, 7], [2, 4, 6], [1, 3, 5]])\n",
    "print A, '\\n'\n",
    "print 'Axis 0 is along columns ', A.mean(axis = 0), '\\n'\n",
    "print 'Axis 1 is along rows ', A.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.91396038 -0.65684235 -0.96442216  0.78052235 -1.53423638  0.10430735\n",
      "  0.01718518 -1.62047077 -0.71080625 -0.44490933 -0.60532243 -0.19436707\n",
      " -0.29755677  0.2273614  -0.11218201 -0.52119499  0.29250583 -0.81236629\n",
      "  0.32008592  0.61246099  1.80154894 -0.44270992 -0.57790395 -0.46545451\n",
      " -0.35772197  0.339486   -1.67062115 -1.45972643 -0.1886938  -1.55602384\n",
      "  0.959571    0.24169594  1.30047677 -0.86536226 -0.10125497 -0.70476176\n",
      " -1.38740462 -0.21242722  0.23920591 -0.97847738 -0.32674801 -0.55756421\n",
      "  0.57406204 -0.63360404  0.47877443 -1.9640817  -0.1449473   2.53337923\n",
      "  0.64097111 -0.00570764] \n",
      "\n",
      "Max:  2.53337922919\n",
      "Min:  -1.96408169716\n",
      "Mean:  -0.250524669802\n",
      "Var:  0.760482249953\n",
      "Std:  0.872056334163\n",
      "Mean +- std:  -0.250524669802 -1.12258100396 0.621531664361 \n",
      "\n",
      "Mean and 95% CI:  (-0.25052466980181387, (-0.50087650011796281, -0.0001728394856649329))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAEACAYAAABBDJb9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZIkSZIkSZIkSdJ1/w/5eGdc168PjgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ce58a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "A = np.random.randn(50)\n",
    "print A, '\\n'\n",
    "print 'Max: ', A.max()\n",
    "print 'Min: ', A.min()\n",
    "print 'Mean: ', A.mean()\n",
    "print 'Var: ', A.var()\n",
    "print 'Std: ', A.std()\n",
    "print 'Mean +- std: ', A.mean(), A.mean() - A.std(), A.mean() + A.std(), '\\n'\n",
    "result = stats.bayes_mvs(A,alpha = 0.95)\n",
    "result\n",
    "print 'Mean and 95% CI: ', result[0]\n",
    "x = np.arange(0, 50, 1)\n",
    "\n",
    "i = 0\n",
    "while i < 50:\n",
    "    plt.plot(x[i], A[i], 'rd')\n",
    "    i += 1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]] \n",
      "\n",
      "[[1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]] \n",
      "\n",
      "[[3 0 0]\n",
      " [0 3 0]\n",
      " [0 0 3]] \n",
      "\n",
      "[[False  True  True]\n",
      " [ True False  True]\n",
      " [ True  True False]]\n"
     ]
    }
   ],
   "source": [
    "Z = np.zeros((5, 5), dtype = int)\n",
    "U = np.ones((4, 4), dtype = int)\n",
    "I = np.eye(3, dtype = int)\n",
    "print Z, '\\n'\n",
    "print U, '\\n'\n",
    "print I * 3, '\\n'\n",
    "print I == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.quiver.Quiver at 0x10f23f650>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEACAYAAAC08h1NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsvXd4XOW19v3bU6SZURt1jaRR75JtuTcMtrFNc4DQAsQh\nnEMSAiHlg4SUN4UAgZwkBN4TyiEnCQQCBGJK6DZgY7BxkXCXbMvqGnWN6kjTZ39/yOL4cELQepyT\nxC+6r2uuy9hz8+yZ2Xvttdez7nvBDGYwgxnMYAYzmMEMZjCDGcxgBjOYwQxmMIMZzGAGM5jBDGYw\ngxnMYAYzmMEMZjCDGcxgBjOYwQxOYziBrUAd8DZw9V94z0pgBNh34vX9v9OxzWAGM5jBDP4XkAFU\nn/hzCtAMxH3oPSuBF/+OxzSDGcxgBjP4KzCcIr8H2H/izwNMZv4L/sL7tFNcZwYzmMEMZvBPiCIm\nM/6YD/39WYCbyRvEL4HCv/NxzWAGM5jBDP4XEAe8D1z0Ef9mA8zAF4CX/47HNYMZzGAGM/gQ/hYl\nGDPwCvAqcN801usBcgD/yf9QWFioNzU1/Q0OZwYzmMEMPjFoYrLaIsKp1vg14LfAYT466KfzXzeY\nTwEH+VDQB2hqakLX9Wm/Bvv7eTUri9pnnxXxdF3n/pUrqbnqKjHv8e9+l2ezsujt7hbxPr9+PW9d\ndx01t9wi4g0PDfGH73yHpzMzCYVCIu5vv/pV9nzpS9TefruIt+WXv2TbH//IC04nkUhkWpwf/ehH\nhEIhHrzkEmquv54a4Zqbr7+e9zZu5E/Cz9nR3MyzS5aw55ZbqPnWt0Rr7rn2WrbffjsbMzPp7+n5\n2M839WdXczPvx8ay6ZZbqLn6atGaNTfdxO7qanYuWULtCy9MmxcIBNiXnMwfzjqLXfPny9b8+c/R\ngZeqq6m5446P/Xz/jbtsGUHgiYQE+nt7p73mwa1bcQMvR0WxedEi2fH+5jccKi3l+awsdtx7r4g7\n6Hbz59xcHklNxe/3f+znO/nV09XFb+x2ai+/XLSmruvUPvccbyQnU/PQQ2Lu7nvv5TcWC16vV8z9\n07nngmLp/FQD/3JgA7Ca/2rXPA+4/sQL4DLgEJM1/suAW05xTQAaX3sN89gYuscj4rl7e7Hs20ew\nr0+8Zu7WrcQbjfQ1Nop4UW43g8ePQ3+/iNe0Ywf5r7+OxWSit7NTxC148016x8ehq0vEi+3uxnTi\nZtrf0zNtXkdjIyteew03QEeHaM3E/n548knioqNpb2iYNq/34EHO3bULl9sN7e2iNbWuLqyPP44j\nK4v2mppp83oOHGCux0P/vn3ows9JRwfz9u9nJBhEFxxvy6FD5LvdzN61i9aODiKRyLS54w0NjAL9\nbje68BxqyslhX1oa6YmJuA4cmDYvd9Ysdt16K57ly0nQZEWFBdddh2/JEqKcTqJGR0XcxKQkHGlp\nxOg6A729Im5SSgoeIDQ8LOIBGBMSCEUiMD4u59psWICJiQkxVzebxZwpnGrg337i/1ENzD3xeg14\n+MQL4AGg6sR7rmEy4z917NtHzOgo3fv2iWgtb73F7JERvMLg7fN6sTc0YPD58Hd3i7i43VBXR0gQ\nSAEijY0s2L+fOJOJnkOHps3zjI2R0d7OeF2dOPBr7e3kvfwySXY7rr17p80bOHiQSq+XwUOHxIEf\nl4uil1/GmpiI++D0Tw/d5cIGjO/dS7itTbzm3OPHGfX7ibS2Tn/Njg7CAEeP0tncjK7r0+a2BgI0\nxMTgtdlE31GUwUDthRfSu3IlFrOZLsHxVt15J/Vr1xK3Zg2a8Fy48He/o9FoJLasjJDLNW1efHIy\nabNnEx8IiJKHD5CaSkjTYGBATDUkJ5Nos9EvvL7NZjMmo5GQwprxDgfecBiESSgAFgtWYFx4kwOI\nREXJ1zuBUw38/zjs24cJCOzZI+MdPkwMiDP+Y+++S+ngIMbBQUYFWSnAfK+XArebiSNHRDyamogC\nAh4PuuACaq6poWB8nMTDh/EIj5WODpK9XobHxohMMytduXIl4bY2PMB4ezujzc3TXk7XdQ6PjDAe\nG4vHZAJBAA9EItQXFkJWFh2CTFjXdZpXrWKL04l57tyPfVpYuXLlB3/OPOcctmzYQPG//itoGn2C\nYHrpK6/QmJxM7MqVosCfV11NwhVXkBAOk5mfT+/+/R9POoHktDSMOTmEIxFCH5Hxn/z5TobVaiUt\nJoYxiwVNmEFb8vKwDg0xGgjgEQZELS2NUDisFPhJSsIQHf3fru+P+nwfRordzqjCmglpaUwoZvx6\ndDRWTWPC7RZz+Qdm/P8wDH/+87TabMTPmSPiWZYsoaO4mAGTSZStJSQm8t755zPkdGISnMjhcJjY\nc8+lIz+f4UBAdKyGxYvZW1LCcF4eCAJ/ckYGW6+6itH16+kfGxN9zuA3vsELDgepF1wA08zyVq5c\nSeFVV7H3uuuo+Pzn6Rsdxev1TouraRrnbdnCXquVlLVrRQFx2Ve/ysT551NaXY3VZKJzmjccTdP4\n9L33MhgOE1Ve/rE3m/8W+EtKSKquxtDaSmZ2Nq7a2mkfr6ZpOPLyGJiYEJeJ7FVVDLe0oGVnT/t3\n+WBdp5NkoPPE3tSH8dcCY0JODhMAwqfcnKoqeoeGyIiLo/PYMRGX1FRCgcDkk7IUSUmETCYYHPzg\nr6Yd+JOTGRofF10vAPHx8fhQKxNhsWAxGJg46Xini39kqecfhmWXX45X07DHxop4VRdeSEJODn6D\ngWAwOG1e3sKFxC5fjjEuDlsoNG2e0Whk9Q9/SDgYxG80irKfeZ/9LHpJCdaMDFHgz6qoIHntWnID\nAcwGAz2CQLH08stJT0hgUNNAUBNOycoipqSEKJeLzMREWgQluDSHA1tUFG6zWV6rLyxEa20lPS+P\nXsGaZrOZ7MxMuicmiEjLRHl56C0tGHJz0YVcLS8Pe1QUXe3togCTV1nJ0MQEvtRUceDXs7JIGBjA\nbDSKzgUAMjMJapo48McnJBBjNmNOSmJM2K2npaUR8XoJKOzDkZxMWNPQhobE1LjUVAKRyLSTlimY\nzWYMBoNS4DfFxaEDEYUa/6gCZwqnbeC32WyENY3QyIiYa05MJBYYlD7WJScTDofFmUiaw0EwHCbV\nZqNLWnrJzCSo66LADxBdUECgowNHZibdgro5QGxeHp5QSBxgyMuD1lZseXlMHD8+bZqmaaQUFDAa\nCOAX1K8BtPx8ws3NaLm54puGKT+fxKgoXC6XaMPUuWQJnW1tRJxO8Zrk5pI8PEwkEhFt2JtMJpwO\nBwPBoPh3iSooIOhyTZ4Lgk1aYPL8C4XQpftaTJ73EyYTCAN4Wnk5IY+HXsVST1jXQSHwG+124jWN\nQeHxhkIhjGYzIYWsvbuxkUAwCMKbDYBfuGdzMk7bwK9pGkajkaDCD6wnJGCPjsYtzfRSUggHAujC\nH9hoNJKZlIQpNpaxlhYRV3c4CAWD4sCfN3curoEB9IwMItIAnpNDlKYxKgxqGfPn09vaip6dLd/g\nzc8nw2DA1d9PQFASy12yBFdHB+HsbNH+wNSa9oEBok0mXIKsNC0zkyiTiSGLRRz49dxctPZ2spxO\nOt9/X8Q15+biC4fRhb9n/vz5dPT1oWdmys+FzExs4TBuYUcQgMHhIGg2iwN/enY2hMNMhMOMjY2J\nuKH4+MnkTHiNRiIRuvr7iY+Kwi1MPo5s24YeChFWyPjDR48SDIfRFQK/UeWJ6ARO28APEJuYyMTC\nhXKi3c7Q3LmkO52y9XJzMYRCmK64Qryk1eHAvWwZWVVVMqLDQRoQ3LBBRIuLjyfZZmN05UrSFvwl\n+6S/gpwcMvx+Il/4goiWVVBAKBIhvHIliStWiLh6Xh4xPT2k3nILkXB42rzktDQSrFa8paXErFsn\nWpP8fLS2NpK/+11iBSVDTdNILSiA+HjMl1wiWtJWXs54czOmm24iq7xcdrw5OaRbrQSv/ksmuB+N\n+IQEkk6cC6nz58vWzMoidWQEw5e/LCpN6boOGRlEcnNJmGaNfQpHd+/GERtL1Gc/i9EgC1FvbdyI\nyWjEcuGFIl7Dnj34jh9naPZssgplrfG+3buJCwYZXrZMxAOw1NfTGg6TPHu2iOedmCBJ4SlsCqd1\n4HempZFaWSknJiRQlJ9PSna2iJZRWEjA72f2lVfK10xLI7e4mIzSUhHNkJ1NzOAgS66//uPf/CEk\n5uWRmJFBjvRiz83F3NnJmltvFdE0TSMzJwezxULhWWfJ1szLg5YWVt9yCxarVUS1FxYSA5SvXy/i\nRZeW4mtsZMn115PkcIi4Wl4eycEgc4TnQuG8eXQPDVF60UVklJSIuOTkEOd2s/TLXxbRgoEAibm5\n2NPSyBUkSr2trUTsdka6ulh7661ogp78F++8k4mYGDJtNopXrxYd74Ef/xhbUhIFy5Zhi/mw9ddH\no6ejg4L33kMfG6Pyor/kHvPR8OzeTVJHB2kJCaQIE0L27SNzYgKzcL8xEAgQf+AACUBffb2I23nk\nCFp6uohzMk7rwG+IiVFqodLsdlB4LEuw2zEAQwq1PNLTQdgSB5A5Zw7dXV3iTgOY3NQTl1yA+IoK\nRoQlqSloJ+r8UqTMm0e/sC/+gzULCkDheIsWLaJzYEC8mafrOuTniz/n2NAQkVCI7NRUmgXdQADv\nPPMM5OTI9xSAR7/2NVAov7Xv2EHgtdcY9vkYE/aZZzc20n30qLhEGQ6HqaivZ8zjQReWMjreeYeL\nhoboHx4WNW4AcPgw9lAIn0AvA5PnQue+fUQ0jcHdu0Vc79gYXevWETGbiRHebIrmz0eTPsmfhNM6\n8KMY+ElIAIVNYU3TSE9MpEe6QQvKgT89K4tQJCLfiIbJi11a0wXyZ81iwOMRX+zhcHgycxfW2kcG\nB8kpKcEXCIj64gEaDxxAP/G0IMHe114j6PWSmZxMk0C5C/DYrbcqBf6GbdvYf999WAoK8AvPocjG\njYwMDdHT1ia6OQ4PDZG/cSOjFot4b0Bra8P+zDM47HbahJvCelMTkX37CAt/z6YDByjs6iLY00NE\neL1oR45gBWL9frHS3R0VRYvFAtIbBpB2//0MJSRQJSw1JiQn41y7FpvBQGpZmXjdT2Q7J0BHR4dS\n4H9/1y50hcC/7YknsKSk4BWeVC0HDtA3Pi7e5AJ489FHycrIwCUQ7QC8+uCD4HSKA3/du+9ybPNm\nnGlpNAsD4iNf/zrk5ooD4sHHHqPu5ZfJys2lQ5g1bbr5ZsK5uegC0RhA5OBBDt9zD9aiInxCYV36\nSy8xEggwKGxT1Ds7sf7+94QyM8XfUVxPD9YXXiAUiYhujm21tZzldtN/9Kj86a+tjUqXi0AohE/w\n/YbDYQzNzSzp6qJT0N0FMFhfT3dmJkGTidGjR0XcuNWr2blgAbEpKQwIlbvnPPAAPTExxMTHi3ia\npuEsLcUbCqkloRYLVk1jXKWK8ElU7na3thJqbSWsIJMObtnCsEL2Hf3WWwyPj4vbOd21tQzV1hIW\nPvZ6vV6677kHLSODoPARP+GNN2hubiYsvNh9TU2MPvggUXl5BIWBLXfTJnrGxvAJs2+b243ngQc+\nqPNPF16vl+V79uBuaqK7tVWUCWu9vdgffxxvejqaIAh7vV6yu7uJfvllxnw+mSdMTw/VjY10tLXJ\nO5A6OynftAl7fLxINBZqacEMhPbtwy/8XbpGRmixWBgzm0XWHwG/n4b162mtrsZrMOARdOYs2bCB\n8S9+kXBJCXbR0ULp6tWYc3OJTkggLPTFAkhLSGBIITlLSE5mHMS+YQBER2PRNCUBFyaTnHMCp23g\nd23eTPbICP3Clri+zk6WNDXRr/ADmxoaJkUlUkVhYyPO3bs/Ujn5UWiqreWyujoGhofFAprori5i\nd+6ko6tL1KM+FWDcmiYyEvOMjeHs7ibmzTfldfOeHma/8QZ9gYAoIHYcOUKBx0Pixo0YNE3Ukqn3\n9FDZ2Ul3UxO6ICB2HDlCzugoxS+9RHJCAu27dk2bO3HC1qKzsxNdcLPx+Xwcy8igIzeXcEqKiJs8\ndy5bLrqImGuuoaevT3QuXPjHP9JdXEz0/PmiwG+12Vhy880ERkbITkmhQ7hxqU8pdxUFXB9W7k4X\naWlpDJ1wyZQgNjaWEIoGbzExmAG/QgUi8oks9ezbhxnQhSdV25YtzA6F8Hm9IhWt3+8nqqGB2M5O\nhoVr0tTE8sFBxkdHGRX8wL5jx7ABgbY2kbNiJBJBa2/njO3bMQQCIlMv3eUiMRxmrKFBtJHYdugQ\nOePjFL3xBonR0TQLbsjhri40oLO9XZTxDx4/TmdiItF+P3EpKfQKMmF3YiIHEhIYy8khLChjxNhs\nvHf11RxauxZLVRURwfGW3X039atWUXbddXS2t087CFssFs587DHaQyHiFy8W/S55CxcSv2QJmR4P\nVrOZTmHWH+104tV1scFbdlERQ14v0enpjAvLcKSnY/T78Z2Cclcl8McmJwOItQMGgwGjyaSkKbIl\nJk4Kznw+MdcQHS3mfMBVZv6DESoro9ViISysyZnNZuqrqog1m2kX1AH7OzroKylhKD0dTbjR2p+c\nTG1CAqmxsbgkNw2jkYPl5QylpxMWZt8t1dUcq6oizeGgR7A/EJ41iwOFhfTOmSMKMEmpqWy99lqa\nLryQhMpKvAJ/lrjvf59dRUXkXH8944KsfeFll+G5/XYilZXEzJkjummc88AD+CsrKVy5ko7OTkLT\ntOHIKisj/bOfJaavD1NRkWjNtKwsjEVFJA8NYTYap+0tBJMaCV3XGY6NRVNQC2sdHaQ7nSKDNwCc\nToLhMBHhvpbJZCI7KYmxqChxZ098QQGm0VG63W55l1dyMkFdR1fx+UlIwK5puBUUsWaLhbDCzcaW\nlEQQlAK/Sdj2fDJO28C/9OtfZ8xqxWSXVQKrr7yS0JIlGOPiCAh+qOyiIhK/8hX8CQlowpPxvIce\nYsBuR8/NZUxwsS/4l38huG4dMUVFjAounviEBKp/+lNGfT4oKcEnyPgX33gjwdmzySsr47ggqDmK\ni3FceilWl4tQTo7IsqF86VISSktJCAQ4NjQ07Zqw0WjEUlmJt6GBcG7u5FOKAIbiYmK7ujDabDQJ\nbC2KzjiDjs5O/FlZjAo3ESksRGtuJsbppFNq8Jafz8DEBIPCrD1pzhwGW1rwORzi/RecTuy6Tr3L\nJQ7CVqeTEU1jQrjPlF1WxrjXy3AkglvazZaSgi8YxKOwh4fdTiQqikGFdmSjzcaows3GGhvLoK4T\nUtgfiJxCjV+d+U+A3KwszDfcIObp8fHEXn45VWeeKeKZHQ7SjUZmP/GEeM20zEyGv/hF5klVv9nZ\n5Pb3k//iiyJaXmUl+8fHmfvjH5NVUCBbMz+fNI+H6m3bRLSCZct4s6ODMzZuJD4pSbZmURFRbW1c\nsHMnMQIhTPGSJbzY18eyz3+e+MRE8Zo0NbH4zTfJEPRRx8XH40hOJio/n/JHH5WtWVBA5OWXKXvy\nSZIzMkRUraCAvPh48l94QcTLLS1lr99P/g9/SE6RcEpfdjYp27cze/t2kYALAIeD5Jwc5n/rWyKa\nzWYjKTqaksceI+lE+WW60JKTSY+Npfqhh0Q8mNT3WNevZ86aNWJuVkYG/muuEfNCgQB9ZjMXf+5z\nYm5E5anmBE7bjB8mM1uLQN7/Aex2ksJhTMI7pqO8nKGhIZJSUsRLag4HiX4/UdIWrOxsTD09pGdl\niWgmkwlnZiZj7e1YLBbZmid61LPy8kQ0e1ISqQkJDHZ0iBSXwGQQbmwkKy9PFGAsVis52dn019cT\nn5AgW7O4GP34cTJzczEIrQGsJSVobW0kpaaKeNlLltDV2kpaVhZm4eacnpeHuaODDKHi3Gg04szO\nxtPWJj4XrMXFeNvbxecCAJmZxI2Oim7kU0hxODCMjIh/l6SiIryDgyQIKwEA7T09JCvEhdHhYdwd\nHdgVMvC2N94gXkE7AMApzCg/rQO/soBLUbmbnJpKUNdFG7QfwOEQ1zoBEsrLGZa2/p2AKT+fsIKi\n1VRcTEi6IXcCMSUlTNTViXlR5eViUdMUTMXFhBW4WUuX0t3UJOt6mkJhIbq0zMOkAZnVbKZVOpQH\nxO2uJ8OYmyvaiJ5CfnU1XYOD+P3/Y0z2xyMzU9yNBnB8/3609HR0hXLNm//xH7h9PrFy1+f10rJ1\nq1JcaHj9dWyDg0pdPVptLbGBAB0K11tE8XqB0z3w22yg4kltt6Mp/EgGg4GM+Hi5tTJARobSRZBb\nUYF7YkKsogUgJ0fU+jeFgiVL6OjqErlkTkHPzweFk7h46VK6+voYV+mFLioCoVAIIMPpJNpsplXa\npTW1pkLg1zSN5OJiBgVjLaeQMHs2wwpZnq7rk8I64aZwJBKh+/hx0uPjaRFaGex86il6fT50hY3S\no7/8JaNGo1jprus6zldfxSYUuQEcfftt5re04FFJePbuJXF8nB5Ba+8UtJoa4nSdhiefFPGGBwcZ\nFj4NnYzTO/DHxqp59SQmoqtMywFiMzIYV8nAFTN+s9lMVkoKrcLZwsDkxa5wrPEJCaQlJNAo1EgA\nypmw1WYj2+Hg+I4d8jVPJQiXlDCo8DltVVWiDWyYDEwjg4NK39HezZtxlpUxMjEhtu949JvfVFJU\nu5qaOHzHHcTl5eERTtEyHz+Of/du3AqWIRmtrYy2tqIJRVgdx48zt6mJ+HCYfmFyFty3j3ggrHC8\n3vffJwJ4hTfHSCTC0YoKNLMZo7B8bE9KIvH880Wck3F6B36bTSnwx2dnM6qilANISVEbAu1wEFa0\nUbU4nfgVMhEtL08kwjoZsYWFjEuFN7pOVFkZQWFQC/j9hMNhzMXFhIQy/c6mJlIWLqS/oUHUdeJq\naJhsrVV4WnjmjjsoWrCA/uFhhgQbbINuN6/ecgsUFIifioLbtnHgt7/F6XTSunOniJuzaRMut1s8\nkL5v/37mv/46HuFweABaWyl96y3x02o4HMbQ2Ijx+HH8wjX7du4kPRLBODbGuPAmNzIywkRcHIMK\nvvgpP/sZ9bGx5Ajtpw0GA3OuvZYooxHHrFnidfVPonIXoKWpCU2h1HOspoZ+j0fcnla3bRu+2FgQ\nZiLBYJDe/n66hcpdgO3PPqtktrbjmWdIqarCJRAKwaRKdNODD04GJ2FN+A/f/S75ixbh6unBK/hd\n6rZupfahhz7ospHgjW9+k8S0NMKRiKgvvvfQIdp/9jOlp4Ws997j4BNP4HQ6aRE8oXTV1zP3hRdw\nWyxibyFjXx/af/4n5OYSEXADgQCpXV1Ydu7E5XJNGulNFx0dZI+PM9TerhT4KwYHSQmHaT98eNq0\nlvp6JgIBMJvxCZOAxIIC3j37bIazs8WjF9f8278RqqxkIjpa9h0BZfPmoWuaUhJqtduVRy9+IgVc\nkUgEz4ED+BUyd8uLL+L3+0XKXQDvjh30t7aKM/6mffswPPXUpMumsAXLdc89eOLi5OP23n+fjqef\nxmI24xIENldDA/zHfxDOyUETBv6i/fs5+tRTZKamclxgthbu7cX40EMEc3LEQbiqo4O6X/yC9KIi\nuiU11oEB8p95hj4gKMz4LYODhB94AAoLiQi4AZeLsuFhQrt24WprkwWYnh7mHzxI9+Cg6IbcfuQI\nOUNDzHvrLcyRCB2C4x1ob6crJobe8XHx5K7BM8/k1dRUovPz8QqOt7CqCus99xAsLcUg3HQvXLEC\n69y5mOPjiVYIwrakJMy6zrDwpqFpGiazmaBCLLLa7ZOjVRU2zw2fRJO2Yzt3UjIwwIjULlbXSWho\nwB4IyBV6DQ2EGxvRhRn/2KFDzN26leSYGFwCoVAoFKKssZGeujpx4Ne6u7H8/vck5eTQL1Brjhw/\nztmHDtHU0CDuAjEPDKA99BDmggL8kjLRwADz6+vprKtjSFib1dxukh95BG9GhuymMTCAw+slautW\nXF1doicU+vuZ//77dA0NyZ5Q+vsJAMaaGmKiomgWnAsdZjOH4+LwJSWJvIVsVis7N2zg0Lp1pJWU\n4BZcL+t++Uu6L7iAxDVrRMpxgLU/+hFhq3VyFrLgOtM0DbPTSfzYGD0jI9NWVH+AlBRCkYiSZYOW\nmIjdbMatMMMiymZTUu5aY2IIgZJy1yht0z4Jp23g9+zYQRQwLNwwbTt6lLzGRkaDQYalNfeGBnJc\nLhqlzn+traQFArgAg+DO3nbkCLn9/cTX1tJhNIqW1Lq7mXfsGI26jibpzunpwQSkbN/OQWkNsb+f\neQcP0jAxQVjSTud2owHhbdtoTE+fdmeP1+ulZ2QESyRCl6ZNWuNOE55IhONZWYxGR6PPnUvPNMsn\nkUiEhtWreScvj/gLLmBYULpznHce2669lpRLL0VfsQKfoGvl0889x0BGBonnnUe34FzILCkh48or\niR0YYGL+fFFmaTAYJsdwahqH4+Jk7qeaRkZ2Nt1WKwGh8Ct71iyGBwfxFBXJW6dTUggAYypB0W7H\nnZpKWKHOb46Lo0fBQsFqtdJmNKIpHK9NaFdzMk5b5a4eF0dcTg6ceSa6rk9b9OPp6MA9ezZFsbHE\nC764SCRCfVQUizIyKPnsZ0XHOhoM0pqSQtSSJcw677xp88Z7ehiaPZukmBgyfvxj0ZqdWVn4ExOp\nuOEG5l511bR5xuRkahcsIFBVxWfvv3/avHA4zPH16xnatIn1TzxBokDYlHD++by9dy8F55/PZ772\ntWnzoqOjyXj+eRquu47PPP64SPh11g9+QE1XFzmpqSy4/fZp8wwGA5c99BAv5uWx8oorSE5LmzY3\ns6SErgULYOtWzt24cdq8KSSUlkI4zILnnhPx8pcu5U2Xi4v+7d/EojHy8oh95x2++M47Mh6gZWVR\nuGgRC266ScRLSknBqGlc+PTTYuUuycnk2Wws/PnPZTwAu52KdesoV5idm+t0goJy12KxkGC3UyYc\nGwqQmpkp5kzhtM34F91wA56CAkrWrxdd8FXr1qFfcgmmykoK5s2bNs9gMLD6kUdoiopi/r/8i+hY\nz/7pT+lfsIDCs88W8WavXQs33ogxPZ28uXNF3E898giexETsc+aIeNVXXgkXXECG1YpVoL41Go1c\neu+9jHqXg46lAAAgAElEQVS9SIcnFp9xBrGLFqEJWwYNBgNzV6zAHwyK9jE+QFkZunADESZbbJ2F\nhbQILS0ArLNnM6GwJqDctmpPSiIlLo5mYVkUwJCXR0hBCwJMNiUIzd3ghC9RejpdwvZIgMTiYoZU\nfHpgcjKfYps3sbGgoEHRNI1oEI//BIhILTROwmkb+AHldk4tMVHpB85wOhkNBhlXWTMzU1TrnIK5\nqIigguJS0zSSCgtxKwiFpqwMpIiKiiI7P58WhexQNQgbDAbSy8vpfe89MddaXY1XRbwFaGVloHC8\nxYsX0zc0JGoD/QCKgR8gtqgIj0IgzVm0SN4NNIWsLKXAD2ByOMRjG4FJIzuvVz5zF8BuV9b3+AwG\npcCv6zoRjwevArdbUcUNpx74ncBWoA54G7j6I953N9AMvA/Ih0t+FGJi1JS7iYlKyl2TyUR6bCyd\nwswUQFcM/AULF9LR16ekoqWgQMnPI33xYnqFffFTMCgGcOeZZ9Ld0KAWYMrKQMECoXTZMgYGB3Gr\n+L6XlioF/qioKJx5eTQr3ByjyssJqMr0FbQDMGlTEhsdTbvKuoozn4FJpbuC4DHKbCbeZBLP3AU4\ncvSoUkKo6/qk2FEhITy2axc2r1dpAteYiqjzBE418AeB/w+oBC4D7gTiPvSeRcAKYAHwixOvvw1U\nM367nYjC0ASAeIeDURVZt2L2ExcfT2pcnFgyDyhf7NmFhZiMRtoUAptWUgIKN8b07GzibDaOC6yK\nP1izvFwpCJvNZrKLiiY9WqTcqioCiiUbY2kpusJ3VLxkCZ19faJRhh8gP1+sHZhCcn4+bqGPv67r\n2CsqJjUAQhzZtYtwWhqaQuB/6lvfIiUlhX6F77f7lVeYUBBnNu7dS3p7O2MK3UBjW7eSGAxS9+ab\nYq6m4vd0Aqca+HuAqTNigMnMf8GH3rMY2AgMAk8B5ae45n9BMfDb8/IYVrU0TUtTGglndDrFwyym\nEF9QwKhABPMBCgqULnZN00gpLmZAOGwdwFBeTkjhogOIq6zEo1Cail+wgOH6erUnlPJypSeU0hUr\n6OrqUgvCJSWgkEFbbTacWVk0Cm0tgoEAWkGBSPg1hUM7dij5/Bzds4fenTsZVPCZGn7lFTo7OtAV\nAn/p/v2M+/1EhNdor8vFWc3N9Cs8oQy/8w6p4TDj0iE3ADU1WADvu++KaJFIhK5/Eq+eIiYz/z0f\n+vtFwMmF1H6g8G+yomKpJ8XpZGBiQs2VMTVVrNwFyJo7d3LWqkJwIidHyXMnZ9kyXC0tap+zuFip\nnlx81lm4OjpkffFTUKybF82di9fvp0ul5qlQJtJ1fdJbKCeH48IN3r7OTrTSUiLCm+OxXbvoa2mZ\ndCIVcv/4zW+SPmcOro4OUV+8ruts+/a3iWRni8+/8aNHMTz55KTPlDAgmltb8e7fjy5stw6FQpga\nGiaFVMLMvX3LFmYHg4xOTIj3B0b27MEHTCg83YycdRZDJhPR5bJ82GAwkC+d7XEyX5n53xEHPM1k\n2efDKbh24nUyFKLf/4QWG6sU+OPi4jBqGiMqGznp6WLXQIA0hwOAPhW/nhOj86RIdTiwRUWpuU8W\nF4s9bMLhMHHx8WSmp3NcsNmq6zqjw8NKdfOmgwcnXVNLS+nevn3avFAoxI6NG4meMwe/MPC/9NOf\nMtTTg6msjLDQgvrpG24gf8UKOlpaRPs2Y3V1NClaTJS1tND+5JPE22yikmGPy8UFu3bR6nLJxz22\ntzNr2zaCUVFyn6nmZsoPH6Zf+DmP19ZS3N2NraeHAeGTY3h8nLa8PCyaRoewi2nBgw/Slp5OSlWV\niAew5AtfwGcwkDt7tpjLP3jYuhl4Fngc+PNf+PfdQMVJ/53K5Ebv/8Btt932wevtt9/+2IUP19ai\nK+yG73jqKRJttkn7BQE6GxvpGR5Wyvi3PfUUmVlZdAo3ZN589FF0hYz/0Ftv0XHoEElFRWIL4Gfu\nvBNzRQUBYWb5yp130t/ePrkJKShNeTwenv/a18hYvpy+o0dFTyjHfvUrjr/7rrjLZtDtpusnP6Fg\n0SJ6+/tFXTaZ3d3U33XX5NOC4DsKhUIseO89Wl9/ndSkJJGtBQMDZD35JG6LRRz4td5erL/7HTG5\nuYwK1MLdBw6QGw4T2bNHblfc3k4sMN7XJ9rbikQi1Hk82JKT6fN4RHMAElNS2HHNNXRVVhIvFB8u\nueEGxs84g+TERLzC69uemIjJZiOikEhaLBbCmkZ4mgns22+//UGM/NPmzeL1pnCqAi4N+C1wGLjv\nI96zG/gl8BhwDvCR6dVtt90mWjyqqYk+hbts9M6dtJeWUiWc2NS9cyfhxkYi69aJeIFAgJaf/pTi\na67BIZykZXj+ecbXr8d41lkinr+xkc7f/56oK67ALpiepOs6xkcfJfaCC+hYvVq0ZtbAAA133UX8\nRRdhFmgA3F1dVD/3HMGvfY3wZZfh9/mw2mzT4qZPTND7k5+Q/PWvi7xSBtvbOWf/fg79+tckfelL\nBMfHYbpioeFhsv/8ZzoffJAogQjQ3d+Pc2gI1333Ybj2WpGAkIEBckZHOVRby7hUYNTXR1lbG09X\nVLBCcC54e3poyMggxWqlY9YskVBSO/NMarZuZWDNGgoqK6e9psFgYNWzz3J4zRpSr7iCYCBA9DTN\nyDKKikg94wyCTU1YhdcLAHY7gxUVVClM2ItLTmZY8DmnYDKZ6LRYKJrmeNSVK1ey8oQL6DvPPsvT\nr7wiXhNOPfAvBzYAB4GpVPZ7QM6JPz/MZM1/O1DL5AbvhlNcE4Ch/n4WdnTgVvC40OrrKdB1HIXC\nrYbGRirfe4+EBx8U0ZoPHODSQ4eoj44mp7paxI3v6yP4/PMsffVVEY++PvI3bmTippsoWLRo2rSR\n4WHmuFz0/vu/s/6RR2RrDg+T+8ILhL74RfLmz582baitjdnj4+y+6y4+JVSlMjLCvE2bOLphA/M2\nTP/UGu/qIg6Iuf9+KmprZTOCR0bIGR2l7s9/5vxnnpk2ra+xkaRIBHtPD76qKpwCcd1YdDSNmZlM\npKdz/ve/P21eJBKh5fOfx/3kk3z22WdFyt3lX/gC7/f2ktDWxppf/3raPID5n/sctX/8I1WLF1Nx\n8cUibmZeHjsDAc793veIjftwk+Bfh56SQoamUX3ttSIegG63U1xVRWZJiZiblpGBJrRlnkJmbCzp\nCqWeBOlc65NwqqWe7Sf+H9XA3BOv15gM+A+f9L7vAPnAfP5Kxi9B46uvUujxYNi8WVQaCAaDmOrq\nKHr3XY5LJ+YcP07R4CDNwovAU19PPMDjj4uOVdd16O6mYtMm6l57TXas/f1keL30/ELWPdvT3EyG\n30/+00/TKP1+hodxeDzs++lPRbTw0BARwFxTI1aXtnk89EZHiydTmYxGaubOZaiwEL+w6yR4zjns\nyMkh7ctfFvEKq6s5dN99jJaVUX3uuSLuqjvvZHj1avKLi0VKdYPBwKd/8APGvV6GFVoVKSgQu7R+\ngJwccTcQTGbBWSkptAvKUlOwFxYyojj3ArsdXbHNm5gYpbIzgMVkwqei+v0n6er5u8Jqt7N37lx6\nZs3CIzByGujspLeigrZZs9CFG8PupCRqEhIICO+0uq5zqLyc4YwM0QAYn89HQ34+zYWFmIXe2/6s\nLOrz8ugSPtVYzGZ2fvrTHF6+nDRh5hO+7DLezcuj5JZbRLy8pUt57eab0VasoEBoMbF+82Y6S0pI\nWb5cxJuzfj2Gm2/GGomQKhwkvvTGG7HMmyfWK9ji4ph32WV0HT0qd50EZaGayWTCWVBAm2Dzewop\n8+bR39io3o2mOAjIkpWFX8EqIrOoiP6JCbXv124HlXnanGg0UZn/DViio/EprGv4JA5iqbroIqis\nJHPpUuITE6fNc+TlkXzddZCaSomwhn3O/fczlJxMtjBbW3jttQQ+9SlSSkqwC+qHVquVlY88QofP\nR/GqVaI1l3/724wvXUquwCwNIG/2bBxf+xrRPT2y8gew6POfJ6a6Gq9wMzklJ4fCiy9mXMFLJioq\nCkt1NX6F8Yl5a9bQdfSomip61ixQENWlZWWRlJDAMeEULZi0iYgoisY0RRsOZ3ExgXCYXoX+di0n\nRz7AZQoOh9KMapvNRnxUFD0K62qKin4A3WZDUwz85qgofAoztQ1Cx97/xlVm/hNAt1qV2jkNyclK\n3tkASZmZuFUUc4rZjyM3F7PRqCSZ10pL0RQu9tLly3EPDTGgIKChqgoUxGZly5Yx6vHQqWAxwezZ\nSkE4JSOD1LQ0jigod6msJKKipgasVVVMKNyoCletoqO5WdTp8gEURWMGg4HMvDxckg6kE4grL2dU\n1eAtMxNNsWSTmpZGn8IN0pKRwYSisLNvaEg54x/p7iagUOoZVDWj4zQP/NhsSoE/uaBAPAnrA2Rk\noCl84VpODhGFwK9pGqmFhQyoDD4vKVGyBjCbzWQXF9MyjZbaD8MwaxYRhcBvNBrJqKykS2FNy4IF\neFVUk0DUnDkEFdTCxevW4WpqUhOqVVSAgrbCnpREemoqDQoD6VUzfgBN0fojf9YsBjweuac+gMOB\nruBt1d/VhSE1FV1BXb/r5ZfpV8z423bsIKTA7Wpuxjo8zKCCQLNHxQzxBE7rwK8pBv7U7GwGfT41\nQ7D0dCXzqOz58+l0udRqpaqeO2ecQXdjo9rnLC9XCk6FZ5+Nq7FRKSBqiuWTsjPOYGRkhG6V7HLW\nLHSFTcSExEQcWVkc3bJFzDVUVaELhV9TsFRU4Fc43vwVK+hobVVzrVT0+fF6PGSnpdEi9F9q2L2b\n/kBArNwF2HvffYzoupLWJn/7dka8XrFFsru3lzyXiyGF39T16qskhMMMKuy/aIrJDpzmgV9XDPw2\nmw2rwYBb4eQgI0NJuZvqcGAyGulSCU6FhUoumxlOJzEWi2jE3wcoL1faSLQnJ+PIzOSoQvlEVwz8\nJpOJjKoqOhXWtC1apLS3AGCeNYuQwsVXfPbZuFpa/m62Fv1dXSSlppISH89xof/Sm48+ilZYKJrz\nCzDu8fD8N75BdG4uQeFNY3TfPgK1tfQr1OmT29sZ7+wUB/5AIEDSsWMk+P3iEmfz66+TGgxiUDje\n4HvvEQZ8Ck6bI0Kbh5NxWgd+FGv8AKl2O30q9eSMDKVMRNM0MnJy6FYoK2iFhURUjhVIKC9nWMHx\nMmb+fMZUjOGYDIhBhYCYv2YNHaew2aqSuZcq7C2MTZUuZs1CF35HB999l3i7nQzhzbG3q4t3Hn4Y\nFDZ49/7qVxx96y1iysoYF35Hnl//Gq/VypBQLdyyfz8LXnqJcbsdXVribGmhePNmRnw+cZlIb2jA\n2NSEXxiEj77zDmV9fST7fLQKr9GxlhYGbDYC4+PiJyrHd75DT3Q0sUKtA0Dppz8t5vwzQpfC1dCg\nN+/bJ+ZFIhH94JYt+vjoqJg72N2tH9u1S8zTdV2vf/ddfWRgQMwbHx3VD23dKuJEIhE9HA7rx3fv\n1gc6O0Vcn9erh0IhveaVV0Q8d2+vHolE9Nb9+/XupiYRt+HE71j76qt6KBicNq/m5Zf1CY9H7zp2\nTG+vqxOt+dRtt+m6ruv7N2/WfRMT0+a98+CD+r6nntIHOjr0xpoa0ZpPn3uu3tXQoNdt26aPDQ1N\nm3fo3Xf17VVV+lB/v35oyxbRmjU33aRvP+88pXOhNjdX337NNXrNK6/okUhk+ms++qiug/7ihg16\nZ0OD7Hgvv1zXQf/DVVfpwUBg2rzRkRH93dhY/ZDFov/xm98Urdnwzjv69tWr9UeXL9eb9+8XcXVd\n199etUp//gc/EPN0XdcfSU/XD+zcKeY1NTToKPqendYZ/55HHyU+PV3M2/vCC2iBADahKtDv97Pl\nP/+TksWLxWv+8bbbKD/jDOKFM0Rfu+cevKOjVAlVgZ1tbbxx990ULVpEsnA25+9vvBE9EmHB+eeL\neEefe469jz5K7pw5ZExTgj6FN2++Gd/EBPPPOw+jpD+5ro7377gDR0kJzoqKj3//SYh9+mkat29n\nztq1RAsGZVuDQQJ3301McjKFCz7sQv7XUTg0RPPtt1Nx5pnE2u3T5vn7+lh2+DBHHn6YKmFrL243\nc157jYmODtG5MDoyQlxfH3kbN5KSkSESjmkuFyEgXFNDotCmZDA9nT0JCeQuX45JoDS2WCyM/exn\n+BYt4jPCmbvFK1YQfcYZVM6dS75QSwIQk5iIU/g5p+CMi8MmsDiZgnh+8kk4rQN/9oEDNP/xj2Ke\nfugQ408/LeYd37OH1KefVtosTXz+eRqEntsAaZ2dHBOqbwEGmptJfuQRkbhtCnMaGqj5v/9XzIsK\nBDD8/OeMK/QkL2hpofbOO8U8ze/H+fDDtCvU6R1jY/TedpvYtlrzell48CDv3323eE08Hsqefpoj\nmzbJeCMjaEDMQw8xKCw1jvf1EdA02t94Q8Qb7e+nef58XGVlaMKmhLSLL+bdSy4h+wtfmLbv0hTW\n/epXjKenk7pkiYhnjoqicPFiRlXakAEtKQkUlbunIuCKio5Wauc8FZy2gT/g9xP1/vug4lBXX0/8\nyy8zImzp9NbXs6yujn2PPy7iBYNBMlwu3PffL+IB6P39pD/2GD3CDbLQwADzm5o4oBCcjB4Pcb/6\nlXxotddL9ZEj7FcJ4D4fWQ8/jEu6r+DzkTs8TNsPfiDqmIpEIuDzMe+tt9j2q1+JltTHxwkDfa+/\nTkDYU19ns9EdH09AGGBisrJ4d+1aOs8+mzjhU2P+gw9yuKKC/Ks/ajLqX0Z2URHZP/kJfr+fXIH3\nEoCzspK4ykrxpvAU4nJyGFNoRc4qLaV3bEype0m329UFXDEx6oE/Kgq/AldXmbNxAqdt4K9/4w0q\nenrI2LaNbunGZ3095f39HP3d70Q0raUFExD8wx9EvPZjx8gZHCT/xRdp3vPhOTUfg74+CgcHOXLX\nXSKaNjyMBui//z390slfHg/ZXV3sFprR6ePjjAMDO3bgF5jnBYNBjpjNBKKjcQs3LidiYjhSUMBg\neroocw+HwzRedBHvFBay5ItfFK2Z8ulPs+3qq8k+5xyihFYaV7/3Hq1WK6kC4zyAsnXrsHzmM6QO\nDGCOihJxc0pKsFVW4lXoHClevJi+wUFGVDLh/HxQFXApjiqNiYlRVu6SkKDu1aPYYQhgjIoioiDK\n+0QG/vTiYt7+9Kc58JnPECOwV45EIjSsXMmOkhJShXVzY1UV+8vLaV+8WJRdmnSd2ksuoe7MM7E7\nnaI1feecw6a0NJL+9V9FPHtFBW9dfDH6Zz5DqrD2OHzrrbydlsbK73xHxMvcsIG9X/wiWWedRbTF\nMm2eyWTivJoajgKFQsvrFd/7Hp4rryQrOhqjQMJuNpu5/Ne/RtN1uoSK1ry5c0lYtQoUOrRMJhPp\ns2fTpdD/7zjrLHoPH1bTZVRUKLXnRkdH48zJoUmhTBlbWYlHsRuNrCw0BQEXQGpGBn0KnzUuJweP\norBTi41VNmnDbEZX6WQ7BZy2gd9RWkpiURGO1FTiBf43BoOBM2++mSGfj4KFC0Vrzt2wgVBFBYXZ\n2aKNrtxZs0i8+mrix8dJOjGJa7o44+abSSwpISTMfgrPOIP49euxKsj013zpS6RnZXFEOAA6q6QE\n65Il6MKAqGkaKenpOIqLOargL25avJig9EmKyXMhccECBhX6/7PXrqXnwAG11tPqalBod80uKiIm\nJoYGBfsEysvRFYdzG0tKxKMiAQqqq+kbHRXP3AXQsrNBwR8IwJCWpjSvNzU3l/6xMSWRpa44/xtg\nbHwcFM6jT2TGDyeUu0KVHUBaZiYjwaDaRZuZCQqZiHPJElytrUrzbw1lZUQULlrHWWfRU1enlCGa\n584lpGATkX/eeXQfOoRP4XcxLFyIrqA5qFi3Dnd3Nz0KsnfmzweFNTNyc0lKS6NeeHMEMMybR1ih\n7AIQM3s24wqBv2DVKjoaG9XOeYUxnDBZu3ZmZNCscLxadjYRxcBPWhooWDZEgkHCwNjYmJi7f8cO\n5Yx/tLWVCYW9hQFV+2lO88CP1QoKg1iioqJIMJnoV/niFAN/WmYmFrNZyWyN0lIlg63soiJibDYa\nFLJhfc4cUOiUSXE4SHM6OaKw6a4tXEhEqCwFiLZYSJszh47XXxdzE1auZLSmRinLi1q4kKBCUCs7\n5xy6Wlom5wxLoahuTkpNJS05mWMK1gCcgs+PuaCAoPDc1XWdlMpKJYuTYzt34omKUrJsqLnnHuIM\nBgYU9hZsDQ2MKmxkD3R1YR8dpVvBf8kl7Qw7Cad14A/ExTGoOIzAm5/PiMIPHMnOpk/Fh0bTCFRU\n4FYxTauqwqViLwH45s5lROFpIW3VKg4qeqmPzZuHR+FGVXb++ewaGFB6WvDOn8+oUF0KULxwIa0x\nMbgUuKG5cxlQ2LyMiY2FqiqaFayZo+bNo13hvAXwzJ7NuDA4+X0+spcvp3ZwUByEazdtYrSgQOx4\n2d3WxsHf/Ia2+HhGhDfH0Z07cTU2Mqji4dXYSJ+m4RGWicY9HqwdHXQpPGW0vvQSE+EwEYXrZVg6\nKOmfFEqqt08CJIrJfwbuzJr/O9yBnh49EomIuXXbtun97e1Ka/7hppv00cFBMU/Xdf3hxYt1r0AR\nPYXajRv1mtJS3e/zibl7brhBry0t1QN+v4gXiUT0PUVFem1hoXjd2mee0UOg783JEXO3/OAHervd\nrv9hzRrx7zM8PPzJVO5+UiDZSP5n4P4915zaM1FZc6pGKuX2trXhqq9XWvP5u+7C7/MpcZ+4/npA\nfrwTDQ0c+8lPlNYs6+rikFAFCzA2OsqZhw6xT0EIqLe1Me/YMfYJR5wCcPw41ceOse/3vxfRWg4f\nJrmpiTSXi91CcWdsYiK1S5fSs3QpHmE76Krbb6enuJjSb3xD/PtYBJ1zH8ZpHfhdx44pORyGQiF6\nFPuLexUnCvUpPp73uVxq7XtAm+K0pjqFEgRMeos3K9ToAf58771KdfbaV17hwFNPKa356s0341b4\nXQY6O6n/1reUjtfZ2krtHXeIeZFIhHnbt7P/ySfFXEZHyX/8cZpUfle3m+Tf/Y5+Ydmv/fBhciYm\niH7kEXnprr0dA9D72GPi77jJZqM+KQlN2EThyM/n+G230XPRRay45hoRt3TNGkyzZ5M6axZJGRki\nLoBmMoHCNa4aF+A0D/xdzz3HIQXrhWM7d3LkvvuU1vzTV76ixNv6f/4PfQo3m5bNm6n5939XWvPF\nm25S6iLq/N3vOPzii2LeyMAAjbfeqrSmfcsW9goFdQBGwPDDH8pVxkDlxAR13/62mBcJhVj86qvU\nKmSkWiiE88EHaRe2c05MTJDq9RK5+24mpN0jY2NkTkzQfeed4kCqu91k9/ayS3i9+Pr7aSguJpSY\nSI+wfh2zfj27Fi4k/itfEWfBn3rySeqio5l73XUinjU2ltTCQgyKM3exWpXbOTWjERRmBH9iA79W\nW4su9B8BmNi7l/hXXiEobG0bHBhg2ZtvUq/QsVLY10fTPfeIeUaPB+sDDzAmfISMRCIs2rePPQqP\n2smahveHP8QnfJrSw2GWvP02exQ+Z4zRiPX22xmQPlFpGrMaGzn0rW+J1wSofuopcRYdDoWIAWLu\nukt+vMEgOcPDHPze90Q0z9gYYa+XxIEB6l59VcT1WizUFxYykJpKWBhgxr7+dTY5HKwTWn/Mv+gi\nQrfcgtHhIE9oela+Zg3m0lLiFMajTil3VeZeaElJRBRHshITo9RaDoDJhKYQxJUGyp/AaRv4Q6EQ\nppoabFu2yDOgI0eY09jI/ieeENHadu9mjtfL6G9+I1sPoK+PjCeeoFvaFjc6ypymJg4KLRu8Xi/x\nPh9x996LW9p+Ggqx4MABam+7TUTTdZ0oIPUXv6BL2EmkaRoV7e3UfvObIh4nMkL7q69y5L33RFRv\nKERQ12kX8jRNo6a8nBGHg6Dw5hhaupT3q6qIu/xyES8xMZGORx6h1W5ngZC74tvfZvySS8iy20Vu\nlwCrvvAF0tPTOaag3LVUVDCh2AZKTo7cx/8EUh0O+lVGW+bnM6Q6kvUUBFx80ks9ksfQI++9B8Eg\nUUYjdcKsv72ujiGTiV5hT7O/sZERwLN3L/2CYKrrOu7eXqyBAMeef160ps/txm000rN3r+iHHvd4\n6DAaMWkaXUKBUi/gstvpFd5QzdHR7Jw3j668PEzCjafx+fPZV1iI5YILRLzMsjJe+MpX8M6eTfmy\nZSKu8557aDznHDJmzRLx5qxaRdoTT+AZGCCtqEjEXXzjjYTXrMEmNKOLtlhY+7nPEQ6FaFJQ/Wpz\n5qArThqLrqwkoMAtXrSInsFBpZm7utMJivtphowMJeVuSlYWbp9PqVSpn8JQKEwmpVLP/zMZv6Se\nN+vMM4l89auMXXABC4WTaM557TXeSE1ltdCVsXzDBupvvBH7Zz5DqtDjPuXJJ9mdmMiKW24R8cpu\nvZWGDRvIWb1a5EWTkpKCc8sWWgwGKoTB9Lzf/paeiy/GKbSXKJk/n9JnnmGsq4t44SbXmd//PsHz\nzsMmnBDlKCxk7d134z52jF5hhphbVoZhxQpQEDUVVFdjiY0VJx0AhqVLCSv0YBsMBuwLFjCsYDFR\nsG4dnceOKWkkVMdwRkdH48zOpknh+zXm5RFSUWKD8njU2NhYzMCQSrlH0UUAIGIwqGX8/68EfjGi\no9EUJOixsbGkWK3iQJGQnIyloECciWiaxvwVK4izWmkSZk4pDgem6mo0YUA0GI2UL1iANSaGI9u2\nibiapsHSpaDQBZJZWEhSbi51CpvDplWrCCmUFGLi4khZtIi2F14Qc5MvuIChHTvE2ZOmaUSfcQb+\nt98Wr1m5fj19bW30qWS0ihYTSampZCj4L8HkcPiwQukEwFhURFhBnJS7YAGu7m6lcoaelqYU+DVN\nIzU+nn6F/YH+4WF0xVJP17Fj+BRsIsKnYOx2Wgd+a1kZodmzlbjGCy/EqPBIFzdvHoHiYrU1L78c\noylPEMMAACAASURBVIJPeMrKlYzl5CitabrqKswKF0/BhRfSpTDdDMBwxRVEKSiqZ33qU7QXFir5\nyZgvvhij0CIZoGDOHPyrVjGoUBqIOf98QgJn2ClYbTZir7qKcYXglLp2LaPCJ7Ep6JdeilVhalPx\nqlW0FxUpta8aVq/GnJoq5iWlpMDZZzMhDKbhcBhDZSWRwkLxmgc3b2Z46VIsQttrgNH9+2lLShLz\nAHzBIG6Fm82g4h4IgLrS5m8PXeXEmsEMZvDPCb/PJ7LnPhk7X3yRpRdeKOYd3b2bnk2bWPnDH4q5\nNbffTtjnY4mwkQKgZs0aIuXlLBaWjzsbG9Grqui+8koWPvqoiLvn9ttZ/KMfgUIcP60z/hnMYAYf\nj4DfLxqMczL2vPSSuO15Co999atKpRqfz0f9HXcocccPHcL2/PNqHS/19RhfeknMHfd4iNm7F8Pm\nzWJu58svk+33Y3znHflmrcKT1BT+FoH/d0w2gnyUZeBKYATYd+L1/b/BmjOYwT8Muq6LRy5Ooeng\nQaWSCcDLCqM7AVxNTbz13e8qcbWaGmruvVeJO/vwYWofekjMaz14kEtra8W2CwD68eNU79/PAQVh\nJ4cPM+fwYQ48+6yIdmjTJoy6jmVsjMPC/bS0s85i+7JlNF16qXizdtENN4jefzL+FoH/EeDcj3nP\nNmDuiZd8IOtfwUx56G8PlXY2mPwtpDXZKXQKZwpPYWJigiMKlrYAr91/v1ikNoX//NKXlHi9mzax\nWzGQmv/0J+pfflnM8w4PU/Doo3QIGwQADB4PCQ88wJDCHohxYADDQw+JnzbGjh3DDgR/+1u50rix\nEe3/Z++8w6Mq0/f/mfRCQkgjgYSEECAFQm/SQlGqgBUVsLusuLLWdRV0wcJasMOuDUFQEQWRJkhN\nQk9CgISEhHRIAmmE9D7n90fIfvmxojwvLBJ9P9c1l4Vz88yZM/PMmXPe+7mBTKEpr6amhnQ/P453\n7iy+PDXwttsof/RR6u66ix4jR4q0/r164eDiQkBYmPJlMRWuRuPfDfyarfR/ci/hxMGDRAtNWNDU\noNa8/rpSzXWKH9pdS5ZQpmAOyTt5kn3Ca3/NfDlnjtIX445Fi8hUHPn62f33K9WMX7SIYwqrcqyt\nrdn/17+Knc0A7qdPc+DJJ8U6k8lEcGQkcQpnpLb29nj+85+cUsk6AKpeeIEq4QqQ2vJyup47R5bK\n+6G8nNBTp0h6VXa+VldXh01xMQEpKUQKs5sbqqtJDAigolUrSoTjyB1mz2a7nx893nhDpLOzsyP4\n6aepdnQkVOHeAvb2yss5DQsLUPEOXMFJ77W4xm8ANwBHgHcA+e32S1C6fTsmhezSjIQEHL/8Uuk6\noO2qVaQqrEt2yswkQeGmUVVpKTX//CeVCvF1/gcOEKPwU9vV1paC2bOpFp69m0wm+hw5wsF33hHX\n9HRzw/T00+QLz/ytra3pmZ9P7F/+Iv4gmBwd6fXZZ8QtXSrSAbS2s8NxzhxOS/MVrK0JKCri5BNP\n0CBd4WUY9ElIYJ/wso1RU0MD4Hz0qDi2scTRkXQPD/Lt7WU1DYPjjz7K8W7duFH45TroT3+ieupU\n2oSE4OrpKdKGDh+Oh48P5xSWkLp36kSR6sgGe3sMVQOXyaTU+GsVLzfCtWn8cYAv0A9IAi45PGbe\nvHn/eURcxvpoY98+LCMjxTdFzh44wMjERI6uXi3SGYaBe24uRSrXWktLabd0KblCI0xdZSUDT5zg\n8IsvikvaW1vj8tpr8jERdnb0j4khWmg2A7Br1Yp2r7xCmnQ9vrMzoRkZnJg5U94QnZ0Z+PXX7BfO\nCDI5OdHabKZ83jyKpZcy7O1xz8/nuPBacp3JxDF3dxqAUuHZbMmAAexv2xaXKVNEuo59+7Jxzhxq\ng4PpOnCgSDv6vfc4O2IEvkLDoq2tLZPnziU/P59ylcFnfn6gOEHX5O0NCul67l5enFONZL2CM34E\nZ/wRERH/X59U5Vo0/nKgCqgHltD0BfCzC64v3KHw8PBf/Esry8txOHiQ7hkZHJNe9zx+HBug7rvv\nRLLCM2fwPHOGjuvWkSk10ZSW0rGkhMzXXhPJ6qqqsAV8P/uMZGkztbQkMC+PfcIvDcPODhPg+OOP\nZApj/hodHXEoLSVTaBQyt2rFiVatMOrqxA3xZOfOJLVpg1VwsEhn37kzOyZMwGroUNyETuPGF14g\noXNnPAcNEun63HcfNR98gHVtLW7CZjr6rbewGjZMPHrBtX17hs+ezZljx6hUyYVVjOG0s7fH19+f\nNOENTwDbrl2pVbzvY3h5gcI9CVtbW5ytrChS8FeoxsACTWf8l/lrNTw8/D898qmnnlKrx7Vp/G35\nv2v8NwPxwM/+RpH8VK8pLyd73Diiw8Np4+srekJG164c8fEhLzRUpKsuKSFl9GhS+/bFzslJpg0K\nIsHPj7O9e4t0zm5ubJ8yhbRBg+gkPFurGzuWmJAQOt59t0jXrmdPfnj8ceoDAugonGNj//LLnBg+\nHBc/P5Eu5LbbKP/yS4yzZ2kjbMJTfviBhhtvxBDevAwZO5aub79NRWQklcLr5v3vuAP7MWOoFDqU\nbWxtCbv1Vsrz8shSyM5lyBClEROunp54derEcYWbw7b9+lGjMB8IwCI4GLPCuIdO/fqRU1hIjUoz\nVWz8AO5t2lCk8oXj4KA+q0fxGn+taj2axplfKSuBV4AOwJ9oWrrZH+gLHALup2nJ558AN2AeTcs/\nL2ae5KeLg5MTjl27YtWzJ4FDhoiecPu+fclt356+U6di5+h42ToXDw8cBwzAFBJCgPBMz2/oUE77\n+tLtpptwELg923h54Tp8OHUeHrQXupR9BwygxNcX727daCVwFTq5u+MfHk4u0KFPH1HNth07Uunt\njVtQEM4C56+NrS3eXbuSdb6mhdD5W9euHY7+/uKTAGd3dwpcXPAODcVa6vxt3x4Lb2/chYPaLK2s\nKPXywjskBHvhCYR9hw6UOTnh3a2bSAdwztMTr27daOXmJtK5dujAKWtr/ITvBYAqV1dademCS/v2\nIp21jQ3nXFxoHxaGlZWVSGtu0wZTx464BwSIdACFbm749+2LXatWMqGdHdUdOuAl/NUJcPDYMdoN\nHoy78L1rY23Na033DedLa2rnrkaj0dBkxCrJzcWna1exNnrFCmxdXOhx881y7aOPYurZk37nozUv\nl8bGxuYvRe3c1Wg0LZ+CnBwlndls5geFICCAlO3bOamStUFTKFSNMCAHmi5vmyIjMRQu38UrLH9u\nRjd+jUZzSQpzc5UDP7Z89JGydvVjjylps5OTsVu6VElrjo/HetMmtTn3MTFYbd8u1iZFRBB8/DiW\ne/eKn/NZxfsuoBu/RnNNUR31AHA8OlpZ+63QgNVMxq5dxCieQbeJiSFWYemzYRj0PnKEQ59+Ktae\njYtjdGIih1esEGs5doyex49z9NtvRbKCnBzcjxxpigCVjiOvrCQ1LIyznTpRKPyVM+qVV2S1LkA3\nfs11geqYCICSoiIlXUp0tPIAMlUHd9yWLRxQyEEGyP7kExIVf97bLF9OhoIb26qxEdd336UgM1Ou\nLSvDbtEiKoTr+M+VlOCen4/x6afis2AjPR0roOHLL0U6gJScHAocHCgRrg6zsbHh2IwZRE2YQHvh\nqr3QiRMxh4TgOnkyXsKVcFdCi278DQ0NHNywQUl7WMHxC3BMcS5MVkKC0lgBUH+u+9evV7J1Jx88\nSFZMjFLNb+bPV2riu5YsIUmxqX370EOcleYKA2Wpqex+5BGl18hp+3YOvveeWOcRGIjDSy9xYscO\nubZ1a4ynn6ZQIZnKt76eM08/Lf+iq62ly5kznJgzR1yTc+cIS0sjXjg+4dTRo9jX1tI6L4/4rVtF\nWpOvL/FBQZwKDRW/D8esW8eBNm0YJQyWd/H0xDssjDatWuHp7y/SAk1r+AXpg1eDFt34j23aRINw\nkh40/ZQ8MHeu0rW8vM8+I1nhQ1t8/DiHVT48wJG5cylSSGsyR0SwT+EnfisPD5JnzBCPTwDwS0oi\n4qmnxM3UKzgYHnlEqSH2sbXl+F13UXHunEjnEhpK9+XLifrb38Q1ndu3x3fuXPEZeFs/P6wbGqh5\n9FF50pOjI90yMkiaNUv+5WphQZ99+9gqvDzQWFNDvqUldampnBUam852784eV1cs+/UT6QL79uX4\nwoVU9O9Pr3HjRNo+Dz5IXc+eBHTuLF4S3MbVlTrDoFJl0KCdnbqBS7Hx1yuEOjXToht//bZt2ERH\ni5tMVlISUw4c4Mg334hrup47x1mVa55mM0FLl5IsPIMB6F5TQ6LCh93W25vOCxaQILxm2c7fH4/y\ncjKnTxf/SrEODGTg+++z9+WXRbrAfv1oMJsx7rtPPiAuIIDBu3cTc889okmQ/qGh5Hp40Pudd4iS\nnr17edGuspLMf/yDaoGRplWrVpS6uuJy+jSZwl9ylfb2JLZvT6Wjo/jMveC229jh7c2g2bNFus5T\np5L84os4de2KqzCR7cZ33sE2JEScOufg5ES7QYOoko4aacbbGxR+AVpaWuJma0tRbq68pq0tqN6/\nMZuVGn+Figv7PC228RuGQfru3XDyJInCpVCn9+yhwsaGbIVc2Or8fIy4OBKl4xMaG6G+nkSV5WKO\njrhERxMnfb6entjX1JDy+eeiLw0LCwsMX1/cTpzg6MqVspoBAVgCFZs3i+bf2NraUtuxIw3l5eQf\nPiwqafj7k+LoSKmtLYbgmrC1tTVpffuy3csLf2EgvV2fPmybNAnrvn2xd3AQaU0ffEB0u3Y4hYSI\ndEOee46q+fOhrEw8wnfcm29iGxpKovDSaJu2bfEaO5YTcXEiXTNVwcGUKjiUA/v2Ja68nHKF4YTV\n7u5qzRuodHPjrMKltAZra04rnvEXNDZSp3C5UTql9UJatIGrpqaGxsZGbG1tRe6+8tJSzIaBc+vW\nTcHiAlIPH8YvNBQbYS5nUXY2FWVl+AtHIAAc3riRzsOG0crZWaQ7k5ZGcVoaIWPGiPczesUKOoaH\n4yF0E+YmJ3MmOppe06eLf2rHrVuHd48eeAuvk5YVF1NeWoqnjw/WCnmphXl5eAjn5gBUlJZiZWOD\nnXByJUBxfj5uCpnGDfX1VFdW4uTiItaWlpTg7OIifi8YhkFFWRlOCvnCVZWV2Nnbi98LzVoHgbO+\nmfr6ekwmk9jxC009xdbWVvwamc1m6uvrsVXIfa6rq8PS0hJLS9kgBcMwml9XcR9v0Y1fo9FoWjoF\nJ09SU1ZGB4UxHOe/oLRzV6PRaFQpUhjnDE2h6Xs+/1xJm/Xtt+QruH6vBN34NRrNdYfkhvnFRCgs\n2gAoLihg29//rqQ9vXkzNorLrtm5E0PBY5GlEKXZjG78Go3mktTX1Smb3OJ++kk503jVE09QpbBq\nxTAM0l9/XUmbsX07ITt2qNXdvx/bXbuoEYaxFObk4L5nD9bR0eIAmGSVQPnz6Mav0bQQ8hW8HM1s\nU8xtLsjPZ6NCLjFA49GjHFKIGwXolp3NEYUIz9yMDMYnJBCvEDlKQgJhubkkLF8ukjU2NmI6eJBu\neXkcE/qKcuPiqPL2prZ1azKFs3fGCkOdLkQ3fk2LR2moFlB8+rQ4V7iZqG+/VXIol5eVsfLZZ5Vq\nJq5cSfQHHyhpzatWEa9wCcTKxob2y5dzQuEyhqmmhnYffURuUpJcW1hIq88/p0yYgXsmNhYvsxnT\nypXi43MuLo4K4ORPP4l0VRUV5A4axKE+fWjt4yPS9pw0idphw7C691669u8v0l4JLb7xJyuOFsiW\nhmSfJy8zU8niX11VRbGCqQQgSyHBCOBEbKzSz/TqqiritmxRqrljyRKl0RRZKSlsff11pdd21ZNP\nkqpyfdVk4rvx45VGIFgfO8au++4Tv75Ozs54bdsmNrgBOAcE4Pv88yQII0MB3Nq0we7pp8kRrqm3\ntrbGo66Oc888I/6SNNXU0LG4mKx//EOkMwwDCgvpkJPDXumQt7o6EoKCKG/blhKh0zhs6VK2tmtH\nuHA4nFPr1viMG4elhwedfyUy9mepqwOFpadXsgqyRTf+zMOHSVMclrX92WeVzvYy1qwhVsGEZWFp\nyTfTpytNZ4z75z/F7luAitxcIm6+mXMFBSKdvYMDmW+8wf6FC8VvLmfg+MiRZOzfL9L5demC7dq1\nRN57r3j0Qpd+/bC55RYOCs+G3by8CLa2Jm/8eLFb2HHwYAZ/+SV7br9dbKRxCg6m+/z57BNeBvHs\n0QOLqioc//KXJvOiBBcXuuTlcUToALe2tqbG0hKv7Gzi164VlaywtSWlQwcKnJxEw9YMwyD7r3/l\noJ8fY4V50X1nzKBu8mRcgoNx8/YWadu2a4ebkxPFKpfUrK0xFO+FUF+PScF/8od07gIUxMVhUjBM\nALhaWpK6b59YZ+XkRLGCi9HW1hY3k4lkhTNTz9BQstasETfhsAkTKCkoIENh/o338OFU/PQT5cIm\n3P2eeyisrCRf2EhNJhN2Y8Zgm5bGOeEHr/sdd3DC1ZXqkyfFr5ExeDANlpbUCn+lBI8cyZ4OHbB2\ndaVW+gEMCiItMBBLoTnJp1Mn9nTsyMnBg7ERRjY2BAWxY9w42s6eLTJTOTg4kPXuuxwYMoQB06eL\nag7/xz8omjkT30GDROYkCwsLpjz1FHmBgUrh8JbdulGrYHADqB00CEuFS3gOXl6c69JFqWaFnx82\nwmhKgPorGPGtDVwtALPZrOR8BKitqRHb+wEqy8uxc3AQuwkBis+cwU0YmA5wrqAAu1atsBOOQICm\nddTthdm3AMU5Odi3bo2DsJECnExOpkNQkFhXmJ1NK3d37BVcqaVnz9JakJ+s+X2jauDSjV+j0Wha\nKNq5q9FoNC2Q+ro6EiIjr2lN3fg1Go3mPMXClUDN1NXW8sObbypp49esoXLdOiWtKrrxazSa6w5J\nrsLFRCksd4Wm1USr/vIXJe2xTZvwVMjaAGjYtAkrheD0MwpBSc3oxq/RaH4R6RiCZjLj45VS3AB+\nevVVchX9K0WLF5OjoE07fJjBW7aQl5Ym1jZERuJ18CBFQq9ORWkpjtu24XD4sHgFU8JXX4m2vxDd\n+DWaFkJRXp44fLyZHcuW0aAY1ffpAw8ouZTPnjzJib/9Tclo1K60lGxh9i00nbV3yMwkR2Fkw7m9\ne+lRUcEphaB20969BFRUkPH99yJdZnQ0ZldXaj08SD94UKS9UehxuBDd+DUtHtVmWFtTw6kTJ5S0\nsRs3clpRu2zWLKUM5ZLTp/lhyhQqFVKpnDIyiHj4YaUG3j8jgz0vvCDWAfRZs4a4JUvkwpISAr/9\nllShUS0vK4v2OTm0/vZbSoTGxarYWKqBDOHIhvr6ejK6d+dwSAiOHTqItN1vvJG6oUMx338/YaNG\nibRXQotu/LW1teQL4v0upODMGaUzEbPZTIlwfkgzyYcOKemO7d4tijFs5nRWFvtXrlRyC//0wQek\nKKw0OLhpE/tee42CzEyRrq62li8eeoj9H3wgPi47ly1j2623kiz8wNrY2hL5zDPsfeAB8TiNdl26\nkDRmDLsVRi8Ee3pyJjycxE2bRLrA3r3pcPIkh8aN41xhoUhr0bUr4cuXs33WLJEOwNLVlZB33yVO\n4dKCA+DwyivysRjnztGmtpb4xYtFspLsbE6FhVHu70+JMMw+6LXXiAsLI1g4/Mza2ppOEyfS6O5O\n6KRJIi0A1dWg4F35wzp3k3ftIu7DD5W0655+mtPCNwZAQnQ0OxRndmft26d0duri4kKKQj6wl58f\nxYcOUaMwmiKwVy/yo6LEun7jxlFy8iQNQvu6ja0tQx96iNKUFHHs3Y0PPUSjhwdWwghEk8nE8Nde\no6i6mtYeHiJtuy5dMCZNwqVrV5EOwO/ee8nq3h3vXr1EOpPJRPmYMdhOnYqzm5tI6z1wIBFTphBw\n770iHUBpjx6kzZlDB+EcGkdXV6Lvv5+KefNo5e4u0lo+/DA7X3qJCUuXinTdwsNxX7QIh2eeIUA4\n9Kytjw9WM2eKoz8B2nXvjnHPPWIdgPWECbgPHizWWSgEtDdzpQauz4EJQAFwqTDZfwJTgRJgGpB8\nie20gUuj0WgE/FYGrqXA2F/48/7AUKAvsPD8Q6PRaDS/IVfa+HfTdCZ/KQYAq4GzwEog+ArraTQa\njeYK+V9f4+8PXJjCUAh0+h/X1Gg0mmuO6uoywzCIVMwJVkU+/V+Gif++/nTJC/nz5s37z7+Hh4cT\nrhJqoNFoNIpkJyfjpzBx1TAMlj/zDA8o5IMkbNoEa9bAXXf96rYRERFERESIa1zM1ZjO6Q9s4Odv\n7j5O05dL86uRzqXP+PXNXY1GA0BJUREubm7iFV4AP/7rX4yZOVNppPi/x4/nTxs2iLVJERHk//nP\nhB8/Ln7OB2bMwOroUfrGx4t02UeP4t+zJ1yH0zkPArcBbsA9gJoHW6PR/GYUKXplKisriRQGlzdz\nfM0a4hQD4l0iIjis4L49W1DA8MhI4hWWTlds2kSflBRShMlzZ8+coc2PP+KekkJBbq5Ie2rXLtH2\nF3KljX8lsA/oCpwCHgRmnn8ARAN7gFjgaUAtZVqj+R2hGg5fdu4cyQqpcQCRK1aQsn27knbrM8/I\nox4Be3t7chcsIE9hbo5NbS2mN99Ucinb5OTQoPCFk755M8FVVdRt3CjSGYaBsXMnzkCZMO3ubFYW\npZ07UxAWRqFwRtCQJ54QbX8hV9r47wbaATaAL03r+j8+/2jm70BHoA9X+Yy/MDOTpM2blbRHvv2W\nSmFWKkBZSQkJwnkczaRs2UJxTo5YZxgGhQo6aBqUpXIJrbamhlRhfGIzh9etU4rMy05IIG7VKrHu\nVHIyMe+/z8mjR8XaTQsXEqHgvs1MTOT7adM4qpCF/N3LL/Pj+PGcFY4AdmrdmsRXXmHL7NnimkHD\nhlEwbRr7Fc6Eu3TqRO7994sHkFlYWNClvp59Tz0lrklVFV2Sk4l44w2RzGw2Y8rKok1UFHHC3lB4\n+DCnbG1JP3pUNNrCMAzSRo0iKjSU1kOGiGoGDhxIXUAAprvvJnT4cJG2VBiLeiEt2rlbV1lJieLP\n0KJTp6hQOJuor64mV3HiYE56OnVVVWLd4R07OKVwpldZUcHeJUuUvuAiv/iC0sREse7kiRMU7dlD\nmXBOCkDu4cPUFRWJde6+vpgtLC69auAXGDRtGhYK+awdQ0MJvf9+WnfsKNbeNX8+DpMn49q2rUhn\nMpno+/LLdFVwiLb188P0xhv0v/tusdZz8mTaf/UV7u3aibV18+czTuHL0W3kSE5GRTHulVdEOrPZ\nTMOHH9LqxAl6jhkj0o5/7z3Mhw9z2+7doqhTCwsLbps3D7/Vq+k6YoSoJkCXN96gy4wZYp1z69Zi\nTTM6elGj0WhaKDp6UaPRaDSXhW78Go1G8wdDN36NRqP5jbnWl7l149doNJqrQL5CuA403ZBeoTjq\nXRXd+DUaze8KleChZnZfQVD7GoVltgCHV62i0969SjVV0Y1fo9H8z1CJegQozM0lN/lS0R2/TMR7\n75Gt4OkAKF68mJyUFLHu2JYtDNqxgzKFtfV1X3yBbXa2uJEf+uILca1mdOPXaP4AVFVWKjfhA2vX\nKjloAT595BFqFLwrZ8+cIf7pp5XOat1yc8n717/EupLCQkLj4shTMGhWr11Lj/JyUoXxn8d37iRo\n+3Z8cnPJSU8XaR2EqWYX0qIb/9ncXGIUnIgA8d9/T76CESs/I4Mja9Yo1Ty0ciWFCnGPeSdOcERx\nbOuBzz5TCvYuPHWKA//+t1LN/YsXK+3nuYICdi5YoFTz4KJFZB8+LNYVZmfz0/PPi3V1tbXsf/11\njq1bJ9buX7+er6dPF+vMZjOfz55NlMIEyPLCQt4cOpQzCsfF0cqK76dNE+sA/Kqq2P/JJ2KdubER\ny/R0TkRHi7V5hYWcTk2lvr5epEuNjKS0Y0cKTpwQ6QzDICcnh7ju3SkV/lrwCg1l5913E3f//VgK\nv+T8fifTiw0pRadOGZ/eeqtYZxiGsfWxx4zjMTFiXWZiorHhwQeVan51661GfmamWLd/2TIj4tln\nlWp+Mnq0kZOQINatf+klI3LOHLGuICfHWDpxopEZHS3WfjNnjrHn9dfFulOpqcaGJ580smJjxdqo\n5cuNg8uWiXUVpaVG7IYNRk5iolhrNpuNlEOHxDrDMIyGhgajKC9PSVt69qySzmw2G5Xl5Ura2poa\n5Zpms1lJ+0eCXxhz/0u0eOfu2cJCXIVB2dD0U9KxTRtsbW1FOsMwyElLw7dzZ3FN1Vnfp1JTad+p\nk8hGDk1niAWnTuHl5yeuWVJURBuFn5L1dXVYWVsrjdPVaDQyVJ2719OnU6nxazQazR8VPbJBo9Fo\nNJeFbvwajUbzB0M3fo1Go/mNyTh27JrW041fo9FozlNbU6Os3fr550q6srNnifzb35TrqqAbv0aj\nuS5RXeyRk5xMiUIQEMAPzz9P6dmzYl1VRQV577yjFKuZ8OabhJ08KdadEoazX4hu/Jo/PHo12S9z\nJa9PzJYtyo7hJYqZsvlRUaQomg/99+7lxIYNYl38Rx8xJTGRTOElm4LsbDyWLsUoLha/zglLloi2\nv5AW3fjjv/uO76dMEevq6+rY+uCDRCs4CuO+/JIfp00TuwINw2DD9OnEKhys2C++IOK++ygrKRFr\n1911l1LNuFWr2H3PPRSfPi3Wbpg2jViF1/Z4VBQ7JkygKDdXrN0ycybRCjb9opwcVo0YoXSGuHve\nPHEmLDQ5lP81apRSJOaql19mvTCOEKC8tJTX776bWoUBZon79rHm1VfFOoDGU6dIj41V0rZqaKC+\nrk6ss2rdmkYHB7GuqrKSqn79sLaxkdd0cSFt5kwahaMt6srKKH34Yc7060d1dbVIO0rhvdeMlbLy\nOsA1KIj6pCSxztrGBqfKSiyEzRvA0sUFp6wsrK2tRTqTyYRLZibWd9whrklNDTbFxTi3aSOW5Q5d\nOQAAIABJREFUWiUl4fzII2KdOTubBrMZVy8vkc4wDCqPHcP10UfFNfO3bcMUEICrt7dIV11VxakT\nJwhRqBm1bBkBd96Ji9AEWFtTQ35DAyPvu09csyA7m4mLFuHo5CTW3j5nDpaWlmKdU+vW/H3lSrEO\noNvgwXQbPFhJO1DhvdfMXYsXK+l6TJ2qpHNwdGSEYs2+Dz8MDz8s1vl0745P9+5KNW3t7JR01xtK\nluX1771n1NfXi3Wpe/cahzZuFOsaGhqMb+bNE+sMwzC+mjtXyYYevXatcSIqSqnmqldeUdJt/+wz\no6K0VKw7V1JiHNqwQalm/J49Srryc+eM6spKJa0eC6BpyfBHHdmg0Wg0f1S0c1ej0Wg0l4Vu/BqN\nRvMHQzd+jUaj+Y1RXfKqim78Go1GcxXIy8xU1i5RzOtVRTd+jUbzu8IwDOXA9biNGylV8MsYhsHq\nWbOUzG6HV6wgcPduse5sXp5Y08zVaPzDgONAKvD4z/x5OFAKHD7/mHsVav6Hs/n51AqND81IDRO/\nFY2NjUo6wzCoVsg7BSg9e1a5br5C1CM0GZtUTE0AOampSh+6hoYGTitEcALkZ2Wpv0YKFn1oinws\nV2hMAOUKQeDNVFdWKumKTp7ktGJo+oH165WO6YmYGPZ/8IFSzeovviBdoQnHrVzJ0KgoyoXv37KS\nEirnz0fu6IDI555TUDVxNRr/+8BMYDTwGPBzsU2RQK/zDzUL4M+w+fHHyercmWzhGyv9yBF2BQWx\na8YMcc1NM2ey19eXwzt2iHQnT5xgi58faxUMXFtnzeJAYCBxmzaJdNXV1fwYEMAPCjWPLVzIocBA\nYn/4QayNGTWKtbffLtalrV3LiaAg4hQs8+l/+hNr77xTrEvZv59T/fuTIDyeAJmvv84PClm0VZWV\nbBk9mnSFjOADixaxY84csa6hoYHF999PgcKXck5aGruXLxfrAJL37qX46FElbc7OndQoDE1zb9eO\nDiNGKNV0evBB2gUHi3V+4eFUvfsuVkJznZOLCx4rVlD1wAPimuM//VSsuVq0puksvpkPgAkXbRMO\nXM4nWWxeSNu920hp1cpIOnhQrN03bpwRM3u2WBe9bJkR6+Vl1NXVybVhYcZBhUzZmIULjZhu3YyG\nhgaxdr+/vxH98cfymq++auwdPFjJHLfF39+IX71aXnPBAiNyyhSjsbFRrF3Vu7eRrmAAi1q40Nj1\nzDNKRq5/33GHUXTqlFgXu2WLcWz9erHOMAzjSGSk0nPVGba/T1A0cF3pGX8/4MLT7SRg4EXbGMAN\nwBHgHaDTpf4yQ/izrtOQIZx89FHMChPxnB9/nDKFEQg97rqLQwMGiEc2AJzq2RMfhTNhiy5dqLv9\ndiWrflyvXvRRsJIXA+4vv4yVlXyqR+aNN9L9ttvEukIHB8I+/licLVxfX0+7554jQGGsgPfo0Qx/\n802ljOAHli/HzcdHrOszZgyhN98s1gH0GDZM6bmaTCadg6z5D1f6ThgNPATcff6//wy0B168YBsn\noBGoB+4DpgATf+bvMl566aX/vDnDw8MJDw//1SdQX1dHfV0dDq1aiZ98QW4unu3bi3V5mZm069hR\nrMtNT6d9p0t+712SqooK6quraa0QKl+cn49b27ZiXUVZGa2cncU6aLonofIlpdFofpmIiAgiIiL+\n89/z58+H3yBsvTUQQdO1e4APgS3ApS5Gm4AzQAfg4tvuhvSMX6PRaP7I/FYjG0rP/3MY4A/cCBy8\naJu2/N8TuxmI57+bvkaj0WiuEVdjLPMTwMeANU03d4toWuXD+f9/O/Ao0EBT03/6KtTUaDQajSLX\n090efalHo9G0WBrq67GwtBQvTgDYuHgxE2bNEt+A19M5NRqN5gopOXOGwpwcJe3yWbOUfAfJW7bQ\nsGSJuOn/1s7d34xzRUVEf/wxmdHRIl1tbS0Ju3ax//PPxTVPxMURu3o1J48cEemKTp0idt06Yn74\nQbxs9eiPPxK7fj2n09PlNb/6iuMHD4qHQB3buJG4DRsoLy399Y0voK6ujqgPPiArKUm8nyd27iRu\nzRpqFT48e/79b7ITE8W63JQUYpYtU7L4H12zhkwFExbAro8+okbBOZ577BipCs5SgIQtW6iqqFDS\nHrtgJYmE1B07SFqzRkn77dNPqzXS/fvZq5ikFfHqq+SkpIh1KQcO0LBjB/b29iKdYRjEv/cebgor\n6JJWrxZrrkfE5oU1Q4caZjBily0T6Q6sXGkUgxFzww3imlE33WQYYER/9plIl7Btm1EBxsE+fcQ1\no++80zCDse+990S6jKQkoxCM3V27GnW1tSJt7KxZRj0Y219+WaSrq6szjri4GDs6dzaqhKlYsa++\natSC8ZNCalhsjx7GTyEhRnVVlUgX8803RgUYO959V1wz5q67jB8HDRKb3MrLyoxdbm5GzKpV4prR\nb75pbLz9drHOMAxj6eTJRmZsrFiXk5FhbHnjDaWaqYcPG6nR0Ura6LVrlUyLJfn5RppimltjY6OS\ngdAwDONccbGSzmw2GxkJCUpaFA1c1xNiZ2FqVJSR26qVuPGbzWZj7+jRRsyUKSKdYRhG9KefGqdN\nJiMzKUlcMzo42Dj4l7/Iay5YYCR6eBhlJSUiXWNjoxHr42PsV4iKjJ0/3zjUtau4kRqGYez38TEO\nLF4s1h16440mt7CCK/rHbt2MRIXIx5hPPzV23XOPkqt1+aRJRk5iolh3JCrKiFBwcBuGYexascKo\nralR0hbk5irpNNcv/EbO3atK4Zkzou0Dhw4lbdYsDOFlDJPJROsnn6TUxUWkA+gxYwbr+/XDLyhI\nXLNh+HAshwwR17QbOJCCUaNwEj5fCwsLjgcF0fXPfxbXNHt6Uvvww9gJf7oCxPbqRT+FmkWGgceC\nBVgpuKLPTplCyMSf8wX+MqZ27eizaJGSq3X4W2/RPiRErOt2ww0MVxywFT59Oja2tkpaj3btlHSa\n3x/X1aqeksJCXNx/bsbbpamtqSEnOZlOPXuKCx7euZNeI0eKddGbN9N/3Dix7si2bQQNGSJupg0N\nDcTv2kXvG28U14yPiiJs2DCx7mRyMm39/bG1sxNrVR3RNdXVSl80Gs0fFdVVPddV4zf0ck6NRqO5\nbPRyTo1Go9FcFrrxazQazR8M3fg1Go3mNyb2hx8oKS6+ZvV049doNJrz1NbUcCYrS0n7w3PPkZ2a\nKtYl/vADWfPn4+LqKtLlHjsmrtVMi238DfX1RH/6KdEzZrBf6NJL37OHmDlzWHv77SJ3qdlsJmrB\nAmJnzybmk09ENVO2bSP2uefY9eijlAmzT3fNncuhZ58lbtkyWc3ISGJnz+bACy9QlJsr0ka89BKx\nzzzDka+/Fuly09LYc++9RL/yCkVC6/v+994j5q9/JUHB6blu+nSiX32VEuGS4Pj164meOZPE9evF\nNXfNmcOBefPEGbi1tbVsnDaN45s3i2vGr1lD1PPPKzmNo157jRMKEZONjY2sfvZZsQ4gdc8e0mNj\nlbRzR49WysWO37aNz2fO/PUNf4a9S5ZQq5BTXZSXx7njx+kQGCjWFh85gn1oqHhJcb1iDjJcZ42/\nQZCkZbKwoO7rr+n/5ZfYlJWJ6lQWFdH1n//ENyFB9GJbWFhgs2cPfT/8EJPQ+t5gMhH85pu02rUL\np9atRVqn5GT6LFxIQ1GRSGfh5ETnDz/EevVqXDw9RdpWubn0efttqoWh4E4eHniuXo3Vl1/Sys1N\npLUpLqbPBx9QmZkp0gG0j42Fb7/FXvja1pWU0P2TT6jOzxfXdEpOxrxrF/bCEKDq6mpchfnJzdRn\nZmLOyVFay38yJgbnDh3EuvLycqydVOLAwdLZmQ5hYUrauRs3ikcgAHQfPZoZixYp1Rz52GP4KXgz\n3Nu14/7165X8IMPmzWP8ihVinf+AAWJNM9dV4z+dnX3Z21paWuL79ttkubqC0MAVNmUKCRMmgEL0\novW0aVQDFp07i3Qho0aR2LMn9Okjf3MMGsQpe3t8b71VJOvUsydpHTvSMHGi2BRl6tSJRB8fuj/6\nqEjn3Lo1pd7e1D7wgHxNvqsrsT170mf2bJkOqLS3x/rvfxfXNNnYcOjmm5XiKU8C7RYuFL+2NdXV\n5EydSrCCF6Tcw4Pe778v1gEMe/NNvITvWwAXFxcmv/SSUs2AsDCsbWyUtHYKHhJoWuKoEo36W3Kt\nYzGvq8ZfkJQk2t6vd2/ynnpK9EuhGc/nnqNAofH3uvtuvu/RQ5zvajKZYMwY6N1bXNNj7FiO9OuH\nd0CASGdhYUFBSAge06aJa9KpE+W33UYr4Rk0wJGuXen5+ONiXZ2zM5ZPPKHUKNKHDaPn3Xf/+oYX\nYdO2Lf4LFih98IKfew7/fv3EOnd3d2758EOxDiD8vvtwFl4LbqZDly5KOo3mf4mRER8vnlXR0NBg\nxG7ZojTnIlJhSJZhGMaOFSuUdOkxMUZ6XJySdtfXXyvp9q1bp6QrzM01cpKTlbTSOUbNnCsuVpqZ\nYxiG8mAtjaYlg+KsHu3c1Wg0mhaKdu5qNBqN5rLQjV+j0Wj+YOjGr9FoNFcJadJdM/Hr15OekHCV\nn82l0Y1fc91wJfd4VLW/VU19P+vXOZWaqvQ61VRXk5OWplSzJD+fjKNHxbq6mhp+mDmTxP37xdp9\nb71F9vPP4y/0D8T/9JO4VjPXVeOvr6+/7G3NZjNb580jqk8fdsyZI6qTFhlJxIQJrBowgEqB+80w\nDDbNns2ewYOJfPVVUc1j69ezd/x4No8eTYEwJHnDgw+yd/Bgol55RaQ79N13HBg6lKjRo8mIjxdp\n106ZQuzAgWwVrqk/umsX+4KDOTByJMkHDoi0Pz76KLH9+rH9mWdEOrPZzJehoewfNYq0Q4dE2j2L\nFxMTFsbOF14Q6QDW3XILkSNGcOrECZGuqLCQDV26ECF8DwFEvvUWm4YPp0zoFgbYcNdd7FFYRlpV\nVcW7I0Yonc3GfPstB1etEusA1r7wAlUKLtqsmBjiv/hCqWbe4cNisyM0GUrt/f3pLlzmDeA5cCAu\n06djaWkp0oUoZIk0c101/tyMjMve1mQyYZeUxLC4OFpL3xwWFgTt2kVgZqbIGWgymXA9c4Yh+/bh\nIPwQ2Hp60nXrVjzT03H38hJp29bWMnjfPhyE69vdQkII2L8fh1On8AsNFWl9vLzoc/Agzr6+Il1g\nv3645OZiWVhIYN++Iq2nlxe9YmNxUvArBJtMmCorCejVS6R1cHUlJCEB1x49RDoAXzs7rOzt8RGa\nolo5OeF47hw+4eHimo62tjh37YqzggelDAiaMkWss7e3x2f0aCws5O3Ct18/ekyaJNYBzP7uOxwd\nHcW6oGHDGC88SWomdOxYXL29xTprGxvGPP+8Us3AoUMZqqBVSapr5rpq/EWCoUMmk4nQd9/lWEAA\nJqGBK3DoUNLvvhvD2Vn8Zm7z5z9TYmkJQut754EDSR86FKN7d/kHaMQIiiwscB0zRiTzDw0lu1s3\nzKNGic8mCA0l2cODkIceEskcW7WiMiCAhjvvxMrKSqQ1+fpyqFs3eiu4aGvc3bGeNUv82pratCFu\n7Fh63HmnuGaevT3eL70kNn/Z2dmROmkSgQoxnHTsSOj8+XIdMPKNN3AXfpFD02ftDuGv6ma8OnbU\nqWrXIddV4689dUq0vVv79jQuWMA5hUFOnV98kdS2bcW6oJEjiRs1CseuXcVa4+abMYRn3gAhd97J\npr59CVCIl6zp3RvbCRPEOucBA8i98UYll+jxzp0JFo56ALD286P+3nuVnLuZgwbRe8YMsc47OBi3\nZ55Rcu6GPPkkAQMHinUmk4kH//UvsQ6g7803K52RAnj7+SnpNJr/JUbqkSNK7rW4HTuUdKqu1oM/\n/GBUV1eLdWUlJcahTZuUau5evVpJF/vTT0qu1sbGRuP4wYNKNU+lpirpamtqjNqaGiWtquNXo2nJ\noJ27Go1G88dCO3c1Go1Gc1lcjcY/DDgOpAKXGsn4TyADOAQEXYWaGo1Go1HkajT+94GZwGjgMcD9\noj/vDwwF+gILzz80Go3md4VhGBSePq2k2/Puu+xXSIFT5Uobf/Ow9iggG9gKXBwLMwBYDZwFVgLB\nl/rLpNf4zWYz2cnJlJ49K9IBFJ0+TUlhobhmY2MjOenpSo7CkuJicUxfc808YRLWf2oWFVEhTCgD\nKC0tJScrS7yfpYWFJO7bR2FBgdjwkxYbS0ZSEnV1dSJdY2MjsT/+yFlhQhlAXkoKKbGxSpkOiZGR\nFAmjHgFqqqpIiIwU7yfA6bQ0TmdnK73/MhISqFKI62tsbCT7xAmlmpXl5eKo0WaiPvxQ6bicSU1l\njzCmtJnUyEgOrFsn1lVXVfHZyJEUCs18AOuffBKWLKHf+PEi3bGdO8W1mrnSxt8PSL7gv5OAi9e3\n9T///5spBDr93F92Rricc80jj9DQty9HnntOpEvcvJmMIUPYFxxMgSByzzAMvps6laqePdn85z+L\nasauWkVWr17s696dk8JA5jWTJ1PWpQubHnlEpNu7YgWnO3fmcOfOJMfEiLS7b7mFhoAAvr/tNpEu\nLy0Nj8GDKWjfniNbt4q055YupXVoKJuESWMmkwnjkUfI6tCB+F27RNrciAi8+/Vj/V13iXQA1e+8\nQ1rXrqQfOSLT1dRguukmtigsec3dsIGU/v0pVvjCOf33v7P7tdfEusbGRtbcdhuNjY1ibdJPP3FE\nIVYQoKy+XqnxW1hZ4aJgcANw6diR3mPHinX2Dg4Mfe01QoYPF2tvfOUVWr32mtj30u06d+6a+O+7\nzj976pAXFyf6i73atsW/shJHwagHAM+QEJxrauhUXY2jIC/VZDLh5+tLl4oKPD08RDX9brgBp4oK\n3Kys8On0s997l8Q/MJCg2lo8hQlK3SZMwBKw8/Cgq9BF23bAAPwMA9/Ro0W6Lv37c8rHh4revekl\nNJwRGIgT4HfPPSKZhYUFJj8/aocMIWzECJHW0seHOktLQhSasKltW4yJE+kk9Fe4tGlDSocO9BGO\npgAweXpiM20a7gpr+bM6dmSQQk0bGxv6zp0rbkwAvSZPpu8DD4h1ABOfekopftGzY0e6TZ6sVNOj\nQwelPGOAoBtuUNI5ODnRU/H5qiI/kv8/McBbF/x3KLDlom0OAiFA80QhD5pu9P4XH3/8Me3Onz2F\nh4cT/iuW9htefpkDMTHYCkc2ePj5kfbXv2L1xhviMOfAp54i9euvQTh2wcPXl/RJk7DMzRW7S51u\nuYWcDz/EaehQka61qyspgwaBn5/YoGTZrx/HPDwIFjZhS0tLzCEhEB4ur9mlC4d69GCAwtl3Tfv2\nOAh/KQC069mTnSNGcOeoUWJtvqsrwX/6k1hnMplomDGD9sGXvOp5Sdr27Yu98MutmdveekvZRTts\n6lQlnZW19RWNFtD8/0RERBAREfFbPw0ADtO0ssefpss+P3dzdw/gBtwDbLzE32P88NRTYgPD6RMn\njK9uv12sa2hoMD4cPlysMwzD2Pvkk0bMd9+JdUk7dhjbHn5YrDObzcbikSOVjFj7Xn3ViFGIbayq\nrDSW3HGHWGcYhrHq8ceNorw8sa6stNRY89JLSjW3fPKJkonLbDYb8bt3K9UsKSpS0mk0Vwt+QwPX\ncOAjwBr44Pxj5vk/+/j8P18HptJ0g3c6Tcs/L8YoKSrCxc1N/ARy09NpL7x8ApB29CiBCsO5inNz\naWxsxFM4rwcg6cABQhRs/imHDtG1Tx+x7nR6Om3atVM60yvIzcWzfXuxrrK8HEcnJ7EOmu6jqIxP\n0Gj+iKgauK6nT9j5LzCNRqPRXA7auavRaDSay0I3fo1Go7kOKMjNvWa1dOPXaDSaq0BucjIHvv9e\nrMtLSWHbLbeQvGOHSHdWwSXczHXV+Gtra0XbF2ZmsnPBAo4pWJ2PfvUVP731FpUVFSJdcW4uEQsX\nclx4kAzD4Mh33xH50UeUFReLtKnx8US8+SZJwpoFmZns/de/2Ld4McU5OSJt9Oefc/Ctt4j7+muR\nLjclhdjXXiP2vffIS07+dcEFHP7qK2LfeIO4b74R6cxmM9vnzCH2gw/IF6S4AZzYtYvYBQuIX7tW\npAM4sHgxse+/T5HQeFhZUUHUiy8qvW9P7NxJ9NtvU6bgVo/5/HOOb7l4tfWvU19fz5bXXlMycOUk\nJJCquPzwg9tuo7y8XKxL2rWL755+Wqnm7mXLWP/BB2JdVUUFG6ZNw1dhie7xFSvgzBmGCvMkKgXm\n0+sZIyEyUrSUafUttxgGGDH33SfS7f/mGyPL2dnIASNPuOxw5fDhhhmMmJkzRbqIzz838i0sjJNW\nVkZ+bq5Iu33oUMMMRrSwZsLWrUYFGDm2tkZuerpIe3DaNMMA46Bw+WlhXp6RYW9vnLKzM3JSUkTa\nmBdfNAwwDjzyiEhnGIYR062bkeHsbJwW7mf0N98YZjD2z54trhl7331GkpeXUVJQINI1NDQYh7y8\njH3z5olrxixbZsQEBxt1tbVi7YEHHzQOfvSRWGc2m40Pb75ZrDMMw8jPyjKivvhCSZublaWkq62t\nNYrz85W0Kkumm6mqrFTWnsnOVtKhuJzzujrjr0lMFG0f/OCDnHZwAOEskH63305Or14YIF462GnG\nDOoAhJbwIffeS1ZYGPk+PngIXZetbr+96V9CQkS60NGjSerenbywMNoJc2xNN9xAI2AhzIV19/am\nOCyMvGHDaC90Gpu6deOcyYSzgoGLLl3InzABL+F++gwaxEFnZ3yEIzgA8Pfn3J134iJ0cVtaWnIs\nKIiQv/xFXLJ1WBglU6YopZRVDB5Mj/vuE+tMJhO3KZwFA3j6+TH03nuVtO0UE8NsbGxwVQhMB5Ry\nhZuxd3BQ1rZVWBp+JVxXjd9ISxNtHzJxIul//zt1wp+9lpaWtHvzTU66uIgPdN8HHyR2+HBwcRHX\nbJw2DaNDB/GXTej993PAywun/v1FOpPJhDFyJIZQB+A3aRIb/fzopuCGpXdvUJh30mnUKDYOGECQ\ngjO1omNHHKdPF+u8fH05OmUKPgo/0eu6dKHDrFliHUD3F1+ktYJnJSAsjBsUQ71HPfggtgojEAC8\n/f2VdJrrk+uq8WcK5uY0M3juXBIUcmw79u9P7r33ipuwyWSi9TPPUKVgUOo5axaJClm9rZydSZo0\nic79+om1DhMnYlbQefr4UDF9upLxq3bwYDpPmybWubi5EfDcc0oGrg7330+3cePEOpPJxPRFi8Q6\ngEH33EN7heMJ0EtxwJalpaWyOU6jaeZ3YeAyFN2eDfX1WFhaKv28q66qUvppV1VZiYOjo1hXU12t\n1IQNw6CxoUFpXorq66rRaK4N2rmr0Wg0fzC0c1ej0Wg0l4Vu/BqNRnOVUAmOAchLTmbr4sVX+dlc\nGt34NRrNdUl1dbWSzmw2UyXM6GimpLCQ3UIDIUB1RQV7587lO4UVV/sXLuT0iBH4CBcKHLmCjN7r\nqvGXCvNoD61bR+SoUewQRi8WZGWx8+GHWTNgAOcEHgDDMIh8+232jx/PzhdeENVM272bffffz7bh\nw8nNzBRptz39NNETJ7LtqadEusTt24m94w7233gjJw4dEml3PvccsZMns12Y2JSXmUnk+PEcnDKF\nVGHc456FC4mdPJldc+aIdAA/3HorB269lcyjR0W6I5s2ETthAlGvvCKuufP559l9yy3kCd3CjY2N\nrJ04kb0LF4prHlm3ji2TJ1Op4GiNnD+fAx99JNYZhsFH06YpZe5mJyUR+fHHv77hz/DOrbdSopBR\nnbhzJ2uefVapZvqPP+KmsGjDZGFBQXo64/72N7G2dZcuZA8aRIgw7S74ppvEtZq50gSuq0ratm30\nufPOy96+YOlSxu3cSaz7xdkvv0xpVhZdvv0Wy/JyKsvLcbnMNfkmkwnLI0cYtHkzsYGBopq2Li74\nfP89ZSYTrsL0LqeaGvpv2kRMt24iXfsePcjftYtaS0v8hEteW9nZ0Xf9eqLnzhXpvP39ycvIwKqi\nAr+wMJHWtk0b+qxfT7SC76B9bS2mtDR8hfvp2rkzNj/9RLY0JhJwsrbGnJODd8eOIp2lpSVeBQXY\nKMQntvLzw1DMO7CwssJewShkMpnw7ttXaYWXX0gIFooJXHM2b1bSdR89mu7CJtpMXwWDG4CdgwO3\nrFyppA2ZNIngm28W61Q9GXCdnfEbwrO1ocuWcWDgQMjLE+k6h4eT9cwz2ABVQvNXl5df5oS3Nwhf\ndN/u3cmZOpUaDw9x3KPXI49w2s4OhGEzLh4enBszhrru3cVvEvcpUzhlZYW9MDzaZDJhDBpEXXi4\nOLvUb+xYolxd6aDi3O3encYJE8S5sL6dO7O5Rw+6qeTCdu2KceutSg0xZeBAeirsZ6cePXCcOfPX\nN/wZQh56iO4KxjqAyU8+qaSDptdY88tc62XT11Xjzzj+c8Fcl6aViwv+K1aQoHBD5Ya5czly003i\nxu/ZsSNFjz+OWSGQ2f+ZZ8hSSLTy79mTpNGjcRSe8QPYTJlCnYLBLaBXLzYOH06IgovWGDgQhKMe\nADzbtyd58mS8FdLUjF69cL/7brHOZDIR+PzzSmfQnW+6ieBHHhHrAKa//TaWlpZinclkUs6/dfPy\nuqKRBJrfD9fVOv60+Hg6de8uFibs3k3IDTeIP0j56elUVVXRUVizob6e2M2bGThpkkgHsPf77xms\nMAbh0JYtdB85EhvhjJbGxkYS9+whTHjmDnAiLo4uvXuLdWVnz2Jpba3UTFWNcRrNHxFt4NJoNJo/\nGNrApdFoNJrLQjd+jUajuQ44Llz+fCXoxq/RaDQXUFdbq+RZKDt7lrULFoh1VRUVRD72GOmffy7S\nNdTXi2s10+Ibf8rOnaRs3y7W1dXWErV0qVLNM5mZZERHi3Vms5mkffuUbN1VlZWcFhq/oMl8U1xU\npPQmaWxsVHJPGoZBfX29+MNjNpsxm83ieoBSveaa9YofINWaoG7tNwxDuaZhGMqvr+qdWXLLAAAI\nkUlEQVTzPZOSwkmhebCZiOXLleo2NDSw4c03qaqsFGtjlyxhqTACEeDk8ePEDxyIl3A5McCPd91F\n0GefESpcIbZbwYzXzHXV+HMFQSxms5mNd9+N+9ixlG3YIKpzaM0ajnXrRusnnqCmpkakXTd1KrWh\noZxdvVqkO/zjj0R36kTp2LHiN/O66dPJbNeOrHffFeky4uPZ7ufH4YAAysvKRNpNjz9OvKcnUbNn\ni3S1NTWs7NyZLT4+FAr9Fbvee48jHh5sUEjDWj92LGt9fSkW5pBmxMezu21bfhS6ogF2vfAC3wYG\ninObAVYPHsyWl14S644fPMi/QkKUGvhPL71E1Pvvi3UACxVTtCrPnCH72DElbU1GBnV1dWKdpaUl\nfr16KY0/9+rfn3EKmRAdgoOpf/RRej72mLjmiI8+4vATT9BRuIJuxOOPi2s1c301/nXrLntbCwsL\nfMaPp87GBlJSRHW6jR9PVfv2+JSVcTorS6T1nzwZl9paEDbvHmPHYvb1xdrREVuhB6DDzTcTUFaG\ntdADEBAWhnNQEC4dOtBGmPbkN3EiXc6exbVvX5HO1s6OwD598AoMxFP4fIMnT8atspJ2Ct6BDv36\n4RMWhlvbtiJdpx49wNOTjpMni2u6DRhAh/79cVQIEHIIDiZY4FJvJnjAABzHjlVaj99t2jQCFG3+\nj/3730q6TsOHM1TRDTt23jwcVMYnmEyE3XijUk2f7t3p0KePknbEk09ir/Bl4+bjw9g33lCqqcp1\n1fgrIyJE2/ecMYMzH35IQXq66AzI1t6eLkuXktu5M8XCL40e99zD0XvvFTd+CwsL2syZQ7Gzs/hs\nouedd3Jk2DBQsPhbTJ1Ko3C8BEDoTTexs2dP2ioYsRg5EmPAALGsXadObB0yhG4KTdhq0CAaFL4w\nTCYTJ8ePJ2jYMLE2aOxYUImmBMKeew4/BUOeyWRihsKMHwCfoCA6KJj5AJxat1bSaa5P5NbB/x3z\nJj/8MF0HDRI1Ru9evcg1mbD18sJZkIPr2KYNZd26UVJYiF+PHqIn6jJkCLFxcYSOGiXSeQQGEpWR\nQS+hbd5kMlFoZ4eNry9thdmnnt26EZOVRYiwsZlMJlIbGug7bpz4i8o5MJAyOzu8FL5wHIKC8FII\n2Xbr2JE2oaHYKZwhht14o9IZtI2NjXg2UDPSgPYL0e5bTTPz588HmC/VaQOXIqqxhFcSZ6ijEDUa\nzYX8FgYuJ2AdcBL4AbjUhc4sIB44DMiXwlynqDbgK2ncuulrNJqrwZU0/kdpavqdgRzgUksxDCAc\n6AXI5+3+DogQ3rtoaej9a9no/bs+KDt3TnmprpQrafz9gSVALfA58Et38/7Qp6ot5Y2nit6/lo3e\nv6tH9KZNSr6QjL17WXX//dfsV/2VNP5+QPL5f0/m0mfzBrCTpstB8nGWGo1GI6SitJTC3FyxrrKs\njC9nzRKnATY2NLB7zhxOL1qEtTB4JmbxYiwnTaKHcJHJ8R9/FG1/Ib/W+LcBCT/zmMTln8UPBnoA\nzwPvAJeMn5L+zKkqLydq9mwOK2RkJu/YwaZHHxXrys+d48Bbb3FM4DmApn1L3LGDrS++KK6Zf/Ik\nMZ9+SvKWLSJdQ309cRs2EPHOO+LXNjclhdjly0lVOFuKW7eOPR9/LDYZFZ08SeyKFWQcOCCueXzH\nDvZ/8YV4P+vr6znwxRdkx8WJa+YmJnLwq6/EOoBjmzeTk5Ag1tXW1BD97bdKNU+npHAmNVWsMwyD\nzx58UOkyxPFNm9j+4YdiHcCuTz4hfvdusa6ksJBFY8Zgr+Cv2PrkkwRUVdG6TRuRLnHHDtp+9hle\nEyeKdHW1tRTv3AmVlbS9/XaRtk2XLqLtrxZraLpuD9AHuBwr6zvApXzJaTT9OtAP/dAP/dCPy3tc\n/riDq8TfgA8Be2Ax8HOp3A40rf4B8AASAd9r8uw0Go1Gc9W51HLOdsCm8/8eABw5/9gBPHiNn6NG\no9FoNBqNRqP5Lfi9mr+GAceBVOBSo/P+CWQAh4Cga/S8rha/tn/hQClNx+swMPeaPbMr53Mgn6bF\nC5eiJR+7X9u/cFrusfMFdtF0KTkCuOcS27XU43c5+xdOCzh+zfcHbIFF/Pz9AYBMwPVaPamrwGGa\nmqMfTUtc3S/68/7AHpr26W5g4zV9dlfOr+1fOLD+Gj+nq8VQmhYrXKoxtvRj92v7F07LPXZeQM/z\n/+5OU3N3umiblnz8Lmf/whEcv99q2tPv0fzVPL4wCsgGtvLf+zWAptVPZ4GVQPA1e3ZXzuXsH7Sc\n43Uxu4FfWrzdko8d/Pr+Qcs9dmdouo8IUETTmfHF88Rb8vG7nP0DwfH7rRr/79H8deE+ASQBAy/a\npv/5/99MIdDpf/y8rhaXs38GcANNb9J3aDn7djm05GN3Ofxejl0gEMp/Xxr+vRy/S+2f6Pj9Lxv/\nNTV/tRBM/Pe+G7/FE/kfEUfT9ch+NH3I1OKerk/0sbv+cQJWAU8CF+cu/h6O3y/tX4s4flfb/HU9\n0Jqma+DNfAhMuGibx2k6aM2k/6+f1FXkcvbvQkw03UyUxY39tvhz6WvgLfnYNePPL9+8bqYlHjtr\nmi4/PnGJP2/px+/X9u9CfvX4/VaXeg7StKbf/vw/f86jf7H5awwgm1lwbSk9/89hNH3AbqRpPy/k\nIHAb4EbTnfnj1+rJXQUuZ//a8n9nVTfTtCKr9lo8uWtASz52l0NLPnYmmu4ZHgPeu8Q2Lfn4Xc7+\ntYjj93s1fw2n6Q2VBjSnlM88/2jmdZpWKx2iZd1ggl/fv8doenMeAZYDYdf6CV4BK4E8oA44RdP7\n7fd07H5t/1rysRsCmGl67s3LGcfx+zl+l7N/Lfn4aTQajUaj0Wg0Go1Go9FoNBqNRqPRaDQajUaj\n0Wg0Go1Go9FoNBqNRqP5fxsFo2AUjIJRMHwAAKAZi5l2uzPiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ce61350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#help(np.mgrid)\n",
    "f = lambda x: [x[0] ** 2 - 2 * x[0] - x[1] + 0.5, x[0] ** 2 + 4 * x[1] ** 2 - 4]\n",
    "x, y = np.mgrid[-0.5 : 2.5 : 24j, -0.5 : 2.5 : 24j]\n",
    "U, V = f([x, y])\n",
    "plt.quiver(x, y, U, V, color = 'r', linewidths = (0.2, ), edgecolors = ('k'), headaxislength = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\left[\\begin{smallmatrix}{}-10.0 & 6.0\\\\15.0 & -19.0\\end{smallmatrix}\\right]$$"
      ],
      "text/plain": [
       "-10.0   6.0 \n",
       "            \n",
       "15.0   -19.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "A = sym.Matrix([[-10., 6.], [15., -19.]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\begin{Bmatrix}-25 : 1, & -4 : 1\\end{Bmatrix}$$"
      ],
      "text/plain": [
       "{-25: 1, -4: 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym.Matrix(A).eigenvals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\begin{bmatrix}\\begin{pmatrix}-25.0, & 1, & \\begin{bmatrix}\\left[\\begin{smallmatrix}{}-0.4\\\\1.0\\end{smallmatrix}\\right]\\end{bmatrix}\\end{pmatrix}, & \\begin{pmatrix}-4.0, & 1, & \\begin{bmatrix}\\left[\\begin{smallmatrix}{}1.0\\\\1.0\\end{smallmatrix}\\right]\\end{bmatrix}\\end{pmatrix}\\end{bmatrix}$$"
      ],
      "text/plain": [
       "-25.0, 1, -0.4, -4.0, 1, 1.0\n",
       "                            \n",
       "          1.0            1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym.Matrix(A).eigenvects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\begin{Bmatrix}-1 : 1, & 4 : 1\\end{Bmatrix}$$"
      ],
      "text/plain": [
       "{-1: 1, 4: 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym.Matrix([[2., 3.], [2., 1.]]).eigenvals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\begin{bmatrix}\\begin{pmatrix}-1.0, & 1, & \\begin{bmatrix}\\left[\\begin{smallmatrix}{}-1.0\\\\1.0\\end{smallmatrix}\\right]\\end{bmatrix}\\end{pmatrix}, & \\begin{pmatrix}4.0, & 1, & \\begin{bmatrix}\\left[\\begin{smallmatrix}{}1.5\\\\1.0\\end{smallmatrix}\\right]\\end{bmatrix}\\end{pmatrix}\\end{bmatrix}$$"
      ],
      "text/plain": [
       "-1.0, 1, -1.0, 4.0, 1, 1.5\n",
       "                          \n",
       "         1.0           1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym.Matrix([[2., 3.], [2., 1.]]).eigenvects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\begin{Bmatrix}-25 : 1, & -4 : 1\\end{Bmatrix}$$"
      ],
      "text/plain": [
       "{-25: 1, -4: 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym.Matrix([[-10., 6.], [15., -19.]]).eigenvals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\begin{bmatrix}\\begin{pmatrix}-25.0, & 1, & \\begin{bmatrix}\\left[\\begin{smallmatrix}{}-0.4\\\\1.0\\end{smallmatrix}\\right]\\end{bmatrix}\\end{pmatrix}, & \\begin{pmatrix}-4.0, & 1, & \\begin{bmatrix}\\left[\\begin{smallmatrix}{}1.0\\\\1.0\\end{smallmatrix}\\right]\\end{bmatrix}\\end{pmatrix}\\end{bmatrix}$$"
      ],
      "text/plain": [
       "-25.0, 1, -0.4, -4.0, 1, 1.0\n",
       "                            \n",
       "          1.0            1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym.Matrix([[-10., 6.], [15., -19.]]).eigenvects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\begin{Bmatrix}\\frac{3}{2} : 2\\end{Bmatrix}$$"
      ],
      "text/plain": [
       "{3/2: 2}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym.Matrix([[1., 1.], [-(1./4), 2.]]).eigenvals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
